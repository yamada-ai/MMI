{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PN_noun_data():\n",
    "    pn_path = \"~/Documents/MMI/corpus/PN/\"\n",
    "    pd.set_option('display.unicode.east_asian_width', True)\n",
    "    df = pd.read_csv(pn_path+\"noun_pn\", names=['word', 'label', 'desc'], delimiter=\"\\t\")\n",
    "    df = df[ (df.label==\"p\") | (df.label==\"n\") | (df.label==\"e\") ]\n",
    "    df[\"label\"] = df[\"label\"].replace({'p':2, 'e':1, 'n':0})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23815] 2021-12-24 15:24:38,837 Info gensim.models.keyedvectors :loading projection weights from ../../corpus/w2v/model.vec\n",
      "[23815] 2021-12-24 15:25:40,936 Info gensim.utils :KeyedVectors lifecycle event {'msg': 'loaded (351122, 300) matrix of type float32 from ../../corpus/w2v/model.vec', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-12-24T15:25:40.936499', 'gensim': '4.0.1', 'python': '3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-Ubuntu-18.04-bionic', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v_path = \"../../corpus/w2v/\"\n",
    "# fasttext\n",
    "# https://qiita.com/Hironsan/items/513b9f93752ecee9e670\n",
    "# w2v_name =  \"dep-ja-300dim\"\n",
    "w2v_name =  \"model.vec\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_path+w2v_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['無', '非', '未', '不']\n"
     ]
    }
   ],
   "source": [
    "denial_list = \"無 非　未　不\".split()\n",
    "def is_in_denimal(word):\n",
    "    for denial in denial_list:\n",
    "        if denial == word[0]:\n",
    "            return True\n",
    "    return False\n",
    "print(denial_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noun = load_PN_noun_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xy_pn(df):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for x, la in zip(df.word, df.label):\n",
    "\n",
    "        if x not in w2v_model:\n",
    "            continue\n",
    "        else:\n",
    "            # if is_in_denimal(x):\n",
    "            #     print(x)\n",
    "\n",
    "            X.append( (x,w2v_model[x] ) )\n",
    "            y.append(la)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_Xy_pn(df_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7811\n",
      "1, 73, 107, 7811, "
     ]
    }
   ],
   "source": [
    "leng = len(y_train)\n",
    "print(leng)\n",
    "for i, v in enumerate(y_train):\n",
    "    if leng %(i+1) == 0:\n",
    "        print(i+1, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor( [xt[1] for xt in X_train_str] ) \n",
    "X_test =  torch.tensor( [xt[1] for xt in X_test_str]) \n",
    "y_train = torch.tensor( y_train ) \n",
    "y_test = torch.tensor( y_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 155\n",
    "epoch_ = 300\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(PNModel, self).__init__()    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hid1= embedding_dim*2\n",
    "        self.hid2 = embedding_dim//2\n",
    "        # self.fb_dim = 4\n",
    "        # self.fb_dim = 0\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, self.hid1)\n",
    "        self.fc2 = nn.Linear(self.hid1, self.hid2)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        # self.hidden2tag = nn.Linear(self.hid2+self.fb_dim, tagset_size)\n",
    "        self.hidden2tag = nn.Linear(self.hid2, tagset_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # fb = x[:, :self.fb_dim]\n",
    "        y = F.relu(self.fc1(x))\n",
    "        # y = F.relu(self.fc1(x[]))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.hidden2tag( y )\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 600 3\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = EMBEDDING_DIM*2\n",
    "OUTPUT_DIM = 3\n",
    "# seq_len = length\n",
    "print(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNModel(EMBEDDING_DIM, OUTPUT_DIM)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 17.671637624502182\n",
      "epoch 100 \t loss 2.5397991091012955\n",
      "epoch 150 \t loss 0.28419510810635984\n",
      "epoch 200 \t loss 0.09209657175233588\n",
      "epoch 250 \t loss 0.07086185642401688\n",
      "epoch 300 \t loss 0.02706228986789938\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "for epoch in range(epoch_): \n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        # X_t_tensor = torch.tensor(data[0], device='cuda:0')\n",
    "        X_t_tensor = data[0].cuda()\n",
    "        # y_t_tensor = torch.tensor(data[1], device='cuda:0')\n",
    "        y_t_tensor = data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        # print(X_t_tensor.shape)\n",
    "        score = model(X_t_tensor)\n",
    "        loss_ = loss_function(score, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "    # if all_loss <= loss_border:\n",
    "    #     print(\"loss was under border(={0}) : train end\".format(loss_border))\n",
    "    #     break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[555 147  21]\n",
      " [104 553  84]\n",
      " [ 31 139 319]]\n",
      "accuracy =  0.7306707629288275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/social/pn_dnn_v1.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/social/\"\n",
    "model_name = \"pn_dnn_v1.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = \"死者 熱中症 いい 悪い\".split()\n",
    "y_test_1 = [0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = [ w2v_model[w] for w in test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(x_test_1, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test_1, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred_1 = np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
