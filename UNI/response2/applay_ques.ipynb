{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from response.feature import Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../X_y_data/response2/Classify_F.pickle\n"
     ]
    }
   ],
   "source": [
    "F_path = \"../X_y_data/response2/\"\n",
    "F_name = \"Classify_F.pickle\"\n",
    "featureM = DataManager(F_path)\n",
    "F = featureM.load_data(F_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response2/Classify_M.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/response2/\"\n",
    "model_name = \"Classify_M.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "lr = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../../corpus/hand_labeled/\"\n",
    "path = \"../../corpus/hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_utt = []\n",
    "y = []\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        # if ut.is_system() and ut.is_exist_error():\n",
    "        #     if conv[i-1].is_type_inclued(\"質問\"):\n",
    "        \n",
    "        if not ut.is_system() :\n",
    "            usr_utt.append(ut.utt)\n",
    "            if ut.is_exist_type():\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of y:2000,  counts:637\n"
     ]
    }
   ],
   "source": [
    "print(\"len of y:{0},  counts:{1}\".format(len(y), y.count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [07:48<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# 正解率を見ておく\n",
    "from tqdm import tqdm\n",
    "print(F.feature_num)\n",
    "usr = []\n",
    "for i, x_t_str in enumerate( tqdm(usr_utt) ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    usr.append(x)\n",
    "usr_ = np.array(usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(usr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_y = []\n",
    "# {'YN': 0, 'WH': 1, 'please': 2, 'proposal': 3, 'plain': 4}\n",
    "for p in y_pred:\n",
    "    if p <= 3:\n",
    "        fixed_y.append(1)\n",
    "    else:\n",
    "        fixed_y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[1116  247]\n",
      " [  94  543]]\n",
      "accuracy =  0.8295\n",
      "precision =  0.6873417721518987\n",
      "recall =  0.8524332810047096\n",
      "f1 score =  0.7610371408549405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y, y_pred=fixed_y))\n",
    "print('accuracy = ', accuracy_score(y_true=y, y_pred=fixed_y))\n",
    "print('precision = ', precision_score(y_true=y, y_pred=fixed_y))\n",
    "print('recall = ', recall_score(y_true=y, y_pred=fixed_y))\n",
    "print('f1 score = ', f1_score(y_true=y, y_pred=fixed_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000円ぐらいかな？\n",
      "海いいですね\n",
      "海外の海もいいものですよね\n",
      "魚もおいしいですよね\n",
      "船旅もいいらしいですね\n",
      "台風は怖いですよね\n",
      "こんにちは！暑いから海行きたいね！\n",
      "いいお天気ですね\n",
      "雨がやみました\n",
      "鈴木選手はワールドカップで活躍しましたね\n",
      "だよね〜\n",
      "え〜欲しいの？わたしは要らないな\n",
      "私は冷夏の方が嬉しいかな？\n",
      "楽しい事をしていると時間を忘れますよね？\n",
      "晴れた日にいきたいですよね\n",
      "歩きにくいですものね\n",
      "確かに気をつけて泳がないといけませんね\n",
      "急な高波は危ないですね\n",
      "一気に読みたいですよね\n",
      "焦点は合うけど疲れたら頭がボーっとするね\n",
      "椅子を工夫して腰が痛くならないようにしています\n",
      "ストレッチをするとよいよ\n",
      "前の日食べた物とかも影響するよね\n",
      "姿勢に気をつけて丈夫なままでいたい\n",
      "そうなの？すごいね。\n",
      "おお！道路を横切るとは！　エゾシカはひかれちゃうんです\n",
      "凍らせると糖度は上がるっていうよね\n",
      "明日は晴れるといいですね\n",
      "カキ氷は好き？\n",
      "嬉しいですね\n",
      "青い海と空、最高ですね！\n",
      "天気がいいですね\n",
      "太陽が出ていると暖かくていいですね\n",
      "聞いたことがないですね\n",
      "それは私の質問の答えではないですよ？\n",
      "ああ。周りの女子の話か。そう？\n",
      "健康が一番だよね。君は結婚してるのかい？\n",
      "すごいですね！\n",
      "扇風機も併用するのさ。塩分を補給するのも良いらしいよ？\n",
      "行きたいね！ビーチバレーしたいな\n",
      "砂浜がとても熱くてやけどしそう\n",
      "青い空が最高だね\n",
      "海水浴は楽しいですよね\n",
      "夏の晴れた日の海は最高ですね\n",
      "でも、たまに荒ぶりますよね\n",
      "湖も楽しいですよ\n",
      "泳いでるニジマスなんかがよく見えますもんね\n",
      "勉強になりました\n",
      "子供のころの女子はしっかりしている子が多いですね\n",
      "キャンプで食べるお肉はおいしいよね\n",
      "毎朝食べていますよ\n",
      "バナナは栄養の吸収が良いから朝食べると良いらしいですよ\n",
      "早く冬こないかなあ\n",
      "友達と飲んでいました\n",
      "飲み過ぎました\n",
      "そんなことはないですよ\n",
      "昔、猫を飼っていました\n",
      "薄い芸ですか。どんな芸なんでしょうね\n",
      "暇ですね\n",
      "写真はいいですね\n",
      "そうですか？\n",
      "趣味はいいですね\n",
      "美味しいですよね\n",
      "元気になれるんですよね\n",
      "塩をかけても美味しいですよ\n",
      "どんな食べ物にも合いますね\n",
      "海を見ると元気になれますよね\n",
      "癒しがあります\n",
      "夏場はそうですね\n",
      "この短時間に何があったの！まあまあ、笑って笑って\n",
      "そらそうよ\n",
      "多いって今言うたやんけ\n",
      "行きましたよ\n",
      "わかります\n",
      "謝らなくていいですよ\n",
      "いい感じですね\n",
      "固いといえばくるみかな\n",
      "花火見に行ったよ\n",
      "サッカーも強いですもんね\n",
      "コロッケは国で違いがないのかもしれませんね\n",
      "映画といえばポップコーンが定番ですからね\n",
      "行きたいですね\n",
      "岸和田行ってみたいですね\n",
      "気になりますね\n",
      "ジーコさんでお願いします。\n",
      "うどんよりラーメンですよね\n",
      "そういえば今年は台風が多いですね\n",
      "グルメ番組にも興味があるんですね\n",
      "行ったことがないんですが、美味しいお店があるんですか？\n",
      "流行ってるよねぇ\n",
      "髭面が好きかな\n",
      "やっぱ美味しい食べ物は人を笑顔にしてくれるね\n",
      "そのために国が努力してくれないとね\n",
      "劇団四季の舞台を一度観てみたいな\n",
      "タレントのミケランって有名なの？初めて聞いた名前\n",
      "お笑いに詳しいんだね？\n",
      "冬彦さんと言えば野際陽子さんとのドラマだよね\n",
      "突発的に金髪とはすごいね、何かあったのかな\n",
      "今度私も買っていこう\n",
      "蔵王ハートランドには行ったことがありません\n",
      "どちらかというとざわちんかな。　モノマネメイクしてみたくならない？\n",
      "松岡修造が出てるときの熱さで感動することあるよ\n",
      "行ったことがありません\n",
      "暑いですね\n",
      "詳しいですね\n",
      "そんなホテルがあるのですか？初耳です\n",
      "そんなホテルはないでしょう\n",
      "昨日終わったオリンピックは見ましたか？リレーの銀メダルには驚きました。\n",
      "迫力があって楽しそうですね！\n",
      "名古屋は美味しい食べ物が多いですよね\n",
      "YAWARA!を読んだことがあります\n",
      "言葉が通じるのがいいですね\n",
      "日本にとって良い物や良い文化が入ってきてほしいですよね\n",
      "阪神タイガースはカッコイイですね\n",
      "仕方ないですね\n",
      "宮沢和史っ俳優だよね。好きなんですか？私は，綾野剛が好きです！\n",
      "レイザーラモンですねあと栗原はるみ\n",
      "フジテレビはいろいろな問題を抱えていますね…\n",
      "そうなの？ぜんぜん知らなかった\n",
      "たしかに、できるだけ長いことプレーしたいよねスポーツ選手って\n",
      "それも見てませんけど、山田孝之さんの事をよく知っているんですね\n",
      "ごめんなさい、わからないです。ほかに好きな俳優さんいますか？\n",
      "それは楽しみですね！USJも賑わいそうですね！\n",
      "ケータリングなのに出張で作ってくれるのはすごいですね\n",
      "うちのホームベーカリーはセレッソ大阪のじゃないですよ\n",
      "サッカーは戦術が大事と言いますもんね\n",
      "外国選手にとって日本の文化などは受け入れがたいところもあるでしょうね\n",
      "その役柄ではないかな？でも広末さんはたくさんのドラマに出ていますね。\n",
      "陳腐なストーリーだね\n",
      "夏は麺類が欲しくなりますね\n",
      "「冷え知らず」さんの生姜チャイ飲んだことある！不味いですよ！好きですか？\n",
      "それじゃあまるで南半球のサンタですね\n",
      "その新米はおいしいのかな？\n",
      "らいおんハートではなくてHEROですよね？\n",
      "倖田來未さんはアナウンサーではないですよ！\n",
      "昨日の台風は凄かったですね\n",
      "最近はパンのバリエーションも凄く増えましたね\n",
      "どんなお菓子でも、うす塩味は外しませんよね\n",
      "ピザポテト味の飲料は斬新ですね\n",
      "おでんと肉まんは定番ですよね\n",
      "違和感を感じさせて、注目させる狙いがあるのかもしれませんね\n",
      "今年の10月から？\n",
      "すごい、よく知っていますね！\n",
      "ダッフィーのぬいぐるみはかわいいですよね\n",
      "ご冥福をお祈りします\n",
      "皇居の周りを散歩しました\n",
      "え？私は1位じゃないことに驚きました\n",
      "よく小説を読みます\n",
      "すごいですね\n",
      "どうでしょうね\n",
      "チャットはほとんどやりません。よくチャットやるんですか？\n",
      "読書好きですか？自分はよく図書館を利用します\n",
      "クラシックを聴いています\n",
      "あまり気にしないでください\n",
      "共感します\n",
      "大人に見えることがよくありますね\n",
      "夏は電気代がかかりますよね？\n",
      "布団は毎日干した方が気持ちいいですよね\n",
      "美容室でのおしゃべりも弾みますよね\n",
      "構図についてそこまで詳しく勉強したことないなぁ\n",
      "本を読むことですね\n",
      "洋書は読んだことありません\n",
      "行くかどうかどうかは時と場合によりますね\n",
      "テレビを見たり読書をしたりして過ごすのが好きです\n",
      "小説を読むことが多いですが、漫画も好きですね\n",
      "そんなに違いますか！\n",
      "途中で見直さないと、意味不明の文になります。\n",
      "それはフィギュアでスケートですね\n",
      "ユーのマイブームはなに？\n",
      "ばらの花は名曲ですね\n",
      "雨が降ってきましたね\n",
      "そうなんですか。猫は可愛いですよね！\n",
      "猫は癒やされますね\n",
      "無視ですか？すいません、スポーツには疎くてわかりません\n",
      "やりがいがありそうなお仕事ですね。ちなみに好きな動物は何ですか？\n",
      "来年の話をすると鬼が笑うよ\n",
      "なに？なに？どこに隠れたらいい？\n",
      "あれ、そうでしたっけ？\n",
      "登山をときどきしています\n",
      "本を読んでいます\n",
      "肉と魚を比較したら、魚のほうが圧倒的に好きです\n",
      "果物はデザートって感じがしますね\n",
      "テレビを見ています\n",
      "「はし」とか、いくつも意味がある言葉があります\n",
      "練習すればきっと上手になりますよ\n",
      "本当ですか？お世辞でも嬉しいです。\n",
      "変わってますか？朝食ヨーグルト派は結構いますよ。\n",
      "ボードですか、楽しそうですね\n",
      "そうですか、よかったですね\n",
      "１つの職業にスポットを当てた漫画ですか、面白そうですね\n",
      "子供の頃スイミングに通っていましたよ\n",
      "短距離ですか？長距離ですか？\n",
      "人柄がでそうだね\n",
      "ちがいますよ\n",
      "何だか不思議ですね\n",
      "ブラジル系の人が多かったことがです\n",
      "最近はまってることは読書です\n",
      "人見知りしますよね\n",
      "？ん？\n",
      "いい天気ですね\n",
      "空気が澄んでいます\n",
      "いいですか？そうは思いません。\n",
      "部活で旅行に行くんですか？変わった部活ですね。\n",
      "着せてないです\n",
      "何年生ですか？\n",
      "いいですよ、受けて立ちましょう！\n",
      "かなり昔からやってますね\n",
      "漫画はスマホで読むのも便利ですよ\n",
      "LINEの無料漫画を読んでいます\n",
      "泊まる場所って旅行の思い出として残るよね\n",
      "マンチカンという種類です\n",
      "犬も可愛いですよね\n",
      "鍋は美味しいですよね\n",
      "暑いですよね、毎日ー\n",
      "落ちていません\n",
      "知っています\n",
      "占いというのは下らないね\n",
      "こちらこそよろしくお願いします\n",
      "余り外にはいかないかな　家の中で音楽聞くのが好き\n",
      "気持ちはいいですよね\n",
      "山も楽しいわよ\n",
      "役立つというか達成感がいいわ\n",
      "ハンバーグが好物です\n",
      "ラーメンも美味しいですよね\n",
      "カラオケに行くとストレスが発散できるからおススメですよ\n",
      "はまりますよね\n",
      "そう思っています\n",
      "京都はいいですね\n",
      "何度もあります\n",
      "楽しいですよ\n",
      "わかりました\n",
      "夜中に地震が起きたらパニックになるかも\n",
      "夏も半分終わりましたね\n",
      "思ってません\n",
      "ジャズを聴くことが多いです\n",
      "テナーサックスはやっていませんよ\n",
      "分かりました\n",
      "以前少し聞いたことがあります\n",
      "撮影に参加することはありません\n",
      "いいですね\n",
      "一緒に行けたらいいですね\n",
      "たまに映画を観に行きます\n",
      "疎外感ですか？私も確かに感じます。\n",
      "空耳では？\n",
      "家の中で２匹飼っていますよ\n",
      "今は2回押してないよ\n",
      "両性なのか\n",
      "247\n"
     ]
    }
   ],
   "source": [
    "# チェック\n",
    "# count = 0\n",
    "# for utt, y_, fixed in zip(usr_utt, y, fixed_y):\n",
    "#     if y_==0 and fixed==1:\n",
    "#         print(utt)\n",
    "#         count+=1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def search_utt(convs, query):\n",
    "    i=0\n",
    "    for i, conv in enumerate( convs ):\n",
    "        for ut  in conv:\n",
    "            if query in ut.utt:\n",
    "                print(i, ut.did, ut.utt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1502868470 魚もおいしいですよね\n",
      "165 1471414705 海水浴です。魚も見えましたよ\n",
      "165 1471414705 海水浴です。魚も見えましたよ\n"
     ]
    }
   ],
   "source": [
    "search_utt(convs, \"魚も\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここから Sentence-BERT vs 後ろ向き\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models ,losses\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers.losses import TripletDistanceMetric, SoftmaxLoss\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from sentence_transformers.readers import TripletReader\n",
    "from sentence_transformers.datasets import SentencesDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_num = 0\n",
    "neutral_num = 0\n",
    "# 0: not error, 1: newtral, 2: error\n",
    "X = []\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        # if ut.is_system() and ut.is_exist_error():\n",
    "        #     if conv[i-1].is_type_inclued(\"質問\"):\n",
    "        usr_utt.append(ut.utt)\n",
    "        # ユーザ発話駆動\n",
    "        if not ut.is_system():\n",
    "            if ut.is_exist_type():\n",
    "                type_num += 1\n",
    "                # システムがエラー\n",
    "                if conv[i+1].is_exist_error():\n",
    "                    X.append( InputExample(texts=[ut.utt, conv[i+1].utt], label=2 ) )\n",
    "                # エラーではない\n",
    "                else:\n",
    "                    X.append( InputExample(texts=[ut.utt, conv[i+1].utt], label=0 ) )\n",
    "            # ニュートラル\n",
    "            else :\n",
    "                if neutral_num <= type_num:\n",
    "                    if not conv[i+1].is_exist_error():\n",
    "                        neutral_num += 1\n",
    "                        X.append( InputExample(texts=[ut.utt, conv[i+1].utt], label=1 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, train_size=0.7, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../corpus/cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] : (768,)\n",
      "[1] : (768,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "\n",
    "download_path = \"../../corpus/\"\n",
    "# download_path = \"\"\n",
    "transformer = models.Transformer(download_path+'cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "pooling = models.Pooling(transformer.get_word_embedding_dimension(),    \n",
    "  pooling_mode_mean_tokens=True,\n",
    "  pooling_mode_cls_token=False, \n",
    "  pooling_mode_max_tokens=False\n",
    ")\n",
    "model = SentenceTransformer(modules=[transformer, pooling])\n",
    "\n",
    "sentences = ['吾輩は猫である',  '本日は晴天なり']\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "for i, embedding in enumerate(embeddings):\n",
    "  print(\"[%d] : %s\" % (i, embedding.shape, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "EVAL_STEPS = 1000\n",
    "WARMUP_STEPS = int(len(X_train) // BATCH_SIZE * 0.1) \n",
    "OUTPUT_PATH = \"../../corpus/sbert_ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SentencesDataset(X_train, model=model)\n",
    "train_dataloader = DataLoader(train_data, shuffle=True,  batch_size=BATCH_SIZE)\n",
    "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fcdbd96d5147d999ae1b945cc6e558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a7c609e52d48ada8c2da8e30ac50ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48aa781bc9e41a6b2f25754bdf35922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc941ddb52a4da9be47f501dccfeb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "         epochs=NUM_EPOCHS,\n",
    "         evaluation_steps=EVAL_STEPS,\n",
    "         warmup_steps=WARMUP_STEPS,\n",
    "         output_path=OUTPUT_PATH\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "# clf = AdaBoostClassifier()\n",
    "clf = svm.SVC(kernel='rbf', gamma =0.0001, C=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "bert_path = \"../../corpus/sbert_ignore\"\n",
    "sbert = SentenceTransformer(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    sentences = []\n",
    "    if isinstance(text, str):\n",
    "        sentences = [text]\n",
    "    elif isinstance(text, list):\n",
    "        sentences = text\n",
    "    \n",
    "    return sbert.encode(sentences)\n",
    "\n",
    "def text2feature(text):\n",
    "    vector = text2vec(text)\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "# clf = AdaBoostClassifier()\n",
    "clf = svm.SVC(kernel='rbf', gamma =0.0001, C=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_num = 0\n",
    "neutral_num = 0\n",
    "# 0: not error, 1: newtral, 2: error\n",
    "X = []\n",
    "y = []\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        # if ut.is_system() and ut.is_exist_error():\n",
    "        #     if conv[i-1].is_type_inclued(\"質問\"):\n",
    "        usr_utt.append(ut.utt)\n",
    "        # ユーザ発話駆動\n",
    "        if not ut.is_system():\n",
    "            if ut.is_exist_type():\n",
    "                type_num += 1\n",
    "                # システムがエラー\n",
    "                if conv[i+1].is_exist_error():\n",
    "                    # X.append( InputExample(texts=[ut.utt, conv[i+1].utt], label=2 ) )\n",
    "                    # X.append( text2vec([ut.utt, conv[i+1].utt]).flatten()  )\n",
    "                    X.append( [ut.utt, conv[i+1].utt] )\n",
    "                    y.append(2)\n",
    "                # エラーではない\n",
    "                else:\n",
    "                    # X.append( InputExample(texts=[ut.utt, conv[i+1].utt], label=0 ) )\n",
    "                    # X.append( text2vec([ut.utt, conv[i+1].utt]).flatten() )\n",
    "                    X.append( [ut.utt, conv[i+1].utt] )\n",
    "                    y.append(0)\n",
    "            # ニュートラル\n",
    "            else :\n",
    "                if neutral_num <= type_num:\n",
    "                    if not conv[i+1].is_exist_error():\n",
    "                        neutral_num += 1\n",
    "                        # X.append( InputExample(texts=[ut.utt, conv[i+1].utt], label=1 ) )\n",
    "                        # X.append( text2vec([ut.utt, conv[i+1].utt]).flatten()  )\n",
    "                        X.append( [ut.utt, conv[i+1].utt] )\n",
    "                        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [ text2feature(x) for x in X_train_str]\n",
    "X_test = [ text2feature(x) for x in X_test_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "# clf = AdaBoostClassifier()\n",
    "clf = svm.SVC(kernel='rbf', gamma =0.0001, C=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma=0.0001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[ 23   5  18]\n",
      " [  4 132   3]\n",
      " [ 19   6 125]]\n",
      "accuracy =  0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel_path = \"../models/response2/\"\n",
    "smodel_name = \"Classify_M_sbert.pickle\"\n",
    "smodelM = DataManager(smodel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/response2/Classify_M_sbert.pickle\n"
     ]
    }
   ],
   "source": [
    "smodelM.save_data(smodel_name, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
