{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from response.feature import Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../corpus/hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xy(convs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for conv in convs:\n",
    "        for i, ut in enumerate( conv ):\n",
    "            # if ut.is_utt_level_error():\n",
    "            #     continue\n",
    "            X.append(ut.utt)\n",
    "            if ut.is_exist_type():\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_Xy(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../X_y_data/response2/Classify_F2.pickle\n"
     ]
    }
   ],
   "source": [
    "F = Feature()\n",
    "F_path = \"../X_y_data/response2/\"\n",
    "F_name = \"Classify_F3.pickle\"\n",
    "featureM = DataManager(F_path)\n",
    "F.make_features(X_train_str)\n",
    "featureM.save_data(F_name, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2940 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2940/2940 [11:51<00:00,  4.13it/s]\n",
      "100%|██████████| 1260/1260 [04:57<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "print(F.feature_num)\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i, x_t_str in enumerate( tqdm( X_train_str) ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_train.append(x)\n",
    "for i, x_t_str in enumerate( tqdm(X_test_str) ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_test.append(x)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# clf = AdaBoostClassifier()\n",
    "clf = svm.SVC(kernel='rbf', gamma =0.0001, C=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[925  42]\n",
      " [ 45 248]]\n",
      "accuracy =  0.930952380952381\n",
      "precision =  0.8551724137931035\n",
      "recall =  0.8464163822525598\n",
      "f1 score =  0.8507718696397942\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 発話レベルエラーを除く\n",
    "\n",
    "        confusion matrix = \n",
    "        [[817  38]\n",
    "        [ 27 263]]\n",
    "        accuracy =  0.9432314410480349\n",
    "        precision =  0.8737541528239202\n",
    "        recall =  0.906896551724138\n",
    "        f1 score =  0.8900169204737732\n",
    "\n",
    "- 発話レベルを含む\n",
    "\n",
    "        confusion matrix = \n",
    "        [[925  42]\n",
    "        [ 45 248]]\n",
    "        accuracy =  0.930952380952381\n",
    "        precision =  0.8551724137931035\n",
    "        recall =  0.8464163822525598\n",
    "        f1 score =  0.8507718696397942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/response2/Classify_M3.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/response2/\"\n",
    "# M2: 発話レベルエラーを除く\n",
    "# M3: 発話レベルエラーを含む\n",
    "model_name = \"Classify_M3.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未検出: 1 : どんな食べ物にも合いますね\n",
      "未検出: 1 : 何ですかそれは、それを聞いて、食べる気が失せました。\n",
      "未検出: 1 : こんにちは。音楽はどんなのを聴かれていますか？\n",
      "未検出: 1 : 私も清水寺に行きたいなあと考えてます。\n",
      "未検出: 1 : TBSのドラマのずっとあなたが好きだったでは、矢部浩之というマザコン男性が、1992年の社会現象となりましたね。\n",
      "未検出: 1 : そうだね．やっぱりみかんが好きなのかな？\n",
      "未検出: 1 : そうなんですか？\n",
      "未検出: 1 : 大丈夫ですか\n",
      "未検出: 1 : ん〜〜〜〜〜友達と遊ぶことかな？\n",
      "未検出: 1 : どちらかというとざわちんかな。　モノマネメイクしてみたくならない？\n",
      "未検出: 1 : 夏は電気代がかかりますよね？\n",
      "未検出: 1 : 何処にあるお店ですか？ベースコートもトップコートも塗ると持ちが違いますよ。\n",
      "未検出: 1 : 日本テレビに来春アナウンサーとして入社予定だった南原清隆さんが内定取消をされたニュースをどう思いますか？ 。\n",
      "未検出: 1 : 私もどちらかというとインドア派で家でのんびり映画とか見てるのが好きなんですが、１３さんは、家でどんな風にのんびり過ごすのが好きですか？\n",
      "未検出: 1 : やりがいがありそうなお仕事ですね。ちなみに好きな動物は何ですか？\n",
      "未検出: 1 : 楽しい事をしていると時間を忘れますよね？\n",
      "未検出: 1 : 恩納村のフォレストアドベンチャーのような娯楽施設での体験を好んでする方ですか？ 。\n",
      "未検出: 1 : 1000円ぐらいかな？\n",
      "未検出: 1 : そうですか？\n",
      "未検出: 1 : 私もどちらかというとインドア派で家でのんびり映画とか見てるのが好きなんですが、１３さんは、家でどんな風にのんびり過ごすのが好きですか？\n",
      "未検出: 1 : え〜欲しいの？わたしは要らないな\n",
      "未検出: 1 : どうして．嫌いですか？\n",
      "未検出: 1 : 神戸にある、GREEN CAFE STYLE・ 茶乃逢やニトリ、阪神タイガースというチーズケーキのお店で販売されているチーズケーキを食べたことはありますか？ 。\n",
      "未検出: 1 : 熱中症に気をつけてたいですか？\n",
      "未検出: 1 : 私は名古屋の方が関心ありますね\n",
      "未検出: 1 : 何年生ですか？\n",
      "未検出: 1 : こんにちは！東京ディズニーランドと国営滝野すずらん丘陵公園なら、どちらに興味がありますか？\n",
      "未検出: 1 : そうですね、トランス状態なのかな？\n",
      "未検出: 1 : 日本テレビのBOSSというドラマは私は未見なのですが、その中で綾瀬はるかさんはどのような役柄を演じていましたか？ 。\n",
      "未検出: 1 : 変わってますか？朝食ヨーグルト派は結構いますよ。\n",
      "未検出: 1 : 昨日終わったオリンピックは見ましたか？リレーの銀メダルには驚きました。\n",
      "未検出: 1 : ？ん？\n",
      "未検出: 1 : TBS系列のずっとあなたが好きだったというテレビ番組で、タレントの小泉八雲さんが紹介した150g1728円のナインティナインが販売するやべっちF.C.とはどのような商品なのでしょうか？ 。\n",
      "未検出: 1 : 読書好きですか？自分はよく図書館を利用します\n",
      "未検出: 1 : 讃岐とフランスなら、どちらに興味がありますか？\n",
      "未検出: 1 : 関西と沖縄なら、どちらに興味がありますか？\n",
      "未検出: 1 : 元気は良いんですか？？元気ですかは元気か\n",
      "未検出: 1 : 越前海岸の温泉とか\n",
      "未検出: 1 : なぜでしょう？\n",
      "未検出: 1 : 他には？\n",
      "未検出: 1 : こんにちは。最近のマイブームは何ですか？\n",
      "未検出: 1 : 今年の10月から？\n"
     ]
    }
   ],
   "source": [
    "for y_p, y_t,  x_s in zip(y_pred, y_test, X_test_str):\n",
    "    # print(\"{0} : {1}\".format(y_p, x_s))\n",
    "    if y_t==0 and y_p==1:\n",
    "        print(\"未検出: {0} : {1}\".format(y_p, x_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
