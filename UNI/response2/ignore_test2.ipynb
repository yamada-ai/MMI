{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from response.feature import Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../X_y_data/response2/Classify_F2.pickle\n"
     ]
    }
   ],
   "source": [
    "F_path = \"../X_y_data/response2/\"\n",
    "F_name = \"Classify_F2.pickle\"\n",
    "featureM = DataManager(F_path)\n",
    "F = featureM.load_data(F_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response2/Classify_M2.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/response2/\"\n",
    "model_name = \"Classify_M2.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "clf = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../eval_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問系かどうかチェックする\n",
    "usr_sys = []\n",
    "y = []\n",
    "errors = [\"Ignore question\", \"Ignore offer\", \"Ignore proposal\", \"Ignore greeting\"]\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        if ut.is_system() :\n",
    "            if ut.is_exist_error():\n",
    "                usr_sys.append( [conv[i-1].utt, ut.utt] )\n",
    "                if ut.is_error_included(errors):\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1386 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1386/1386 [08:03<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(F.feature_num)\n",
    "usr = []\n",
    "for i, u_s in enumerate( tqdm(usr_sys) ):\n",
    "    x = F.featurization(u_s[0])\n",
    "    usr.append(x)\n",
    "usr_ = np.array(usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pred = clf.predict(usr_)\n",
    "# np.count_nonzero(question_pred) : 643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "bert_path = \"../../corpus/sbert_ignore\"\n",
    "sbert = SentenceTransformer(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response2/Classify_M_sbert.pickle\n"
     ]
    }
   ],
   "source": [
    "smodel_path = \"../models/response2/\"\n",
    "smodel_name = \"Classify_M_sbert.pickle\"\n",
    "smodelM = DataManager(smodel_path)\n",
    "\n",
    "sclf = smodelM.load_data(smodel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    sentences = []\n",
    "    if isinstance(text, str):\n",
    "        sentences = [text]\n",
    "    elif isinstance(text, list):\n",
    "        sentences = text\n",
    "    \n",
    "    return sbert.encode(sentences)\n",
    "\n",
    "def text2feature(text):\n",
    "    vector = text2vec(text)\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_X = []\n",
    "for u_s, qp in zip(usr_sys, question_pred):\n",
    "    if qp==1:\n",
    "        question_X.append(u_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sbert = [ text2feature(x) for x in question_X]\n",
    "sbeert_pred = sclf.predict(X_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "y_pred = []\n",
    "for p in question_pred:\n",
    "    if p==1:\n",
    "        if sbeert_pred[count] <2:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[878 154]\n",
      " [ 82 272]]\n",
      "accuracy =  0.8297258297258298\n",
      "precision =  0.6384976525821596\n",
      "recall =  0.768361581920904\n",
      "f1 score =  0.6974358974358975\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
