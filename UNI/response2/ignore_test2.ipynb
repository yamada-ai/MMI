{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from response.feature import Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../X_y_data/response2/Classify_F2.pickle\n"
     ]
    }
   ],
   "source": [
    "F_path = \"../X_y_data/response2/\"\n",
    "F_name = \"Classify_F2.pickle\"\n",
    "featureM = DataManager(F_path)\n",
    "F = featureM.load_data(F_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response2/Classify_M2.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/response2/\"\n",
    "model_name = \"Classify_M2.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "clf = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../eval_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問系かどうかチェックする\n",
    "usr_sys = []\n",
    "y = []\n",
    "errors = [\"Ignore question\", \"Ignore offer\", \"Ignore proposal\", \"Ignore greeting\"]\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        if ut.is_system() :\n",
    "            if ut.is_exist_error() and not ut.is_utt_level_error() :\n",
    "                usr_sys.append( [conv[i-1].utt, ut.utt] )\n",
    "                if ut.is_error_included(errors):\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/976 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [02:59<00:00,  5.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(F.feature_num)\n",
    "usr = []\n",
    "for i, u_s in enumerate( tqdm(usr_sys) ):\n",
    "    x = F.featurization(u_s[0])\n",
    "    usr.append(x)\n",
    "usr_ = np.array(usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pred = clf.predict(usr_)\n",
    "# np.count_nonzero(question_pred) : 643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "bert_path = \"../../corpus/pretrained/sbert_ignore\"\n",
    "sbert = SentenceTransformer(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response2/Classify_M_sbert.pickle\n"
     ]
    }
   ],
   "source": [
    "smodel_path = \"../models/response2/\"\n",
    "smodel_name = \"Classify_M_sbert.pickle\"\n",
    "smodelM = DataManager(smodel_path)\n",
    "\n",
    "sclf = smodelM.load_data(smodel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    sentences = []\n",
    "    if isinstance(text, str):\n",
    "        sentences = [text]\n",
    "    elif isinstance(text, list):\n",
    "        sentences = text\n",
    "    \n",
    "    return sbert.encode(sentences)\n",
    "\n",
    "def text2feature(text):\n",
    "    vector = text2vec(text)\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_X = []\n",
    "for u_s, qp in zip(usr_sys, question_pred):\n",
    "    # if qp==1:\n",
    "    #     question_X.append(u_s)\n",
    "    question_X.append(u_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sbert = [ text2feature(x) for x in question_X]\n",
    "sbeert_pred = sclf.predict(X_sbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "y_pred = []\n",
    "for p in question_pred:\n",
    "    if p==1:\n",
    "        if sbeert_pred[count] <2:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "        count+=1\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[608  14]\n",
      " [235 119]]\n",
      "accuracy =  0.7448770491803278\n",
      "precision =  0.8947368421052632\n",
      "recall =  0.3361581920903955\n",
      "f1 score =  0.4887063655030801\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新バージョン 学習方法変更\n",
    "- 前向きの検出 and S-BERT を用いた検出\n",
    "\n",
    "        confusion matrix = \n",
    "        [[878 154]\n",
    "        [ 82 272]]\n",
    "        accuracy =  0.8297258297258298\n",
    "        precision =  0.6384976525821596\n",
    "        recall =  0.768361581920904\n",
    "        f1 score =  0.6974358974358975\n",
    "\n",
    "- 発話レベルエラーを除く(誤情報が邪魔？)\n",
    "\n",
    "        confusion matrix = \n",
    "        [[585  37]\n",
    "        [ 80 274]]\n",
    "        accuracy =  0.8801229508196722\n",
    "        precision =  0.8810289389067524\n",
    "        recall =  0.7740112994350282\n",
    "        f1 score =  0.8240601503759398\n",
    "\n",
    "- S-BERT のみ\n",
    "\n",
    "        confusion matrix = \n",
    "        [[608  14]\n",
    "        [235 119]]\n",
    "        accuracy =  0.7448770491803278\n",
    "        precision =  0.8947368421052632\n",
    "        recall =  0.3361581920903955\n",
    "        f1 score =  0.4887063655030801\n",
    "\n",
    "\n",
    "## 旧バージョン\n",
    "\n",
    "- 前向きの検出 and S-BERT を用いた検出\n",
    "\n",
    "        confusion matrix = \n",
    "        [[1654  192]\n",
    "        [ 163  191]]\n",
    "        accuracy =  0.8386363636363636\n",
    "        precision =  0.49869451697127937\n",
    "        recall =  0.53954802259887\n",
    "        f1 score =  0.5183175033921302\n",
    "\n",
    "- 前向きの検出 and S-BERT を用いた検出 and 特徴量変更後\n",
    "\n",
    "        confusion matrix = \n",
    "        [[1647  199]\n",
    "        [ 145  209]]\n",
    "        accuracy =  0.8436363636363636\n",
    "        precision =  0.5122549019607843\n",
    "        recall =  0.5903954802259888\n",
    "        f1 score =  0.5485564304461943\n",
    "\n",
    "- S-BERT のみ\n",
    "\n",
    "        confusion matrix = \n",
    "        [[1542  304]\n",
    "        [  79  275]]\n",
    "        accuracy =  0.8259090909090909\n",
    "        precision =  0.4749568221070812\n",
    "        recall =  0.7768361581920904\n",
    "        f1 score =  0.5894962486602358\n",
    "\n",
    "- SBERT のみ and 特徴量変更後\n",
    "\n",
    "        confusion matrix = \n",
    "        [[1521  325]\n",
    "        [  61  293]]\n",
    "        accuracy =  0.8245454545454546\n",
    "        precision =  0.4741100323624595\n",
    "        recall =  0.827683615819209\n",
    "        f1 score =  0.602880658436214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
