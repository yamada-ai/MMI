{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xy(convs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for conv in convs:\n",
    "        for i, ut in enumerate( conv ):\n",
    "            # if ut.is_utt_level_error():\n",
    "            #     continue\n",
    "            X.append(ut.utt)\n",
    "            # print(ut.type_)\n",
    "            if ut.is_exist_type():\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_Xy(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filler_func_ = lambda L: [\"FOS\",  *L, \"EOS\"]\n",
    "def fill_SYMBOL_(L):\n",
    "    return list(map(filler_func_, L))\n",
    "\n",
    "def sentence2formated(sen):\n",
    "    return sum( fill_SYMBOL_( sentence2normalize_noun(sen) ), [] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def make_vocab_dict(text):\n",
    "    vocab_dict = dict()\n",
    "    # doc = nlp(text)\n",
    "    print(\"analyzed vocab text\")\n",
    "    vocab_dict[\"[PAD]\"] = 0\n",
    "    for key in tqdm(sentence2formated(text)):\n",
    "        # key = token.orth_\n",
    "        if key not in vocab_dict:\n",
    "            vocab_dict[key] = len(vocab_dict)\n",
    "\n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzed vocab text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68953/68953 [00:00<00:00, 4427788.23it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = make_vocab_dict(X)\n",
    "vocab_size = len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../X_y_data/response2/vocab_dict_noun3.pickle\n"
     ]
    }
   ],
   "source": [
    "vocab_path = \"../X_y_data/response2/\"\n",
    "vocab_name = \"vocab_dict_noun3.pickle\"\n",
    "vocabM = DataManager(vocab_path)\n",
    "vocabM.save_data(vocab_name, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../X_y_data/response2/vocab_dict_noun3.pickle\n"
     ]
    }
   ],
   "source": [
    "vocab_path = \"../X_y_data/response2/\"\n",
    "vocab_name = \"vocab_dict_noun3.pickle\"\n",
    "vocabM = DataManager(vocab_path)\n",
    "vocab_dict = vocabM.load_data(vocab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2ids(sentence:str, vocab_dict:dict):\n",
    "    doc = sentence2formated(sentence)\n",
    "    ids = np.zeros(len(doc))\n",
    "    for i, key in enumerate(doc):\n",
    "        # key = token.orth_\n",
    "        if key in vocab_dict:\n",
    "            ids[i] = vocab_dict[key]\n",
    "        else:\n",
    "            ids[i] = vocab_dict[\"[UNK]\"]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "def padding_vector(Xseq):\n",
    "    Xseq = [ torch.tensor( xseq[:, None] ) for xseq in Xseq]\n",
    "    Xseq = rnn.pad_sequence(Xseq, batch_first=True)\n",
    "    Xseq = [ torch.flatten(xseq) for xseq in Xseq ] \n",
    "    return Xseq\n",
    "\n",
    "\n",
    "def make_X(utt_list:list, vocab_dict:dict):\n",
    "    utt_id_list = []\n",
    "    for utt in tqdm( utt_list) :\n",
    "        utt_id = sentence2ids(utt, vocab_dict)\n",
    "        utt_id_list.append(utt_id)\n",
    "\n",
    "    utt_id_pad = padding_vector(utt_id_list)\n",
    "    upl = len(utt_id_pad[0])\n",
    "    # X =   [ torch.Tensor([u, s]) for u, s in zip(usr_id_pad, sys_id_pad) ] \n",
    "    # print(usr_pad_len, sys_pad_len)\n",
    "    X = torch.zeros( (len(utt_list), upl) )\n",
    "    for i, u in enumerate(utt_id_pad):\n",
    "        X[i, :upl] = u\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [01:25<00:00, 49.23it/s]\n"
     ]
    }
   ],
   "source": [
    "X_= make_X(X,  vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.30, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size, vocab_dict):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim,  padding_idx=0)\n",
    "        # モデルを2つ定義\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True,  bidirectional=True )\n",
    "        # self.lstm2 = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True,  bidirectional=True )\n",
    "        self.hidden2tag = nn.Linear(hidden_dim , tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "        self.vocab_dict = vocab_dict\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #embeds.sizea() = (batch_size × len(sentence) × embedding_dim)\n",
    "\n",
    "        # x : [seq]\n",
    "        # usr_ = x[:, :upl]\n",
    "        # sys_ = x[:, upl:upl+spl]\n",
    "        emb1 = self.word_embeddings(x)\n",
    "        # emb2 = self.word_embeddings(sys_)\n",
    "        _, lstm1_out = self.lstm1(emb1)\n",
    "        # _, lstm2_out = self.lstm1(emb2)\n",
    "        # print(hidden_layer)\n",
    "        # bilstm_out = torch.cat([lstm_out[0][0], lstm_out[0][1]], dim=1)\n",
    "        \n",
    "        # usr_vec = ( lstm1_out[0][0] + lstm1_out[0][1] )\n",
    "        # sys_vec = ( lstm2_out[0][0] + lstm2_out[0][1] )/2\n",
    "\n",
    "        # print(usr_vec.shape, sys_vec.shape)\n",
    "        # print(torch.cat([ usr_vec, sys_vec], dim=1).shape)\n",
    "        tag_space = self.hidden2tag(torch.cat([ lstm1_out[0][0], lstm1_out[0][1]], dim=1 ))\n",
    "        \n",
    "        # y = self.hidden2tag(hidden_layer[0].view(batch_size, -1))\n",
    "\n",
    "        # y = self.hidden2tag(bilstm_out)\n",
    "        y =self.softmax(tag_space)\n",
    "        return y\n",
    "    \n",
    "    def last_context(self, x):\n",
    "        emb1 = self.word_embeddings(x)\n",
    "        # print(emb1.shape)\n",
    "        _, lstm1_out = self.lstm1(emb1)\n",
    "        context = torch.cat([ lstm1_out[0][0], lstm1_out[0][1]], dim=1 )\n",
    "        return context\n",
    "    \n",
    "    def text2context(self, text):\n",
    "        if isinstance(text, str):\n",
    "            utt_id = self._sentence2ids(text, self.vocab_dict)\n",
    "            utt_id_tensor = torch.tensor( [utt_id] , device='cuda:0', dtype=torch.int)\n",
    "            # utt_id_tensor = torch.tensor( [utt_id] , device='cpu', dtype=torch.int)\n",
    "            return self.last_context(utt_id_tensor)\n",
    "        if isinstance(text, list):\n",
    "            X = self._make_X(text, self.vocab_dict)\n",
    "            utt_id_tensor = X.to(torch.int).cuda()\n",
    "            # utt_id_tensor = X.to(torch.int)\n",
    "            return self.last_context(utt_id_tensor)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "        \n",
    "    def _sentence2ids(self, sentence:str, vocab_dict:dict):\n",
    "        doc = self._sentence2formated(sentence)\n",
    "        ids = np.zeros(len(doc))\n",
    "        for i, key in enumerate(doc):\n",
    "            # key = token.orth_\n",
    "            if key in vocab_dict:\n",
    "                ids[i] = vocab_dict[key]\n",
    "            else:\n",
    "                ids[i] = vocab_dict[\"[UNK]\"]\n",
    "        return ids\n",
    "    \n",
    "    def _sentence2formated(self, sen):\n",
    "        return sum( fill_SYMBOL_ONE( sentence2normalize_noun(sen) ), [] )\n",
    "    \n",
    "    def _padding_vector(self, Xseq):\n",
    "        Xseq = [ torch.tensor( xseq[:, None] ) for xseq in Xseq]\n",
    "        Xseq = rnn.pad_sequence(Xseq, batch_first=True)\n",
    "        Xseq = [ torch.flatten(xseq) for xseq in Xseq ] \n",
    "        return Xseq\n",
    "\n",
    "\n",
    "    def _make_X(self, utt_list:list, vocab_dict:dict):\n",
    "        utt_id_list = []\n",
    "        for utt in tqdm( utt_list) :\n",
    "            utt_id = self._sentence2ids(utt, vocab_dict)\n",
    "            utt_id_list.append(utt_id)\n",
    "\n",
    "        utt_id_pad = self._padding_vector(utt_id_list)\n",
    "        upl = len(utt_id_pad[0])\n",
    "        # X =   [ torch.Tensor([u, s]) for u, s in zip(usr_id_pad, sys_id_pad) ] \n",
    "        # print(usr_pad_len, sys_pad_len)\n",
    "        X = torch.zeros( (len(utt_list), upl) )\n",
    "        for i, u in enumerate(utt_id_pad):\n",
    "            X[i, :upl] = u\n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "epoch_ = 300\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_dict)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = EMBEDDING_DIM*2\n",
    "OUTPUT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, vocab_dict)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 56.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"あああ\", \"いいい\"]\n",
    "model.text2context(text).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 1.1895661564813054\n",
      "epoch 100 \t loss 1.0556369136270405\n",
      "epoch 150 \t loss 1.0455451972147785\n",
      "epoch 200 \t loss 1.0339987502047734\n",
      "epoch 250 \t loss 1.0184768556254085\n",
      "epoch 300 \t loss 1.020979551129102\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(epoch_):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        # X_t_tensor = torch.tensor(data[0], device='cuda:0', dtype=torch.int16)\n",
    "        X_t_tensor = data[0].to(torch.int).cuda()\n",
    "        y_t_tensor = data[1].to(torch.long).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        # print(X_t_tensor.shape , y_t_tensor.view(-1,1).shape)\n",
    "\n",
    "        score_ = model(X_t_tensor)\n",
    "        # print(X_t_tensor.shape, score.view(-1,5).shape, y_t_tensor.view(-1,1).shape)\n",
    "        loss_ = loss_function(score_,  y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score_\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0', dtype=torch.int)\n",
    "    y_tensor = torch.tensor(y_test, device='cuda:0', dtype=torch.long)\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[923  44]\n",
      " [ 29 264]]\n",
      "accuracy =  0.942063492063492\n",
      "precision =  0.8571428571428571\n",
      "recall =  0.9010238907849829\n",
      "f1 score =  0.8785357737104824\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/response2/forward_v3.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/response2/\"\n",
    "model_name = \"forward_v3.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response2/forward_v3.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/response2/\"\n",
    "model_name = \"forward_v3.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "model = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, y2 = make_Xy(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_sys = []\n",
    "y = []\n",
    "y2 = []\n",
    "utt_list = []\n",
    "errors = [\"Ignore question\", \"Ignore offer\", \"Ignore proposal\", \"Ignore greeting\"]\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        utt_list.append(ut.utt)\n",
    "        # システム発話で，無視系統のエラー\n",
    "        if ut.is_system() and ut.is_exist_error():\n",
    "        # if ut.is_system():\n",
    "            usr_sys.append( [conv[i-1].utt, ut.utt] )\n",
    "            if ut.is_error_included(errors):\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)\n",
    "            \n",
    "            if conv[i-1].is_type_included(\"質問\"):\n",
    "                y2.append(1)\n",
    "            else:\n",
    "                y2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1386/1386 [00:26<00:00, 52.89it/s]\n"
     ]
    }
   ],
   "source": [
    "Xt= make_X([us[0] for us in usr_sys],  vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1386, 41])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:662: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:915.)\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(Xt, device='cuda:0', dtype=torch.int)\n",
    "    y_pred2 = np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1349, 1386]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-61c2ccfe1864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/MMI/UNI/datatools/analyzer.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(test, pred)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'confusion matrix = \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1349, 1386]"
     ]
    }
   ],
   "source": [
    "score(y, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[863 176]\n",
      " [ 11 299]]\n",
      "accuracy =  0.8613787991104522\n",
      "precision =  0.6294736842105263\n",
      "recall =  0.964516129032258\n",
      "f1 score =  0.7617834394904458\n"
     ]
    }
   ],
   "source": [
    "score(y, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
