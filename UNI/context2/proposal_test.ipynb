{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "error_types = ['Unclear intention', 'Wrong information',\n",
    " 'Ignore question', 'Topic transition error', \n",
    " 'Lack of information', 'Repetition', \n",
    " 'Contradiction', 'Self-contradiction',\n",
    "  'Lack of common sense', 'Semantic error',\n",
    "   'Grammatical error', 'Ignore proposal', \n",
    "   'Ignore offer', 'Lack of sociality', \n",
    "   'Uninterpretable', 'Ignore greeting', \n",
    "   'No-Err']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../response/\")\n",
    "from feature import Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../X_y_data/response/forback1.pickle\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "F1_path = \"../X_y_data/response/\"\n",
    "F1_name = \"forback1.pickle\"\n",
    "featureM1 = DataManager(F1_path)\n",
    "\n",
    "F_fb = featureM1.load_data(F1_name)\n",
    "F_fb.set_preprocessor(Preprocessor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/response/forback_clf.pickle\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model1_path = \"../models/response/\"\n",
    "model1_name = \"forback_clf.pickle\"\n",
    "modelM1 = DataManager(model1_path)\n",
    "\n",
    "clf_fb = modelM1.load_data(model1_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残す形態素\n",
    "pos_sets = set(\"名詞 代名詞 動詞 形容詞 接続詞 連体詞\".split() )\n",
    "def utt2vecter_s(ut):\n",
    "    vector = np.zeros(300)\n",
    "    remains = 0\n",
    "    for token in nlp(ut.utt):\n",
    "        tag = token.tag_.split(\"-\")[0]\n",
    "        if tag in pos_sets:\n",
    "            vector += token.vector\n",
    "            remains += 1\n",
    "    \n",
    "    if remains < 2:\n",
    "        return vector\n",
    "    else:\n",
    "        return vector/remains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utt2vecter_mini(ut, dim=10):\n",
    "    vector = np.zeros(300)\n",
    "    remains = 0\n",
    "    for token in nlp(ut.utt):\n",
    "        tag = token.tag_.split(\"-\")[0]\n",
    "        if tag in pos_sets:\n",
    "            vector += token.vector\n",
    "            remains += 1\n",
    "    \n",
    "    if remains < 2:\n",
    "        return vector[:dim]\n",
    "    else:\n",
    "        return vector[:dim]/remains\n",
    "    # return np.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyknp import Juman\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utt2vecter_BERT(ut):\n",
    "    return Nmodel.encode(ut.utt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def make_Xy_conv(convs, length, errors:list,  dim=300):\n",
    "    X = []\n",
    "    y = []\n",
    "    for conv in tqdm(convs):\n",
    "        # X_ = [ np.zeros(2*dim+2) for _ in range(length-1) ] \n",
    "        X_ = [ np.zeros(dim+2) for _ in range(length-1) ] \n",
    "        prev_vector = np.zeros( dim )\n",
    "        for i, ut in enumerate(conv):\n",
    "\n",
    "            # fb\n",
    "            # 0: 後ろ向き   1: 前向き\n",
    "            f = F_fb.featurization(ut.utt)\n",
    "            fb_proba = clf_fb.predict_proba(f.reshape(1, -1))[0]\n",
    "            # vector = utt2vecter_mini(ut, dim)\n",
    "            if dim==768:\n",
    "                vector = utt2vecter_BERT(ut)\n",
    "            else:\n",
    "                vector = utt2vecter_s(ut)\n",
    "\n",
    "            # x_cat_vector = np.concatenate( [fb_proba, prev_vector-vector, vector] )\n",
    "            x_cat_vector = np.concatenate( [fb_proba, prev_vector-vector] )\n",
    "            prev_vector = vector\n",
    "            X_.append( x_cat_vector )\n",
    "            if not ut.is_system() or ut.is_utt_level_error():\n",
    "                continue\n",
    "            X.append(X_[-length:])\n",
    "            \n",
    "            y.append(1 if ut.is_error_included(errors) else 0)\n",
    "        # break\n",
    "    return np.array(X), np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xy_conv2(convs, length, errors:list,  dim=300):\n",
    "    X = []\n",
    "    y = []\n",
    "    for conv in tqdm(convs):\n",
    "        # X_ = [ np.zeros(2*dim+2) for _ in range(length-1) ] \n",
    "        X_ = [ np.zeros(dim+2) for _ in range(length-1) ] \n",
    "        prev_vector = np.zeros( dim )\n",
    "        for i, ut in enumerate(conv):\n",
    "            if not ut.is_system() or ut.is_utt_level_error():\n",
    "                continue\n",
    "            # fb\n",
    "            # 0: 後ろ向き   1: 前向き\n",
    "            f = F_fb.featurization(ut.utt)\n",
    "            fb_proba = clf_fb.predict_proba(f.reshape(1, -1))[0]\n",
    "            # vector = utt2vecter_mini(ut, dim)\n",
    "            if dim==768:\n",
    "                vector = utt2vecter_BERT(ut)\n",
    "            else:\n",
    "                vector = utt2vecter_s(ut)\n",
    "\n",
    "            # x_cat_vector = np.concatenate( [fb_proba, prev_vector-vector, vector] )\n",
    "            x_cat_vector = np.concatenate( [fb_proba, prev_vector-vector] )\n",
    "            prev_vector = vector\n",
    "            X_.append( x_cat_vector )\n",
    "\n",
    "            if not ut.is_system() or ut.is_utt_level_error():\n",
    "                continue\n",
    "            X.append(X_[-length:])\n",
    "            \n",
    "            y.append(1 if ut.is_error_included(errors) else 0)\n",
    "        # break\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [20:29<00:00,  6.15s/it]\n"
     ]
    }
   ],
   "source": [
    "errors = [\"Topic transition error\", \"Unclear intention\", \"Lack of information\"]\n",
    "# errors = errorprint(errors)\n",
    "emb_dim = 768\n",
    "X, _ = make_Xy_conv(convs, length, errors, dim=emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 97906.26it/s]\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "errors = [\"Topic transition error\", \"Unclear intention\", \"Lack of information\"]\n",
    "# errors = errors[:1]\n",
    "for conv in tqdm(convs):\n",
    "    for i, ut in enumerate(conv):\n",
    "        if not ut.is_system() or ut.is_utt_level_error():\n",
    "                continue\n",
    "        y.append(1 if ut.is_error_included(errors) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../X_y_data/context/topic_proposal_bert1.pickle\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../X_y_data/context/\"\n",
    "data_name = \"topic_proposal_bert1.pickle\"\n",
    "dataM = DataManager(data_path)\n",
    "dataM.save_data(data_name, [X, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size, batch_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True, bidirectional=True )\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        # self.softmax = \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        _, hidden_layer = self.lstm(x)\n",
    "        # print(hidden_layer)\n",
    "        bilstm_out = torch.cat([hidden_layer[0][0], hidden_layer[0][1]], dim=1)\n",
    "        # y = self.hidden2tag(hidden_layer[0].view(batch_size, -1))\n",
    "\n",
    "        y = self.hidden2tag(bilstm_out)\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450\n",
      "1, 2, 5, 10, 25, 29, 50, 58, 145, 290, 725, 1450, "
     ]
    }
   ],
   "source": [
    "X_train = X_train[:-1]\n",
    "y_train = y_train[:-1]\n",
    "leng = len(y_train)\n",
    "print(leng)\n",
    "for i, v in enumerate(y_train):\n",
    "    if leng %(i+1) == 0:\n",
    "        print(i+1, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 145\n",
    "epoch_ = 600\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = emb_dim+2\n",
    "HIDDEN_DIM = emb_dim//2\n",
    "\n",
    "# EMBEDDING_DIM = 2*emb_dim+2\n",
    "# HIDDEN_DIM = emb_dim\n",
    "\n",
    "OUTPUT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, BATCH_SIZE)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 0.33530114591121674\n",
      "epoch 100 \t loss 0.05293357349000871\n",
      "epoch 150 \t loss 0.030125949706416577\n",
      "epoch 200 \t loss 0.027484692283906043\n",
      "epoch 250 \t loss 0.02378037929884158\n",
      "epoch 300 \t loss 0.021934577758656815\n",
      "epoch 350 \t loss 0.022958412540901918\n",
      "epoch 400 \t loss 0.020873499874142\n",
      "epoch 450 \t loss 0.02159672305060667\n",
      "epoch 500 \t loss 0.021209194761468098\n",
      "epoch 550 \t loss 0.01991285672193044\n",
      "epoch 600 \t loss 0.019997238403448137\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "# print(\"error[{0}]\".format(error_types[error_i]))\n",
    "for epoch in range(epoch_):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        X_t_tensor = torch.tensor(data[0], device='cuda:0').float()\n",
    "        # y_t_tensor = torch.tensor(data[1].reshape(batch_size, 1), device='cuda:0').float()\n",
    "        y_t_tensor = torch.tensor(data[1], device='cuda:0').long()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        # print(X_t_tensor.shape)\n",
    "\n",
    "        score = model(X_t_tensor)\n",
    "        loss_ = loss_function(score, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "    # if all_loss <= loss_border:\n",
    "    #     print(\"loss was under border(={0}) : train end\".format(loss_border))\n",
    "    #     break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[151  78]\n",
      " [ 62  72]]\n",
      "accuracy =  0.6143250688705234\n",
      "precision =  0.48\n",
      "recall =  0.5373134328358209\n",
      "f1 score =  0.5070422535211268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
