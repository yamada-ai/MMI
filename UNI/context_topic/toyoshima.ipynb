{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_path = \"../../corpus/w2v/\"\n",
    "# fasttext\n",
    "# https://qiita.com/Hironsan/items/513b9f93752ecee9e670\n",
    "w2v_name =  \"dep-ja-300dim\"\n",
    "w2v_name =  \"model.vec\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_path+w2v_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsv_dim = w2v_model[\"あ\"].shape[0]\n",
    "add_keys = [\"FOS\", \"EOS\", \"[SEP]\", \"[UNK]\", \"[NONE]\"]\n",
    "add_weights = [np.random.randn(wsv_dim) for _ in range(len(add_keys))]\n",
    "add_weights = [ v/np.linalg.norm(v) for v in add_weights ]\n",
    "SYMBOL_w2v = dict(zip(add_keys, add_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/context_topic/toyoshima_symbol.pickle\n"
     ]
    }
   ],
   "source": [
    "symbol_path = \"../models/context_topic/\"\n",
    "symbol_name = \"toyoshima_symbol.pickle\"\n",
    "symbolM = DataManager(symbol_path)\n",
    "symbolM.save_data(symbol_name, SYMBOL_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyoshima_Xy_str(convs):\n",
    "    errors = [\"Topic transition error\"]\n",
    "    X_str = []\n",
    "    y = []\n",
    "    for conv in convs:\n",
    "        for i, ut in enumerate( conv ) :\n",
    "            if ut.is_system() and not ut.is_utt_level_error():\n",
    "                X_str.append( [conv[i-1].utt, ut.utt]  )\n",
    "                if ut.is_error_included(errors):\n",
    "                    y.append(1)\n",
    "                else:\n",
    "                    y.append(0)\n",
    "    return X_str, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_str, y = toyoshima_Xy_str(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyoshima_set = set(\"NOUN PROPN VERB ADJ\".split())\n",
    "\n",
    "def w2v(word, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    if word in SYMBOL_w2v:\n",
    "        vector = SYMBOL_w2v[word]\n",
    "    elif word in w2v_model:\n",
    "        vector = w2v_model[word]\n",
    "    else:\n",
    "        vector = SYMBOL_w2v[\"[UNK]\"]\n",
    "    return vector\n",
    "\n",
    "def filtering(doc, filter_set):\n",
    "    left = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in filter_set:\n",
    "            left.append(token.lemma_)\n",
    "    return left if len(left)>0 else [\"[NONE]\"]\n",
    "\n",
    "def doc2vec(doc, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    left = filtering(doc, toyoshima_set)\n",
    "    return np.mean([ w2v(w, w2v_model, SYMBOL_w2v) for w in left], axis=0)\n",
    "\n",
    "# 副詞など，ほぼすべて\n",
    "def doc2vec2(doc, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    left = filtering(doc, independent_set)\n",
    "    return np.mean([ w2v(w, w2v_model, SYMBOL_w2v) for w in left], axis=0)\n",
    "\n",
    "def sentence2formated(sen, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    docs = sentence2docs(sen, sents_span=False)\n",
    "    vector = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i==0:\n",
    "            prev_vector = doc2vec2(doc, w2v_model, SYMBOL_w2v)\n",
    "        else:\n",
    "            current_vector = doc2vec2(doc, w2v_model, SYMBOL_w2v)\n",
    "            diff_vec = np.abs(prev_vector-current_vector)\n",
    "            norm = np.linalg.norm(diff_vec)\n",
    "            if norm==0:\n",
    "                norm = 1            \n",
    "            vector.append( diff_vec/norm )\n",
    "            prev_vector = current_vector\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1584/1584 [00:48<00:00, 32.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X = []\n",
    "for x_str in tqdm( X_str ):\n",
    "    feature = sentence2formated(x_str, w2v_model, SYMBOL_w2v)[0]\n",
    "    X.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.30, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# clf = AdaBoostClassifier()\n",
    "clf = svm.SVC(kernel='rbf', gamma =0.0001, C=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100000, gamma=0.0001)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[397  29]\n",
      " [ 48   2]]\n",
      "accuracy =  0.8382352941176471\n",
      "precision =  0.06451612903225806\n",
      "recall =  0.04\n",
      "f1 score =  0.04938271604938271\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
