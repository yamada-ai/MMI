{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../../corpus/SNLI/\"\n",
    "data_name = \"dev_sentence.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(corpus_path+data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pre</th>\n",
       "      <th>hypo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>家の前の雪の山の前に立っている数人の人と、シャベルを使っている人。</td>\n",
       "      <td>マイアミの暑い夏の日です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>人が２頭の馬の間にひざまずいている</td>\n",
       "      <td>２頭の牛の間に人が立っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>人は森の中の崖に登り、他の人は見ています。</td>\n",
       "      <td>人が森の中の木に登る。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>男と女が丘の上を歩きます。</td>\n",
       "      <td>男と女が座っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>３人、１人は床に座ってギターを弾き、２人はソファでゲームをします。</td>\n",
       "      <td>数人がビーチに座っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>neutral</td>\n",
       "      <td>バセットハウンドは、男と女の前の路地の戸口に縛られています。</td>\n",
       "      <td>それは彼らの犬です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ローラーダービーの前にストレッチ。</td>\n",
       "      <td>競争の前にストレッチをしている人もいます。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>neutral</td>\n",
       "      <td>アクロバティックな動きを実行するステージ上の２人の芸能人。</td>\n",
       "      <td>２人の芸能人が異常に大勢の観客のためにアクロバットを行っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>neutral</td>\n",
       "      <td>バスケットボールコートの２人の男性が１人は白で、もう１人は青で、白の選手はチームメイトが見な...</td>\n",
       "      <td>男性はバスケットボールトーナメントでプレーしています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>neutral</td>\n",
       "      <td>バスケットボールコートでバスケットボールをプレーする２人の若い男性。</td>\n",
       "      <td>高校の新入生は、大学を目指して練習します。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3916 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                                pre  \\\n",
       "0     contradiction                  家の前の雪の山の前に立っている数人の人と、シャベルを使っている人。   \n",
       "1     contradiction                                  人が２頭の馬の間にひざまずいている   \n",
       "2     contradiction                              人は森の中の崖に登り、他の人は見ています。   \n",
       "3     contradiction                                      男と女が丘の上を歩きます。   \n",
       "4     contradiction                  ３人、１人は床に座ってギターを弾き、２人はソファでゲームをします。   \n",
       "...             ...                                                ...   \n",
       "3911        neutral                     バセットハウンドは、男と女の前の路地の戸口に縛られています。   \n",
       "3912        neutral                                  ローラーダービーの前にストレッチ。   \n",
       "3913        neutral                      アクロバティックな動きを実行するステージ上の２人の芸能人。   \n",
       "3914        neutral  バスケットボールコートの２人の男性が１人は白で、もう１人は青で、白の選手はチームメイトが見な...   \n",
       "3915        neutral                 バスケットボールコートでバスケットボールをプレーする２人の若い男性。   \n",
       "\n",
       "                                   hypo  \n",
       "0                         マイアミの暑い夏の日です。  \n",
       "1                      ２頭の牛の間に人が立っています。  \n",
       "2                           人が森の中の木に登る。  \n",
       "3                           男と女が座っています。  \n",
       "4                        数人がビーチに座っています。  \n",
       "...                                 ...  \n",
       "3911                         それは彼らの犬です。  \n",
       "3912              競争の前にストレッチをしている人もいます。  \n",
       "3913  ２人の芸能人が異常に大勢の観客のためにアクロバットを行っています。  \n",
       "3914        男性はバスケットボールトーナメントでプレーしています。  \n",
       "3915              高校の新入生は、大学を目指して練習します。  \n",
       "\n",
       "[3916 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entailment       1432\n",
       "neutral          1328\n",
       "contradiction    1156\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pre</th>\n",
       "      <th>hypo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>家の前の雪の山の前に立っている数人の人と、シャベルを使っている人。</td>\n",
       "      <td>マイアミの暑い夏の日です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>人が２頭の馬の間にひざまずいている</td>\n",
       "      <td>２頭の牛の間に人が立っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>人は森の中の崖に登り、他の人は見ています。</td>\n",
       "      <td>人が森の中の木に登る。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>男と女が丘の上を歩きます。</td>\n",
       "      <td>男と女が座っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>３人、１人は床に座ってギターを弾き、２人はソファでゲームをします。</td>\n",
       "      <td>数人がビーチに座っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>neutral</td>\n",
       "      <td>バセットハウンドは、男と女の前の路地の戸口に縛られています。</td>\n",
       "      <td>それは彼らの犬です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ローラーダービーの前にストレッチ。</td>\n",
       "      <td>競争の前にストレッチをしている人もいます。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>neutral</td>\n",
       "      <td>アクロバティックな動きを実行するステージ上の２人の芸能人。</td>\n",
       "      <td>２人の芸能人が異常に大勢の観客のためにアクロバットを行っています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>neutral</td>\n",
       "      <td>バスケットボールコートの２人の男性が１人は白で、もう１人は青で、白の選手はチームメイトが見な...</td>\n",
       "      <td>男性はバスケットボールトーナメントでプレーしています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>neutral</td>\n",
       "      <td>バスケットボールコートでバスケットボールをプレーする２人の若い男性。</td>\n",
       "      <td>高校の新入生は、大学を目指して練習します。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3916 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                                pre  \\\n",
       "0     contradiction                  家の前の雪の山の前に立っている数人の人と、シャベルを使っている人。   \n",
       "1     contradiction                                  人が２頭の馬の間にひざまずいている   \n",
       "2     contradiction                              人は森の中の崖に登り、他の人は見ています。   \n",
       "3     contradiction                                      男と女が丘の上を歩きます。   \n",
       "4     contradiction                  ３人、１人は床に座ってギターを弾き、２人はソファでゲームをします。   \n",
       "...             ...                                                ...   \n",
       "3911        neutral                     バセットハウンドは、男と女の前の路地の戸口に縛られています。   \n",
       "3912        neutral                                  ローラーダービーの前にストレッチ。   \n",
       "3913        neutral                      アクロバティックな動きを実行するステージ上の２人の芸能人。   \n",
       "3914        neutral  バスケットボールコートの２人の男性が１人は白で、もう１人は青で、白の選手はチームメイトが見な...   \n",
       "3915        neutral                 バスケットボールコートでバスケットボールをプレーする２人の若い男性。   \n",
       "\n",
       "                                   hypo  \n",
       "0                         マイアミの暑い夏の日です。  \n",
       "1                      ２頭の牛の間に人が立っています。  \n",
       "2                           人が森の中の木に登る。  \n",
       "3                           男と女が座っています。  \n",
       "4                        数人がビーチに座っています。  \n",
       "...                                 ...  \n",
       "3911                         それは彼らの犬です。  \n",
       "3912              競争の前にストレッチをしている人もいます。  \n",
       "3913  ２人の芸能人が異常に大勢の観客のためにアクロバットを行っています。  \n",
       "3914        男性はバスケットボールトーナメントでプレーしています。  \n",
       "3915              高校の新入生は、大学を目指して練習します。  \n",
       "\n",
       "[3916 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models ,losses\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers.losses import TripletDistanceMetric, SoftmaxLoss\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from sentence_transformers.readers import TripletReader\n",
    "from sentence_transformers.datasets import SentencesDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "label2id = dict( zip(label, range(len(label))) )\n",
    "\n",
    "def make_dataset_snli(df, max_n = 300):\n",
    "    X = []\n",
    "    each_label_num = [0, 0 ,0]\n",
    "    for la, pre, hypo in zip(df.label, df.pre, df.hypo):\n",
    "        if each_label_num[label2id[la]] >= max_n:\n",
    "            continue\n",
    "        X.append( InputExample(texts=[pre, hypo], label=label2id[la] ) )\n",
    "        each_label_num[label2id[la]] += 1\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_dataset_snli(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, train_size=0.8, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] : (768,)\n",
      "[1] : (768,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "\n",
    "transformer = models.Transformer('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "pooling = models.Pooling(transformer.get_word_embedding_dimension(),    \n",
    "  pooling_mode_mean_tokens=True,\n",
    "  pooling_mode_cls_token=False, \n",
    "  pooling_mode_max_tokens=False\n",
    ")\n",
    "model = SentenceTransformer(modules=[transformer, pooling])\n",
    "\n",
    "sentences = ['吾輩は猫である',  '本日は晴天なり']\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "for i, embedding in enumerate(embeddings):\n",
    "  print(\"[%d] : %s\" % (i, embedding.shape, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "NUM_EPOCHS = 3\n",
    "EVAL_STEPS = 1000\n",
    "WARMUP_STEPS = int(len(X_train) // BATCH_SIZE * 0.1) \n",
    "OUTPUT_PATH = \"../../corpus/sbert_snli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SentencesDataset(X_train, model=model)\n",
    "train_dataloader = DataLoader(train_data, shuffle=True,  batch_size=BATCH_SIZE)\n",
    "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=len(label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ab9b4340df95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0mevaluation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEVAL_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWARMUP_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m          \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m          )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mloss_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_objectives\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mloss_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mloss_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m9999999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "         epochs=NUM_EPOCHS,\n",
    "         evaluation_steps=EVAL_STEPS,\n",
    "         warmup_steps=WARMUP_STEPS,\n",
    "         output_path=OUTPUT_PATH\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
