{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../eval_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_sys = []\n",
    "y = []\n",
    "utt_list = []\n",
    "errors = [\"Ignore question\", \"Ignore offer\", \"Ignore proposal\", \"Ignore greeting\"]\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        utt_list.append(ut.utt)\n",
    "        # システム発話で，無視系統のエラー\n",
    "        if ut.is_system() and ut.is_exist_error() and not ut.is_utt_level_error():\n",
    "        # if ut.is_system():\n",
    "            usr_sys.append( [conv[i-1].utt, ut.utt] )\n",
    "            if ut.is_error_included(errors):\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../X_y_data/base/vocab_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "vocab_path = \"../X_y_data/base/\"\n",
    "vocab_name = \"vocab_dict.pickle\"\n",
    "vocabM = DataManager(vocab_path)\n",
    "vocab_dict = vocabM.load_data(vocab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2ids(sentence:str, vocab_dict:dict):\n",
    "    doc = nlp(sentence)\n",
    "    ids = np.zeros(len(doc))\n",
    "    for i, token in enumerate(doc):\n",
    "        key = token.orth_\n",
    "        if key in vocab_dict:\n",
    "            ids[i] = vocab_dict[key]\n",
    "        else:\n",
    "            ids[i] = vocab_dict[\"[UNK]\"]\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "def padding_vector(Xseq):\n",
    "    Xseq = [ torch.tensor( xseq[:, None] ) for xseq in Xseq]\n",
    "    Xseq = rnn.pad_sequence(Xseq, batch_first=True)\n",
    "    Xseq = [ torch.flatten(xseq) for xseq in Xseq ] \n",
    "    return Xseq\n",
    "\n",
    "\n",
    "def make_X(usr_sys:list, vocab_dict:dict):\n",
    "    usr_id_list = []\n",
    "    sys_id_list = []\n",
    "    for turn in tqdm( usr_sys ) :\n",
    "        usr_id = sentence2ids(turn[0], vocab_dict)\n",
    "        usr_id_list.append(usr_id)\n",
    "\n",
    "        sys_id = sentence2ids(turn[1], vocab_dict)\n",
    "        sys_id_list.append(sys_id)\n",
    "    \n",
    "    # usr_id_pad = rnn.pad_sequence(torch.Tensor( usr_id_list) , batch_first=True)\n",
    "    # sys_id_pad = rnn.pad_sequence(torch.Tensor( sys_id_list), batch_first=True)\n",
    "    usr_id_pad = padding_vector(usr_id_list)\n",
    "    sys_id_pad = padding_vector(sys_id_list)\n",
    "\n",
    "    usr_pad_len = len(usr_id_pad[0])\n",
    "    sys_pad_len = len(sys_id_pad[0])\n",
    "    # X =   [ torch.Tensor([u, s]) for u, s in zip(usr_id_pad, sys_id_pad) ] \n",
    "    # print(usr_pad_len, sys_pad_len)\n",
    "    X = torch.zeros( (len(usr_sys), usr_pad_len+sys_pad_len) )\n",
    "    for i, (u, s) in enumerate( zip(usr_id_pad, sys_id_pad) ):\n",
    "        # print(i, u, s)\n",
    "        X[i, :usr_pad_len] = u\n",
    "        X[i, usr_pad_len: usr_pad_len+sys_pad_len] = s\n",
    "    return X, usr_pad_len, sys_pad_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 976/976 [00:20<00:00, 47.09it/s]\n"
     ]
    }
   ],
   "source": [
    "X, upl, spl = make_X(usr_sys, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size, batch_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim,  padding_idx=0)\n",
    "        # モデルを2つ定義\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True,  bidirectional=True )\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True,  bidirectional=True )\n",
    "        self.hidden2tag = nn.Linear(hidden_dim , tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, x, upl, spl):\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "\n",
    "        # x : [seq]\n",
    "        usr_ = x[:, :upl]\n",
    "        sys_ = x[:, upl:upl+spl]\n",
    "        emb1 = self.word_embeddings(usr_)\n",
    "        emb2 = self.word_embeddings(sys_)\n",
    "        _, lstm1_out = self.lstm1(emb1)\n",
    "        _, lstm2_out = self.lstm1(emb2)\n",
    "        # print(hidden_layer)\n",
    "        # bilstm_out = torch.cat([lstm_out[0][0], lstm_out[0][1]], dim=1)\n",
    "        \n",
    "        usr_vec = ( lstm1_out[0][0] + lstm1_out[0][1] )/2 \n",
    "        sys_vec = ( lstm2_out[0][0] + lstm2_out[0][1] )/2\n",
    "\n",
    "        # print(usr_vec.shape, sys_vec.shape)\n",
    "        # print(torch.cat([ usr_vec, sys_vec], dim=1).shape)\n",
    "        tag_space = self.hidden2tag(torch.cat([ usr_vec, sys_vec], dim=1 ))\n",
    "        \n",
    "        # y = self.hidden2tag(hidden_layer[0].view(batch_size, -1))\n",
    "\n",
    "        # y = self.hidden2tag(bilstm_out)\n",
    "        y =self.softmax(tag_space)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/base/\"\n",
    "model_name = \"responce_form.pickle\"\n",
    "modelM = DataManager(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/base/responce_form.pickle\n"
     ]
    }
   ],
   "source": [
    "model = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:662: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:915.)\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X, device='cuda:0', dtype=torch.int)\n",
    "    y_tensor = torch.tensor(y, device='cuda:0', dtype=torch.long)\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor, upl, spl).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[582  40]\n",
      " [ 74 280]]\n",
      "accuracy =  0.8831967213114754\n",
      "precision =  0.875\n",
      "recall =  0.7909604519774012\n",
      "f1 score =  0.830860534124629\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ベースラインつっよ！(全データ)\n",
    "\n",
    "        confusion matrix = \n",
    "        [[955  77]\n",
    "        [ 74 280]]\n",
    "        accuracy =  0.8910533910533911\n",
    "        precision =  0.7843137254901961\n",
    "        recall =  0.7909604519774012\n",
    "        f1 score =  0.7876230661040786\n",
    "\n",
    "- 発話レベルエラーを除く理想値\n",
    "\n",
    "        confusion matrix = \n",
    "        [[582  40]\n",
    "        [ 74 280]]\n",
    "        accuracy =  0.8831967213114754\n",
    "        precision =  0.875\n",
    "        recall =  0.7909604519774012\n",
    "        f1 score =  0.830860534124629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
