{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = []\n",
    "utt_list = []\n",
    "errors = [\"Unclear intention\", \"Topic transition error\", \"Lack of information\"]\n",
    "for conv in convs:\n",
    "    # utt_list_conv = [\"\"]*5\n",
    "    utt_list_conv = []\n",
    "    for i, ut in enumerate( conv ) :\n",
    "        utt_list_conv.append(ut.utt)\n",
    "        # システム発話で，[文脈-形式]のエラー\n",
    "        if ut.is_system() and ut.is_exist_error():\n",
    "        # if ut.is_system():\n",
    "            # usr_sys.append( [conv[i-1].utt, ut.utt] )\n",
    "            utt_list.append( utt_list_conv[-5:] )\n",
    "            if ut.is_error_included(errors):\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_path = \"../../corpus/w2v/\"\n",
    "# fasttext\n",
    "# https://qiita.com/Hironsan/items/513b9f93752ecee9e670\n",
    "w2v_name =  \"dep-ja-300dim\"\n",
    "w2v_name =  \"model.vec\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_path+w2v_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsv_dim = w2v_model[\"あ\"].shape[0]\n",
    "add_keys = [\"FOS\", \"EOS\", \"[SEP]\", \"[UNK]\"]\n",
    "add_weights = [np.random.randn(wsv_dim) for _ in range(len(add_keys))]\n",
    "add_weights = [ v/np.linalg.norm(v) for v in add_weights ]\n",
    "SYMBOL_w2v = dict(zip(add_keys, add_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_path = \"../models/base/\"\n",
    "symbol_name = \"context_symbol.pickle\"\n",
    "symbolM = DataManager(symbol_path)\n",
    "symbolM.save_data(symbol_name, SYMBOL_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def w2v(word, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    # 形態素が登録されていたとき\n",
    "    \n",
    "    if word in SYMBOL_w2v:\n",
    "        vector = SYMBOL_w2v[word]\n",
    "    elif word in w2v_model:\n",
    "        vector = w2v_model[word]\n",
    "    else:\n",
    "        vector = SYMBOL_w2v[\"[UNK]\"]\n",
    "    return torch.from_numpy(vector)\n",
    "\n",
    "def sentence2formated(sen, w2v_model, SYMBOL_w2v):\n",
    "    normal = sentence2morpheme(sen, sents_span=False)\n",
    "\n",
    "    # 1文だけ\n",
    "    if len(normal) < 2:\n",
    "        formated =  fill_SYMBOL_ONE(normal)[0]\n",
    "    else:\n",
    "        normal_sep = fill_SYMBOL_SEP(normal)\n",
    "        formated =  fill_SYMBOL_ONE( [sum( normal_sep, [] )] )[0]\n",
    "    \n",
    "    return  torch.stack( [w2v(w, w2v_model, SYMBOL_w2v) for w in formated] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 300])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [\"aa\", \"bb\"] -> [\"FOS\", \"aa\", \"[SEP]\", \"bb\", \"EOS\"]\n",
    "sentence2formated([\"aa\", \"bb\"],  w2v_model, SYMBOL_w2v ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.utils.rnn as rnn\n",
    "\n",
    "# def padding_vector(Xseq):\n",
    "#     Xseq = [ torch.tensor( xseq[:, None] ) for xseq in Xseq]\n",
    "#     Xseq = rnn.pad_sequence(Xseq, batch_first=True)\n",
    "#     Xseq = [ torch.flatten(xseq) for xseq in Xseq ] \n",
    "#     return Xseq\n",
    "\n",
    "\n",
    "def make_X(utt_list:list, w2v_model, SYMBOL_w2v):\n",
    "    utt_morp_list = []\n",
    "    for utt in tqdm( utt_list) :\n",
    "        # [\"FOS\", \"aa\", \"[SEP]\", \"bb\", \"EOS\"] : 1データ\n",
    "        utt_morp = sentence2formated(utt, w2v_model, SYMBOL_w2v)\n",
    "        utt_morp_list.append(utt_morp)\n",
    "\n",
    "    X = rnn.pad_sequence(utt_morp_list, batch_first=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [01:38<00:00, 10.09it/s]\n"
     ]
    }
   ],
   "source": [
    "X_= make_X(utt_list, w2v_model, SYMBOL_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_, y,  test_size=0.30, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size, w2v_model, SYMBOL_w2v):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # モデルを2つ定義\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True,  bidirectional=True )\n",
    "        # self.lstm2 = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True,  bidirectional=True )\n",
    "        self.xtoy_2 = nn.Linear(embedding_dim*3 , hidden_dim)\n",
    "        self.y3toy = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "        self.w2v_model = w2v_model\n",
    "        self.SYMBOL_w2v = SYMBOL_w2v\n",
    "    \n",
    "    def pooling(self, A):\n",
    "        # A : dim3\n",
    "        # pooled = []\n",
    "        b_len = len(A)\n",
    "        f_len = len(A[0][0])\n",
    "        pooled = torch.zeros((b_len, f_len)).cuda()\n",
    "        for i, batch in enumerate( A ):\n",
    "            for j in range(f_len):\n",
    "                # batch_pooled.append( A[i, torch.argmax(A[i, :, j]), j] )\n",
    "                pooled[i, j] = A[i, torch.argmax(A[i, :, j]), j]\n",
    "        return pooled\n",
    "\n",
    "    def pooling_2(self, A):\n",
    "        # A : dim3\n",
    "        if len(A.shape) == 2:\n",
    "            A = torch.stack([A])\n",
    "        b_len = len(A)\n",
    "        seq_len = len(A[0])\n",
    "        m = nn.MaxPool1d(seq_len, stride=seq_len)\n",
    "        B = A.permute((0, 2, 1))\n",
    "        return m(B).reshape(b_len, -1)\n",
    "    \n",
    "    def forward(self, e):\n",
    "        \n",
    "        out, hc = self.bilstm(e)\n",
    "        x = torch.cat([ out, e], dim=2 )\n",
    "        y_2 = self.tanh( self.xtoy_2(x) )\n",
    "        y_3 = self.pooling_2(y_2)\n",
    "        y = self.softmax( self.y3toy(y_3) )\n",
    "        return y\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "epoch_ = 150\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = len(vocab_dict)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = EMBEDDING_DIM*2\n",
    "OUTPUT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, w2v_model, SYMBOL_w2v)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      " 17%|█▋        | 50/300 [03:20<16:45,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 0.00019619047725427663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [06:47<15:32,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 \t loss 1.3646743695971963e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [10:13<10:10,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 \t loss 3.478404494217102e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/300 [13:35<06:30,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 \t loss 0.0024220320156018715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 202/300 [13:43<06:39,  4.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-12ca69434fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0;31m# again, normally you would NOT do 300 epochs, it is toy data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# X_t_tensor = torch.tensor(data[0], device='cuda:0', dtype=torch.int16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# X_tens= data[0].to(torch.int).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm( range(epoch_) ) :  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        # X_t_tensor = torch.tensor(data[0], device='cuda:0', dtype=torch.int16)\n",
    "        # X_tens= data[0].to(torch.int).cuda()\n",
    "        # y_tens = data[1].to(torch.long).cuda()\n",
    "        X_tens= data[0].float().cuda()\n",
    "        y_tens = data[1].to(torch.long).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        score = model(X_tens)\n",
    "        # print(X_t_tensor.shape, score.view(-1,5).shape, y_t_tensor.view(-1,1).shape)\n",
    "        loss_ = loss_function(score,  y_tens)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dce153d12419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, device='cuda:0', dtype=torch.long)\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[ 52  54]\n",
      " [ 32 160]]\n",
      "accuracy =  0.7114093959731543\n",
      "precision =  0.7476635514018691\n",
      "recall =  0.8333333333333334\n",
      "f1 score =  0.7881773399014778\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/base/context_form.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/base/\"\n",
    "model_name = \"context_form.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(60).view(5, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(A):\n",
    "    # A : dim3\n",
    "    # pooled = []\n",
    "    b_len = len(A)\n",
    "    f_len = len(A[0][0])\n",
    "    pooled = torch.zeros((b_len, f_len))\n",
    "    for i, batch in enumerate( A ):\n",
    "        for j in range(f_len):\n",
    "            # batch_pooled.append( A[i, torch.argmax(A[i, :, j]), j] )\n",
    "            pooled[i, j] = A[i, torch.argmax(A[i, :, j]), j]\n",
    "    return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(8), tensor(9), tensor(10), tensor(11)],\n",
       " [tensor(20), tensor(21), tensor(22), tensor(23)],\n",
       " [tensor(32), tensor(33), tensor(34), tensor(35)],\n",
       " [tensor(44), tensor(45), tensor(46), tensor(47)],\n",
       " [tensor(56), tensor(57), tensor(58), tensor(59)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled = []\n",
    "f_len = len(A[0][0])\n",
    "for i, batch in enumerate( A ):\n",
    "    batch_pooled = []\n",
    "    for j in range(f_len):\n",
    "        batch_pooled.append( A[i, torch.argmax(A[i, :, j]), j] )\n",
    "    # pooled.append(torch.stack(batch_pooled))\n",
    "    pooled.append(batch_pooled)\n",
    "A_ = pooled \n",
    "A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0][2][0] = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [30,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26, 27],\n",
       "         [28, 29, 30, 31],\n",
       "         [32, 33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38, 39],\n",
       "         [40, 41, 42, 43],\n",
       "         [44, 45, 46, 47]],\n",
       "\n",
       "        [[48, 49, 50, 51],\n",
       "         [52, 53, 54, 55],\n",
       "         [56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(30), tensor(9), tensor(10), tensor(11)],\n",
       " [tensor(20), tensor(21), tensor(22), tensor(23)],\n",
       " [tensor(32), tensor(33), tensor(34), tensor(35)],\n",
       " [tensor(44), tensor(45), tensor(46), tensor(47)],\n",
       " [tensor(56), tensor(57), tensor(58), tensor(59)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = torch.tensor(A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[1][2][0] = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30,  9, 10, 11],\n",
       "        [20, 21, 22, 23],\n",
       "        [32, 33, 34, 35],\n",
       "        [44, 45, 46, 47],\n",
       "        [56, 57, 58, 59]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(30), tensor(9), tensor(10), tensor(11)],\n",
       " [tensor(60), tensor(21), tensor(22), tensor(23)],\n",
       " [tensor(32), tensor(33), tensor(34), tensor(35)],\n",
       " [tensor(44), tensor(45), tensor(46), tensor(47)],\n",
       " [tensor(56), tensor(57), tensor(58), tensor(59)]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
