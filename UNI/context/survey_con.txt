話題遷移
https://aclanthology.org/2021.sigdial-1.10/

1. 自然な対話継続のための推移する話題推定
    Sidner の焦点モデルを活用した
        Current Focus  (CF)
            現在の話題
        Alternate Focus List(ALFL)
            候補の話題
        Focus Stack (FS)
            これまでの焦点
    雑談用に適用しているが，その話題が「どうなのか」については言及していない
    名詞句のみを推定している

2. 応答の自然性と話題遷移を考慮した雑談対話システムにおける対話破綻の検出
    コーパスとして使われているのは，話題が明らかに読み取れる発話群のみ
        ゼロ照応・照応解析は多分やってない
    話題遷移をシステム発話・ユーザ発話の差分ベクトルで検出
        明らかな破綻については検出出来るが，
        両発話の名詞が共通している場合のみであったり，ラベルPBのものは
        検出が出来ていない 
            -> ここが狙い目
            共起する単語か否かを計算することが有効？
    
    https://library.naist.jp/mylimedio/dllimedio/showpdf2.cgi/DLPDFR014499_P1-51


3. Dialogue Breakdown Detection based on Estimating Appropriateness of Topic Transition(トピック遷移の適切さの推定に基づく対話破綻の検出)
    　トピック遷移の自然さを捉える特徴を導入することで、従来の手法よりも高い精度で、より類似した分布を持つ対話の破綻を検出することができた。また、大規模対話データを用いて学習したseq2seqに基づく発話の埋め込みベクトルや、質問・応答パターンに頻出する単語ペアが、分布関連指標の改善に有効であることを示した。
    らしい

4. Empirical feature analysis for dialogue breakdown detection
    　チャット指向の対話システムは、対話の崩壊を引き起こすユーザーの発話に対して不適切な応答の発話を生成することがあります。 そのような不適切な発話を検出し、それらを抑制することは、対話の継続をサポートします。 以前の最先端の対話内訳検出器は、対話行為の遷移と発話ペア間の単語ベースの類似性を活用しましたが、これらの機能は、質問応答の適切性またはトピックの単語をほとんど共有しない発話間の関連性を評価するには不十分です。 本論文では、これらの問題を評価するための新しい機能を提案し、対話の内訳検出のパフォーマンスを改善するためのそれらの有効性を調べます。

    　見たかったけど，なんか面倒そうで見られない

情報不足



発話意図不明確



矛盾，自己矛盾
1. I like fish , especially dolphins : Addressing Contradictions in Dialogue Modeling
    https://aclanthology.org/2021.acl-long.134.pdf
    　自然言語理解モデルが一般的な会話の一貫性をどの程度捉えられるかを定量化するために、DialoguE COntradiction DEtection task (DECODE)と、人間と人間、人間とロボットの矛盾した会話を含む新しい会話データセットを導入した。そして、事前に学習したTransformerモデルを用いて矛盾を検出する構造化発話ベースのアプローチと、典型的な非構造化アプローチを比較した。その結果、以下のことが明らかになった。(i)我々が新たに収集したデータセットは、対話領域をカバーすることを目的とした既存のNLIデータに比べて、対話の矛盾検出タスクにスーパーバイズを提供するのに非常に効果的である。また、我々が開発した最適な矛盾検出モデルは、人間の判断とよく相関していることを示し、さらに、最先端の生成チャットボットの自動評価と一貫性の向上の両方に利用できることを示す。

一貫性 : Coherence で検索してよいかもしれないね
2. Evaluating Coherence in Dialogue Systems using Entailment(含意)
    https://arxiv.org/pdf/1806.08044.pdf
    NLI(ニューラル言語推論モデル)をベースにしている．
    BERTを使って，過去の履歴と次の発話を入力して，(帰納，矛盾，中立)を推論
    ・他の会話からのランダムな発話や「わからない」などの一般的な回答が中立的なインスタンスを構成します
        →中立のラベルいるか？これは基本的に破綻だと思うが
    
    
3. Coherence Models for Dialogue
    https://arxiv.org/pdf/1806.08044.pdf
    　会話システムを評価・比較するための標準化された自動評価指標がないため，オープンドメイン対話モデルの進歩が妨げられているのが現状です[3]．現在利用可能な対話評価のための自動指標のほとんどは，使用された単語などの表面的な特徴（BLEU[4]など）に依存しているか，人間の一般的な判断を再現しようとしているか[5]，あるいはタスクベースの対話システムにしか対応していないかのいずれかです[6]
    　

4. Dialogue Coherence Assessment Without Explicit Dialogue Act Labels
    https://arxiv.org/pdf/1908.08486.pdf
    強力なコヒーレンスモデルはエンティティグリッド+対話行為ラベルによって構成されているが，この研究では，対話行為ラベルを同時に学習させるマルチタスク実験を行う．
    ヒーレンス評価の際に明示的なDAラベルの必要性を軽減することができる

5. Don’t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training
    https://aclanthology.org/2020.acl-main.428/
    生成的対話モデルは現在、標準的な最尤トレーニングでは対処できない多くの問題に悩まされています。それらは、（i）文脈からのコピーに過度に依存し、（ii）発話内に繰り返しを含み、（iii）頻繁な単語を使いすぎ、（iv）より深いレベルで、論理的な欠陥を含む世代を生み出す傾向があります。最近導入された可能性の低い損失（Welleck et al。、2019）をこれらのケースに拡張することにより、これらすべての問題にどのように対処できるかを示します。生成された出力を人間の分布に一致するように正規化する適切な損失関数が最初の3つの問題に有効であることを示します。最後の重要な一般的な問題については、モデルがすべきでないことの収集されたデータに可能性を適用することが論理的一貫性を改善するのに効果的であることを示します。より優れた推論能力を備えた生成モデルへの道を開く可能性があります。私たちは、いくつかの対話タスクにわたって私たちのアプローチの有効性を示しています。

    学習方法がイマイチわからなかったが，対話に活用した例として参考になるかも

6. Dialogue Natural Language Inference
    https://aclanthology.org/P19-1363/
    一貫性は、対話モデルが直面する長年の問題です。このホワイトペーパーでは、対話エージェントの一貫性を自然言語推論（NLI）としてフレーム化し、DialogueNLIと呼ばれる新しい自然言語推論データセットを作成します。Dialogue NLIでトレーニングされたモデルを使用して、対話モデルの一貫性を改善できることを示す方法を提案し、対話モデルの一貫性を測定するように設計された一連の評価セットで、人間による評価と自動メトリックを使用して方法を評価します。


