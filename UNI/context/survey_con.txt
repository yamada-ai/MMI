話題遷移
https://aclanthology.org/2021.sigdial-1.10/

1. 自然な対話継続のための推移する話題推定
    Sidner の焦点モデルを活用した
        Current Focus  (CF)
            現在の話題
        Alternate Focus List(ALFL)
            候補の話題
        Focus Stack (FS)
            これまでの焦点
    雑談用に適用しているが，その話題が「どうなのか」については言及していない
    名詞句のみを推定している

2. 応答の自然性と話題遷移を考慮した雑談対話システムにおける対話破綻の検出
    コーパスとして使われているのは，話題が明らかに読み取れる発話群のみ
        ゼロ照応・照応解析は多分やってない
    話題遷移をシステム発話・ユーザ発話の差分ベクトルで検出
        明らかな破綻については検出出来るが，
        両発話の名詞が共通している場合のみであったり，ラベルPBのものは
        検出が出来ていない 
            -> ここが狙い目
            共起する単語か否かを計算することが有効？
    
    https://library.naist.jp/mylimedio/dllimedio/showpdf2.cgi/DLPDFR014499_P1-51


3. Dialogue Breakdown Detection based on Estimating Appropriateness of Topic Transition(トピック遷移の適切さの推定に基づく対話破綻の検出)
    　トピック遷移の自然さを捉える特徴を導入することで、従来の手法よりも高い精度で、より類似した分布を持つ対話の破綻を検出することができた。また、大規模対話データを用いて学習したseq2seqに基づく発話の埋め込みベクトルや、質問・応答パターンに頻出する単語ペアが、分布関連指標の改善に有効であることを示した。
    らしい

4. Empirical feature analysis for dialogue breakdown detection
    　チャット指向の対話システムは、対話の崩壊を引き起こすユーザーの発話に対して不適切な応答の発話を生成することがあります。 そのような不適切な発話を検出し、それらを抑制することは、対話の継続をサポートします。 以前の最先端の対話内訳検出器は、対話行為の遷移と発話ペア間の単語ベースの類似性を活用しましたが、これらの機能は、質問応答の適切性またはトピックの単語をほとんど共有しない発話間の関連性を評価するには不十分です。 本論文では、これらの問題を評価するための新しい機能を提案し、対話の内訳検出のパフォーマンスを改善するためのそれらの有効性を調べます。

    　見たかったけど，なんか面倒そうで見られない


5. Fuzzy Prediction Model to Measure Chatbot Quality of Service
    https://ieeexplore.ieee.org/abstract/document/9494346

    　故障の検出は、会話型システムで一般的な現象であり、システムがユーザーに適切な応答を提供できない場合に参照されます。既存の大学地区 ES 単語の類似性、トピックの遷移、クラスタリングなどのさまざまな機能を使用して内訳を検出します。この論文では、人間の思考と推論という、さまざまな重要な機能に焦点を当てます。この機能を使用して、故障の検出に基づいてチャットボットのサービス品質（CQoS）をモデル化します。したがって、エンドユーザーとチャットボットの観点を考慮して内訳発話を検出することにより、チャットボットのサービス品質を測定するファジー予測ルールベースのフレームワークを紹介します。提案されたファジー論理ベースのモデルで利用される入力は、発話から抽出された複数の有用な特徴です。出力は、サービスの品質に対する各発話の関連性の程度です。いくつかのファジールールが設計されており、目的のCQoS結果を達成するために非ファジー化方法が使用されます。ファジーモデルからの出力に基づいて、ハンドオーバーメカニズムがアクティブになります。提案された型枠を他の最先端モデルで評価します。

情報不足



発話意図不明確



矛盾，自己矛盾
1. I like fish , especially dolphins : Addressing Contradictions in Dialogue Modeling
    https://aclanthology.org/2021.acl-long.134.pdf
    　自然言語理解モデルが一般的な会話の一貫性をどの程度捉えられるかを定量化するために、DialoguE COntradiction DEtection task (DECODE)と、人間と人間、人間とロボットの矛盾した会話を含む新しい会話データセットを導入した。そして、事前に学習したTransformerモデルを用いて矛盾を検出する構造化発話ベースのアプローチと、典型的な非構造化アプローチを比較した。その結果、以下のことが明らかになった。(i)我々が新たに収集したデータセットは、対話領域をカバーすることを目的とした既存のNLIデータに比べて、対話の矛盾検出タスクにスーパーバイズを提供するのに非常に効果的である。また、我々が開発した最適な矛盾検出モデルは、人間の判断とよく相関していることを示し、さらに、最先端の生成チャットボットの自動評価と一貫性の向上の両方に利用できることを示す。

一貫性 : Coherence で検索してよいかもしれないね
2. Evaluating Coherence in Dialogue Systems using Entailment(含意)
    https://arxiv.org/pdf/1806.08044.pdf
    NLI(ニューラル言語推論モデル)をベースにしている．
    BERTを使って，過去の履歴と次の発話を入力して，(帰納，矛盾，中立)を推論
    ・他の会話からのランダムな発話や「わからない」などの一般的な回答が中立的なインスタンスを構成します
        →中立のラベルいるか？これは基本的に破綻だと思うが
    
    
3. Coherence Models for Dialogue
    https://arxiv.org/pdf/1806.08044.pdf
    　会話システムを評価・比較するための標準化された自動評価指標がないため，オープンドメイン対話モデルの進歩が妨げられているのが現状です[3]．現在利用可能な対話評価のための自動指標のほとんどは，使用された単語などの表面的な特徴（BLEU[4]など）に依存しているか，人間の一般的な判断を再現しようとしているか[5]，あるいはタスクベースの対話システムにしか対応していないかのいずれかです[6]
    　

4. Dialogue Coherence Assessment Without Explicit Dialogue Act Labels
    https://arxiv.org/pdf/1908.08486.pdf
    強力なコヒーレンスモデルはエンティティグリッド+対話行為ラベルによって構成されているが，この研究では，対話行為ラベルを同時に学習させるマルチタスク実験を行う．
    ヒーレンス評価の際に明示的なDAラベルの必要性を軽減することができる

5. Don’t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training
    https://aclanthology.org/2020.acl-main.428/
    生成的対話モデルは現在、標準的な最尤トレーニングでは対処できない多くの問題に悩まされています。それらは、（i）文脈からのコピーに過度に依存し、（ii）発話内に繰り返しを含み、（iii）頻繁な単語を使いすぎ、（iv）より深いレベルで、論理的な欠陥を含む世代を生み出す傾向があります。最近導入された可能性の低い損失（Welleck et al。、2019）をこれらのケースに拡張することにより、これらすべての問題にどのように対処できるかを示します。生成された出力を人間の分布に一致するように正規化する適切な損失関数が最初の3つの問題に有効であることを示します。最後の重要な一般的な問題については、モデルがすべきでないことの収集されたデータに可能性を適用することが論理的一貫性を改善するのに効果的であることを示します。より優れた推論能力を備えた生成モデルへの道を開く可能性があります。私たちは、いくつかの対話タスクにわたって私たちのアプローチの有効性を示しています。

    学習方法がイマイチわからなかったが，対話に活用した例として参考になるかも

6. Dialogue Natural Language Inference
    https://aclanthology.org/P19-1363/
    一貫性は、対話モデルが直面する長年の問題です。このホワイトペーパーでは、対話エージェントの一貫性を自然言語推論（NLI）としてフレーム化し、DialogueNLIと呼ばれる新しい自然言語推論データセットを作成します。Dialogue NLIでトレーニングされたモデルを使用して、対話モデルの一貫性を改善できることを示す方法を提案し、対話モデルの一貫性を測定するように設計された一連の評価セットで、人間による評価と自動メトリックを使用して方法を評価します。



7. Addressing Inquiries about History: An Efficient and Practical Framework for Evaluating Open-domain Chatbot Consistency
    https://arxiv.org/pdf/2106.02228.pdf
    優れたオープンドメインのチャットボットは、会話の中で事実や意見について矛盾した回答を提示しないようにする必要があり、これを「一貫性能力」と呼びます。しかし、チャットボットの一貫性能力を評価することは困難です。人間の審査員がわざわざチャットボットと対話して能力をチェックすることは、コストや効率が低く、主観的なバイアスを取り除くことも困難です。本論文では、整合性評価のための効率的かつ実用的なフレームワークであるAddressing Inquiry about History (AIH)を提案する。AIHは会話の段階で、チャットボットが歴史的事実や意見を再宣言するように誘導するために、対話履歴に関する適切な問い合わせに対処しようとするものである。チャットボット同士の会話は、人間とロボットの対話よりも効率的であり、主観的なバイアスを軽減することができます。このようにして、矛盾の可能性が高い回答を含む対話セッションを迅速に得ることができます。矛盾を認識する段階では、人間の審査員または自然言語推論（NLI）モデルを採用して、問い合わせに対する回答が履歴と矛盾しているかどうかを認識します。最後に、矛盾の統計値に基づいてチャットボットをランク付けすることができます。オープンドメインのチャットボットを使った実験では、我々のアプローチが効率的かつ信頼性の高い方法でチャットボットの一貫性能力を評価し、人間の評価と高
    
    い順位相関を得られることを示している。我々はこのフレームワークを公開し、チャットボットの一貫性能力の向上に役立てたいと考えている1。





----------------------
発話ベクトルの差分特徴量を用いた雑談対話システムにおける
破綻した話題遷移の検出
https://ahcweb01.naist.jp/papers/conference/2017/201803_NLP_Toyoshima_1/201803_NLP_Toyoshima_1.paper.pdf


Generative Chat Bot Implementation Using Deep Recurrent Neural Networks and Natural Language Understanding
自然言語理解 NLU のやつかな？

基盤化に基づく修復発話の理解
https://anlp.jp/proceedings/annual_meeting/2005/pdf_dir/D1-4.pdf


特徴を考慮した対話行為推定
https://www.jstage.jst.go.jp/article/jnlp/24/4/24_523/_pdf/-char/ja

