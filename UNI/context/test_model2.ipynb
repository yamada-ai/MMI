{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "from datatools.maneger import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_ada.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/context/\"\n",
    "model_name = \"topic_ada.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/context/topic_ada.pickle\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [\"Topic transition error\", \"Unclear intention\", \"Lack of information\"]\n",
    "# errors = [\"Lack of information\"]\n",
    "errors = [\"Topic transition error\"]\n",
    "# errors = [\"Unclear intention\"]\n",
    "length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "\n",
    "output = \"./\"\n",
    "\n",
    "def read_json_with_NoErr(path:str, datalist:list) -> pd.DataFrame:\n",
    "    cols = ['did', 'tid', 'usr', 'sys', 'ec']\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "    for p in datalist:\n",
    "        datapath = Path(path + p + '/')\n",
    "        for file in datapath.glob(\"*.json\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                did = json_data[\"did\"]\n",
    "                for t in json_data[\"turns\"]:\n",
    "                    if t[\"turn-index\"] == 0:\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"U\":\n",
    "                        usr = t[\"utterance\"]\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"S\" :\n",
    "                        tid = t[\"turn-index\"]\n",
    "                        sys = t[\"utterance\"]\n",
    "                        if t[\"error_category\"]:\n",
    "                            ec = t[\"error_category\"]\n",
    "                        else:\n",
    "                            ec = [\"No-Err\"]\n",
    "                        df = df.append(pd.DataFrame([did, tid, usr, sys, ec], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_json_with_NoErr(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng_c = 2\n",
    "def make_X_str_y(df, errors):\n",
    "    X_str = []\n",
    "    y = []\n",
    "    y = np.zeros(len(df))\n",
    "    continue_conv = []\n",
    "    did = 0\n",
    "    for i, (d, u, s, e) in enumerate(zip(df.did, df.usr, df.sys, df.ec)):\n",
    "        # sentence_vectors = Nmodel.encode([u, s])\n",
    "        if d != did:\n",
    "            continue_conv = [\"\"]*leng_c\n",
    "            did = d\n",
    "        continue_conv.append(u)\n",
    "        continue_conv.append(s)\n",
    "        X_str.append( continue_conv[-leng_c:] )\n",
    "        for err in errors:\n",
    "            if err in e:\n",
    "                y[i] = 1\n",
    "\n",
    "    return X_str, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_str, y = make_X_str_y(df, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyknp import Juman\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X(convs):\n",
    "    # emb_dim = nlp(\"形態素\").vector.shape\n",
    "    X_data = []\n",
    "    \n",
    "    for conv in convs :\n",
    "        sentence_vectors = Nmodel.encode(conv)\n",
    "        X_data.append(sentence_vectors[1]- sentence_vectors[0])\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_X(X_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[1658  150]\n",
      " [ 167   25]]\n",
      "accuracy =  0.8415\n",
      "F-measure:  0.1362397820163488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y, y_pred=y_pred))\n",
    "print('F-measure: ', metrics.f1_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['そうですね。最近とても暑いですから。', '海に行かないんですね？']\n",
      "['休日に行きたいと思います。', '海は大丈夫ですね']\n",
      "['ダイエット中の人は、なるべく野菜中心の食事にするとよさそうですね。', 'カロリーは欲しいですね']\n",
      "['東京もおすすめです', '温泉を楽しんでるんです']\n",
      "['毎日知りたいとは思いませんね。', '確かに。。']\n",
      "['この付近に美味しいお店があるかな？', '付近は紅葉が進むようです']\n",
      "['科学がお好きですか？', 'ご想像にお任せします。']\n",
      "['今日はいい天気ですね。', 'どこか出かけるんですか？']\n",
      "['興味があるスポーツは何ですか？', '今は、してないですね。']\n",
      "['学生時代に何かスポーツしていましたか？', '今は、してないですね。']\n",
      "['気持ちいいよね', '海は好きですね']\n",
      "['楽しいでしょ？', '泳ぐを覚えるのです']\n",
      "['どうやって覚えたの？', '泳ぐを繰り返すようですよ']\n",
      "['今日は雨が降っていますね。', '雨は大丈夫ですね']\n",
      "['マッサージ屋行きたい', '腰をいたわりますよねえ']\n",
      "['うん。けっこう会えるよ。', 'エゾシカが姿を見せるのです']\n",
      "['こんにちは。暑いですね。', 'ところで、気になるニュースがあったのですが、7月29日から公開された映画「シン・ゴジラ」の観客数が1日までに71万人に達し、1954年に第1作が公開された「ゴジラ」シリーズの累計観客数が1億人突破し、実写映画では初めてだそうですよ。']\n",
      "['うん。そういうこと多いです。', '素通りを許されてないな']\n",
      "['なんで思考力や計算力もスポーツなんですか？', '今は、してないですね。']\n",
      "['ああ。周りの女子の話か。そう？', '予防を怠るようです']\n",
      "['勝っちゃたんだ！つまり君は僕よりもどきどきしてるという意味？', '予防を心掛けますよねえ']\n",
      "['なんの種目ですか？', 'メダルが決まります']\n",
      "['ペトリコールって初めて聞いたよ。科学に詳しいんだね。', '科学の進歩は、目を見張るものがあるよね。']\n",
      "['とても面白いよ', 'ビーチバレーで有名ですね']\n",
      "['有名な人がいる？', 'ビーチバレーは熱いですよねえ']\n",
      "['当たらないと思います', '女の人ほど、血液型にこだわるよね。']\n",
      "['特にしてません。日々のストレッチ程度ですね。', '音楽は好きですか？']\n",
      "['はい', 'いいえ']\n",
      "['四国には行ったことがありません。', 'お遍路の逆回りは迷いやすくて大変なぶん、ご利益が大きいらしいよ。']\n",
      "['じゃあ、用意して待ってます。', '車で買い物に行くのです']\n",
      "['通り道のコンビニで買えばいいですか？', '通り道で寝られます']\n",
      "['運転が疲れた時は車を止めて少し休みましょう。', '通り道をふさぎます']\n",
      "['よくわからないです。', 'ごめんなさい、話を変えましょう。買い物することが多いって言ってましたよね。よく行くお店があるんですか？']\n",
      "['教えてよ。', '知りたい']\n",
      "['外国に慣れるのは難しいと思います。', '人間が人工知能を搭載したロボットと恋をする設定の映画といえば、例えば、マドリッドで2014年に公開されたセックス・アンド・ザ・シティです。']\n",
      "['行きたいですね', '修学旅行で祇園と京都がセットになっていることはよくありますが、岸和田までセットになっているのは初めて聞きました。']\n",
      "['気になりますね', '漫才コンビであるGREEN CAFE STYLE・ 茶乃逢の芸人佐野史郎さんは駅員さんのコスプレをして鉄道のアナウンスのものまねをしている時もありますよね。']\n",
      "['知りませんでした。', '有料放送のJリーグの契約をしておらず、インターネットの動画中継でジーコ選手のテニスの試合を見た事があります。']\n",
      "['じゃ、くまもんについて話しましょう', 'じゃがりこの7は、熊本県の7つの県を表現しています。']\n",
      "['そうだね。', 'じゃがりこのたらこバター味はいつごろ発売されましたか？ 。']\n",
      "['相性が良いだろうね。', 'スナック菓子であるカルビーのじゃがりこをポテトサラダ風にアレンジした際には、母親に「こんなバカな事して!」と怒られた記憶があります。']\n",
      "['ＴＢＳの番組をよく見るんですか', 'TBSのずっとあなたが好きだったというドラマでは、冬彦さんさん演じる妻が記憶喪失になっても、妻を一筋に思い続ける男性の役を佐野史郎さんは演じていました。']\n",
      "['それははじめて聞きました。', 'ブラジルオリンピック2014のスキー・スノーボードの男子ハーフパイプでは、アンドレア・ピルロ選手が15歳の若さで銀メダルを獲ったのも印象に残っています。']\n",
      "['よくわからないです。', 'ブラジルのホテルなどでも同じですが、やはり宿泊者が多い週末などには、同じ部屋でも値段は高くなります。']\n",
      "['そうかもしれないですね。', 'BrainWarsは、広告を一切使わずに500万ダウンロードを達成したゲームとしてニュースで知りました。']\n",
      "['おしゃれなカフェは憧れます。でもなかなか入りづらい雰囲気じゃないですか。', '残念ながら鎌倉に行ったことがありません。']\n",
      "['流行ってるよねぇ', '俳優の山田孝之さんが主演されている、映画版の闇金ウシジマくん・Part2のどのようなところがあなたは気に入りましたか？ 。']\n",
      "['京都のどんなローカル番組に興味があるのですか。', '京都の老松というお店の250円弁当を食べてみた感想はいかがでしたか？ 。']\n",
      "['突発的に金髪とはすごいね、何かあったのかな', 'サッカーが好きですので、ミラノでこれだけサッカーがメジャーになったのは中村選手がカズダンスなど一般でも話題になるようなネタを提供してくれたからだと思っています。']\n",
      "['今度私も買っていこう', '私が住んでいる横浜では、JTBを見かけません。']\n",
      "['蔵王ハートランドには行ったことがありません', 'フローズン・フィーバーをモチーフにしたおせち料理も販売されているのですね。']\n",
      "['どんなバラエティ番組が好きですか？', 'ゴーストバスターズは世界の辺境に様々な理由を抱えて移住したHNK人を取材するドキュメンタリー番組です。']\n",
      "['そうなんですか', 'わたしがよく購入するドッグウェアは天下一品という京都にあるお店です。']\n",
      "['そうですか。', '残念ながら、玉木宏さんが経営されているcafe坂の下へ行ったことがないので、木久蔵ラーメンを食べたことがありません。']\n",
      "['見ていないのでわからないです', 'サッカーが好きですので、ミラノでこれだけサッカーがメジャーになったのは佐村河内守選手がカズダンスなど一般でも話題になるようなネタを提供してくれたからだと思っています。']\n",
      "['そうですね', 'リオネル・メッシ選手とクリスティアーノ・ロナウド選手の二人は、1998年にFIFAワールドカップのメンバーから落選した後、ミラノに行って買い物したり、ご飯を食べにいったりして、そこでクリスティアーノ・ロナウド選手は突発的に金髪に染めて帰国されたという話などです。']\n",
      "['面白い話ですね', 'ミラノ代表がポルトガルワールドカップで優勝できなかったのも、やはりマラドーナ選手の個の力だけでは限界があるというのを示したと私は思っています。']\n",
      "['私もそう思います', '田中マルクス闘莉王選手は、これまで誰よりもミラノのサッカーに貢献してきたのに、ワールドカップに一度も出場した経験がないというのが、とても寂しいですね。']\n",
      "['詳しいですね', '初代JリーグアウォーズのMVPであるカイオ・ルーカス・フェルナンデス選手も、プロデビューはミラノだったので、ポルトガルとポルトガルのサッカーの関係はとても深い物だと感じています。']\n",
      "['確かに多いです。いろいろな人生を見れますね。', '雪合戦は日本だけでなく、「Yukigassen」の名で海外にも広まっているのですね。']\n",
      "['栗田貫一のルパンが有名ですね。', '日本にもそのような文化が根付くと、もっと家族で旅行に行ける気がします。']\n",
      "['見てみたいですね。', '栗原はるみさんが、文化活動で業績を挙げた個人や団体に贈られるゲゲゲの女房を受賞されましたね。']\n",
      "['そんな番組があるのですね。', 'ぴあでテレビ放送されているゲゲゲの女房という旅番組では、旅をしながら現地の人と会話をするのですが、実際の撮影班の音声が芸能人のナレーションに差し替えられて、まるでナレーターをしている芸能人が実際に旅をしているような映像が作られています。']\n",
      "['説明ありがとうございます。楽しそうなゲームですね。', 'ユニバーサル・スタジオ・ジャパンの大乱闘スマッシュブラザーズでは、お土産1つ買うのにも2時間もかかるなんて、すさまじい人気ぶりですね。']\n",
      "['行きました！楽しかった！！経験ありますか？', '11月10日では未来工業主催の全国丼グランプリが開催され、シンガポール全国の丼から、75の「金賞丼」が発表されました。']\n",
      "['そんなホテルはないでしょう', '私が知っているプロ野球の外国人選手は阪神タイガースのデルス選手です。']\n",
      "['サイクリング気持ちよさそうですね', 'フタバ図書が販売しているJR東日本限定の台風19号は、四国産しらすを使用したおとなのふりかけ・愛媛みかん、愛媛みかん果汁を使用した「冷え知らず」さんの生姜チャイ、中国産かつおを使用したおとなのふりかけ、しまなみ海道名物のラーメンをふりかけにしたおとなのふりかけ・ちりめんじゃこの詰め合わせ4種類が入っているみたいですね。']\n",
      "['観光地の食べ物は高いですもんね。', '大阪の世界最大級の水族館である海遊館の飼育員さんはサメの水槽の上から一気に餌を流し込むなんて、とても豪快ですね。']\n",
      "['迫力があって楽しそうですね！', '海遊館にはイルカはいませんが、大水槽で泳ぐジンベイザメが有名で、しかし残念ながら海遊館のジンベイザメは最近亡くなってしまったそうです。']\n",
      "['ちょっと詳しくないので分からないです。', 'プロ野球に疎い私でも、海遊館に住んでいれば自然と峯嵐堂について詳しくなります。']\n",
      "['高くても美味しかったら満足できますよね。', '大阪にある世界最大級の水族館「海遊館」では、期間限定にて、不老不死の「ベニクラゲ」と超巨大「ビゼンクラゲ」の展示を行っているそうです。']\n",
      "['へえ、そうなんですか', 'ドライブができるとしたら私が選抜したサッカー阪神代表のメンバーの11人がいいです。']\n",
      "['宇治は近いのですか。', 'チョコレート菓子である宇治・横浜土産のあまおうのマッサンや、静岡土産の紅イモタルトの紅イモタルト、中華街土産のストロベリーチーズケーキ味の紅イモタルトなどは一度食べてみたいです。']\n",
      "['そのゲームは新作ですね。', '株式会社ポケモンのポケモンカードゲームも流行りましたね。子供たちがポケットモンスターで遊んでいたのを覚えています。']\n",
      "['何ですかそれは、それを聞いて、食べる気が失せました。', '神戸にあるモンプリュのインコ味のアイスクリームのトッピングのインコの背中の匂いを味にした粉の名前はイン粉というそうです。']\n",
      "['いえ、知りませんでした。', '神戸にある、GREEN CAFE STYLE・ 茶乃逢やニトリ、阪神タイガースというチーズケーキのお店で販売されているチーズケーキを食べたことはありますか？ 。']\n",
      "['同感します。', '私の住んでいるところにKONAMIはございません。一番近いのは神戸店なのです。']\n",
      "['Qualってなんですか?', '浜崎あゆみさんのカバーアルバムに参加するアーティストのリストに近藤真彦さんが名を連ねているのを知った時は、ちょっとびっくりしました。']\n",
      "['楽しそうですね', '関西では毎日放送のオールザッツ漫才は売っている所がないのですね。']\n",
      "['予防措置は大事ですよね。', '羽生結弦選手と、JR東日本の内村航平選手との衝突で全治2週間から3週間ですからね。下手をすると来年のフィギュアスケート男子のグランプリシリーズにも響きますね。']\n",
      "['そうかもしれないね。', 'ニュージーランドのPABLOというメーカーの清涼飲料水を飲んだことがないのですが、どのようなところがおすすめですか？ 。']\n",
      "['セブンイレブン知ってるんだね。', '今の時期のセブンイレブンでは、チョコケーキマウンテンが販売されていますが、まだ食べていないので近々買いに行こうと思っています。']\n",
      "['食べたら感想を聞かせてね。', 'セブンイレブンのチョコケーキマウンテンというスイーツは、濃厚なチョコレートの味わいが楽しめるケーキで、チョコレート味の生クリームが高く盛られていて、チョコケーキマウンテンという名前の通り、山のような形になっています。']\n",
      "['君は物知りだね。', 'セブンイレブンでは、たまにおでんが一個70円セールというのをやっているので、おにぎりとセットでも安くていいですね。']\n",
      "['レイザーラモンですねあと栗原はるみ', '少し前に、NHKのきょうの料理という番組で、語り部バスのことを見ました。東日本大震災でとても辛い体験をされたにも関わらず、一生懸命生きて伝えていこうとする姿に感動いたしました。']\n",
      "['バラエティー見るの？', '俳優の小籔千豊さんといえば、TBSのドラマで放送されたWOWOWの宮川大輔役のイメージが強く、その役に成りきられるイメージが強いです。']\n",
      "['好きな食べ物は何？', '女優小泉八雲さんが主演された、TBSで放送されたテレビドラマのWOWOWも好きでしたよ。']\n",
      "['興奮しますよね。', '恩納村のフォレストアドベンチャーのような体験を好んでする方ではありません。']\n",
      "['矢部浩之さんは芸人さんですよ。吉本の。', 'TBS系列のずっとあなたが好きだったというテレビ番組で、タレントの小泉八雲さんが紹介した150g1728円のナインティナインが販売するやべっちF.C.とはどのような商品なのでしょうか？ 。']\n",
      "['サッカー好きなの？', '2014年のレイザーラモン系列の番組THE MANZAIに出場した芸人レイザーラモンRGが披露していたネタで、大笑いした記憶があります。']\n",
      "['どんなネタ？', 'レイザーラモンの流れ星は、戦国時代にタイムスリップした高校生が天下を取るまでのサクセスストーリーです。']\n",
      "['その所為で最後まで頑張るのですね。', 'リン・ユーチュンは好きで、アメリカでのサッカーワールドカップの時には涙したと言っていました。']\n",
      "['そうかも知れませんね。', 'サッカーのFIFAワールドカップイングランド大会で公式試合球であった旅の指差し会話帳のレプリカが懸賞で当選したのは凄いですね。']\n",
      "['そんな協会あるんですね。今度買ってきて下さい', 'JR東日本あたりでのクリスマスに登場する遠藤保仁は、やはり暑い季節に合わせたコスチュームになっているのでしょうかね？ 。']\n",
      "['そんなに美味しいんですか？', 'マツダスタジアムに住んでいるにもかかわらず、広島県へ行ったことがないので、広島県の球場グルメの、伯方の塩ソフトクリームを知りませんでした。']\n",
      "['広島に住んでいるのですか？', '広島で初めて広島風のお好み焼きを食べて大好きになりました。']\n",
      "['らいおんハートではなくてHEROですよね？', '女子アナウンサーのタレント化というか、アイドル化というのも以前からありますよね。元フジテレビアナウンサーの倖田來未さんくらいから女子アナウンサーのタレント化は顕著ですかね。']\n",
      "['今年の10月から？', '宮部みゆきさんのタマシイレボリューションシリーズでは、体の弱い廻船問屋の若だんなが主人公なのですが、あやかしと呼ばれる妖怪達と話せる能力を持っています。']\n",
      "['瀬戸内ですかね。なんでその２つなんですか？', '東海道新幹線観光キャンペーンでは、瀬戸内でいちばん出荷量の多いレモンがありましたね。']\n",
      "['そうなんですか。どんなキャンペーンだったんですか？', '天満屋の東海道新幹線の粋な計らいとでも言いますか、一番美しく瀬戸内が見える場所は柵も何も設置されておらず、私は毎回新富士駅あたりを通過する際に、スマートフォンで撮影しています。']\n",
      "['話がかみ合ってないですよ。', '私が永谷園の鶴の子 大粒納豆へ乗った際に、瀬戸内を見る場所は、新富士駅の前後あたりです。']\n",
      "['見てみたいです。', 'ミニストップは、ラスベガスディズニーランドの非公認キャラクターふなっしーの中華まんふなっしーまんを10月28日に発売します。']\n",
      "['おすすめはどれですか？', 'ミニストップのファミマプレミアムチキンはどんなお味なんでしょう？梨味でしょうかね？。']\n",
      "['ざわちんですね。', 'ざわちんさんの出演されたハングリー!はどのような内容でしたか？。']\n",
      "['それは興味がありますね。', '大通会場の中にある、ジェラート専門ショップの阪神タイガースでは、厚生労働省創立100周年を記念したすみれ味のジェラートが販売されていて、厚生労働省のファンの方々にとても人気なんだそうです。']\n",
      "['元気やって何ですか？', 'オペラ歌手で、テレビのバラエティー番組などでも活躍していた、ミケランさんが東京ディズニーシー都内の病院で呼吸不全のためお亡くなりになりました。']\n",
      "['さださんて！ボケが上手だね。', '通販なども行っていないので、噂の現場直行ドキュメン・ガンミ!!を買うには京に行くしかないそうです。']\n",
      "['ガンミ、見てたの？', '毎日放送は京の百貨店等に店舗を構えています。']\n",
      "['名物だからね', '挑戦したことがないですが、沖縄の海でのシュノーケリングもとても楽しそうですね。']\n",
      "['パソコンを触っています。', '一応毎日さわっています。ブログみたいな「mixi]。']\n",
      "['布団は毎日干した方が気持ちいいですよね', 'そうですね、トランス状態なのかな？']\n",
      "['散歩することです。', 'そうだね．犬は大変だから．']\n",
      "['維持費が結構かかりますよ。', '普通車の一年間の税金って、だいたいの車が３万９千５百円なんですが、軽自動車だと７千５百円なんです!']\n",
      "['機械が好きな人には楽しいみたいですよ。', 'いませんねー']\n",
      "['はい、卓球の放送は見たいです。', 'フィギアは人気がありますね。あなたはスポーツはしておられないんですよね？']\n",
      "['こんにちは。私は野球観戦が好きですね。', 'それが無いんですよね、いつも中継ばかりで。']\n",
      "['やりがいがありそうなお仕事ですね。ちなみに好きな動物は何ですか？', 'フリーターです']\n",
      "['耳は冷たいよね', 'どっちなんですか？']\n",
      "['キノコ料理好きです。料理しますか？', 'あまり好きではないですが、１日に１度何かは作ってます。']\n",
      "['私もたばこの臭いは苦手です', '暗くまでなりますか！']\n",
      "['瞬発力がありそうですよね。マラソンは苦手なので羨ましいです。', '予定は、私もほとんどが未定です。']\n",
      "['コンビニのパンは食べません', '洋食ですね！美味しかったですか？']\n",
      "['ドラゴンズですか。今年は優勝できるといいですね。', 'そうです。けどハムの森本の守備には萌えました。']\n",
      "['そうなんですね。私は良い方です。', 'けがも多そう。']\n",
      "['どんなデジタルな音楽が好きなんですか？', 'ミスチル好き！！']\n",
      "['おいしいですよね。', 'チーズがお好きならやっぱスイスでしょう。']\n",
      "['あなたはどんなことをしているんですか？', '最近だと旅行にはまりだしたので、旅代で消えてしまいますね。']\n",
      "['京都も好きです', 'その気持ちよくわかります。あの土産屋さんがならんでいるところで、八つ橋の試食をしまくりながらただでお茶を飲んだり。']\n",
      "['何年生ですか？', '今は３年生です。そろそろ就活と卒論に怯える日々が近づいてます…。']\n",
      "['すごいね。クラシック音楽が好きです', 'あとはお客としてではないですが、ＧＬＡＹのライブにも３日連続して行ったことがありますね。']\n",
      "['推理小説は面白いよね', '漫画かぁ。ちなみに妹が漫画オタクなので旬な漫画はだいたい家にあります！絵は描いてない、ハズ…。']\n",
      "['海外旅行は治安に気をつけないと危ない国とかあるらしいですよ', 'はい。好きです。']\n",
      "['マンチカンという種類です', 'ゴールデンレトリバーと柴犬２匹です。']\n",
      "['好きな季節は何ですか', 'ずばり鍋でしょう！']\n",
      "['横浜中華街へは行かれましたか？', '韓国！国外まで行ってるとは相当お好きですね！DEATHNOTEは結構話題になってますねぇ。']\n",
      "['全部揃えるとお金もかかりそうですね。', 'そんなにするんですか？！私、バイクに']\n",
      "['エアコンつけっぱなしですよ。電気代こわい〜', 'ツケは・・・（汗）']\n",
      "['家ではパソコンで映画を見たりしています。', 'よく見るのですか？']\n",
      "['休日は何をしていますか？', 'そうですね、散歩がてら買い物にでも出ます']\n",
      "['あらあら大丈夫？\\u3000歩ける？', 'さっき休憩で外にいたんですが、風が気持ちよかったんですよ〜部屋の中にいるのがもったいないくらい・・・お外で散歩とかしたいなぁなんて思ってしまったんですが、普段外とかで遊ぶことってありますか？']\n",
      "['気持ちはいいですよね', '川でバーベキューとか素敵だと思います。']\n",
      "['わかりました', '最後に、マンガでプロになろうと思ってます？']\n",
      "['車を軽自動車に買い替えようかな。', '大きい買い物だから悩みますよね。']\n",
      "['最近、高いもの買った？', 'たまには息抜きして下さいね。ちなみに私はまつげパーマかな。']\n",
      "['私は電動自転車を買ったよ。', '聴けばわかると思いますが']\n",
      "['テナーサックスはやっていませんよ', 'そういうわけです。（この辺の話はもしわかる人がいたらと思って書いたんですけど守備範囲外だったらスルーしていいですよ）。']\n",
      "['マウンテンバイクがほしいんですか？', '靴も欲しいです']\n",
      "['新鮮な気持ちになりたいですよね', '一年目って言っても、学部時代に４年過ごしてるから、あんまり新鮮味はないかも。']\n",
      "['インドア派ですか？', '私もどちらかというとインドア派で家でのんびり映画とか見てるのが好きなんですが、１３さんは、家でどんな風にのんびり過ごすのが好きですか？']\n",
      "['そんなことないよ', 'あんな風に、別売りしているんですね']\n",
      "corrent_n: 25\n",
      "all_tp_one: 192\n",
      "bad_n, PF, FP: 317 150 167\n",
      "rate c: 0.13020833333333334\n"
     ]
    }
   ],
   "source": [
    "correct_n = 0\n",
    "bad_n = 0\n",
    "all_tp_one = 0\n",
    "\n",
    "PF = 0\n",
    "FP = 0\n",
    "for x, t, n in zip(X_str, y, y_pred):\n",
    "    # t==1 : 本来の破綻\n",
    "    # n==1 : 予想された破綻\n",
    "    if t == 1:\n",
    "        all_tp_one += 1\n",
    "        if n == 1:\n",
    "            # t==n==1 : 適切に検出\n",
    "            correct_n += 1\n",
    "            # print(x)\n",
    "        else:\n",
    "            # 破綻なのに未検出\n",
    "            bad_n += 1\n",
    "            FP += 1\n",
    "            # print(x)\n",
    "    else:\n",
    "        # 破綻ではないのに破綻扱い\n",
    "        if n == 1:\n",
    "            bad_n += 1\n",
    "            PF += 1\n",
    "            print(x)\n",
    "print(\"corrent_n:\", correct_n)\n",
    "print(\"all_tp_one:\", all_tp_one)\n",
    "print(\"bad_n, PF, FP:\", bad_n, PF, FP)\n",
    "print(\"rate c:\", correct_n/all_tp_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
