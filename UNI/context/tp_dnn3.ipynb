{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza')\n",
    "emb_dim = nlp(\"形態素\").vector.shape[0]\n",
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_convs(path, filename):\n",
    "    with open(path+filename, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "        # length = json_data[\"length\"]\n",
    "        convs = json_data[\"convs\"]\n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_dir = \"continue/\"\n",
    "cont_path = \"../../corpus/nucc/\" + cont_dir\n",
    "length = 3\n",
    "filename = \"cont{0}.json\".format(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = load_convs(cont_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_str = [conv for data in convs for conv in data]\n",
    "X_utt = [utt for data in convs for conv in data for utt in conv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "def fake_error(convs):\n",
    "    utt_list = [conv[-1] for conv in convs]\n",
    "    # print(utt_list)\n",
    "    new_conv = copy.deepcopy(convs)\n",
    "    for conv in new_conv:\n",
    "        conv[-1] = random.choice(utt_list)\n",
    "    return new_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UT: 575\n",
      "UT_NO: 5177\n"
     ]
    }
   ],
   "source": [
    "UT = fake_error( X_str[:int( len(X_str)*0.1) ] ) \n",
    "UT_NO = X_str[int( len(X_str)*0.1):]\n",
    "print(\"UT: {0}\".format(len(UT)))\n",
    "print(\"UT_NO: {0}\".format(len(UT_NO)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['社会科の人。わかんない。', '社会科だね。たぶん。でもねー。', 'もそうなんだけど、前に買ってて、'],\n",
       " ['だって土日でしょう、しかも。悲しーい。バイトに行きたいなあ。',\n",
       "  '強制じゃないって。でも、それって半強制だよね。',\n",
       "  'コンビニで。謝らしちゃったんだよ。びっくりした。謝れ、ごめんなさい。'],\n",
       " ['強制じゃないって。でも、それって半強制だよね。', '半強制やろ。行きたくない、も', 'でもそ、わかんなかったんだからしょうがないでしょ。']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_str[:3]\n",
    "UT[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM?\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size, batch_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True, bidirectional=True )\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        # self.softmax = \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        _, hidden_layer = self.lstm(x)\n",
    "        # print(hidden_layer)\n",
    "        bilstm_out = torch.cat([hidden_layer[0][0], hidden_layer[0][1]], dim=1)\n",
    "        # y = self.hidden2tag(hidden_layer[0].view(batch_size, -1))\n",
    "\n",
    "        y = self.hidden2tag(bilstm_out)\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class DataManager:\n",
    "    def __init__(self, data_path) -> None:\n",
    "        import os\n",
    "        import pickle\n",
    "        self.data_path = data_path\n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "        self.dir = os.listdir(data_path)\n",
    "\n",
    "    def is_exist(self, name):\n",
    "        return (name in self.dir)\n",
    "    \n",
    "    def save_data(self, name, obj):\n",
    "        with open(self.data_path+name, \"wb\") as f:\n",
    "            pickle.dump(obj, f)\n",
    "        print(\"success save : {0}{1}\".format(self.data_path, name))\n",
    "\n",
    "    def load_data(self, name):\n",
    "        with open(self.data_path+name, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "        print(\"success load : {0}{1}\".format(self.data_path, name))\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyknp import Juman\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X(convs, max_len):\n",
    "    # emb_dim = nlp(\"形態素\").vector.shape\n",
    "    X_data = []\n",
    "    \n",
    "    for conv in convs :\n",
    "        # vec_list = np.zeros( (max_len, emb_dim[0]) )\n",
    "        sentence_vectors = Nmodel.encode(conv)\n",
    "        # for i, ut in enumerate(conv):\n",
    "        #     doc = nlp(ut)\n",
    "        #     vec_list[i] = doc.vector\n",
    "        X_data.append(sentence_vectors)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic4-3.pickle\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../X_y_data/context/\"\n",
    "data_name = \"topic4-{0}.pickle\".format(length)\n",
    "dataM = DataManager(data_path)\n",
    "print(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../X_y_data/context/topic4-3.pickle\n"
     ]
    }
   ],
   "source": [
    "if dataM.is_exist(data_name):\n",
    "    \n",
    "    DATA_Xy = dataM.load_data(data_name)\n",
    "    X = DATA_Xy[0]\n",
    "    y = DATA_Xy[1]\n",
    "else:\n",
    "    # X_data, y_data = pre.extract_X_y(df, error_types, seq_len)\n",
    "    X = make_X(UT + UT_NO, length)\n",
    "    y = np.concatenate( [ np.ones(len(UT)), np.zeros(len(UT_NO)) ] )\n",
    "    dataM.save_data(data_name, [X, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4592\n",
      "1, 2, 4, 7, 8, 14, 16, 28, 41, 56, 82, 112, 164, 287, 328, 574, 656, 1148, 2296, 4592, "
     ]
    }
   ],
   "source": [
    "X_train = X_train[:-9]\n",
    "y_train = y_train[:-9]\n",
    "leng = len(y_train)\n",
    "print(leng)\n",
    "for i, v in enumerate(y_train):\n",
    "    if leng %(i+1) == 0:\n",
    "        print(i+1, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 94\n",
    "epoch_ = 400\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = emb_dim\n",
    "HIDDEN_DIM = emb_dim*4\n",
    "OUTPUT_DIM = 2\n",
    "seq_len = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, BATCH_SIZE)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 0.00013961097238279763\n",
      "epoch 100 \t loss 1.9436393969840537e-05\n",
      "epoch 150 \t loss 4.229296349578249e-06\n",
      "epoch 200 \t loss 1.0272922708054466e-06\n",
      "epoch 250 \t loss 2.3378969093990065e-07\n",
      "epoch 300 \t loss 5.0727355649371475e-09\n",
      "epoch 350 \t loss 0.0\n",
      "epoch 400 \t loss 0.0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "# print(\"error[{0}]\".format(error_types[error_i]))\n",
    "for epoch in range(epoch_):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        X_t_tensor = torch.tensor(data[0], device='cuda:0').float()\n",
    "        # y_t_tensor = torch.tensor(data[1].reshape(batch_size, 1), device='cuda:0').float()\n",
    "        y_t_tensor = torch.tensor(data[1], device='cuda:0').long()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        # print(X_t_tensor.shape)\n",
    "\n",
    "        score = model(X_t_tensor)\n",
    "        loss_ = loss_function(score, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "    # if all_loss <= loss_border:\n",
    "    #     print(\"loss was under border(={0}) : train end\".format(loss_border))\n",
    "    #     break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9192006950477846"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic4-3.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/context/\"\n",
    "model_name = \"topic4-{0}.pickle\".format(length)\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/context/topic4-3.pickle\n"
     ]
    }
   ],
   "source": [
    "modelM.save_data(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
