{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../../corpus/SNLI/\"\n",
    "data_name = \"dev_sentence.csv\"\n",
    "data_name = \"train_sentence.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(corpus_path+data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_contradict_df =  df.query('label == \"entailment\" | label == \"neutral\"')\n",
    "contradict_df = df.query('label == \"contradiction\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([not_contradict_df, contradict_df.sample(frac=0.3)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13591] 2022-01-21 02:14:59,798 Info sentence_transformers.SentenceTransformer :Load pretrained SentenceTransformer: ../../corpus/pretrained/sbert_snli2\n",
      "[13591] 2022-01-21 02:15:00,681 Info sentence_transformers.SentenceTransformer :Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "bert_path = \"../../corpus/pretrained/sbert_snli2\"\n",
    "sbert = SentenceTransformer(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    sentences = []\n",
    "    if isinstance(text, str):\n",
    "        sentences = [text]\n",
    "    elif isinstance(text, list):\n",
    "        sentences = text\n",
    "    \n",
    "    return sbert.encode(sentences)\n",
    "\n",
    "def text2feature(text):\n",
    "    vector = text2vec(text)\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])\n",
    "\n",
    "\n",
    "def vec2feature(vector):\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2feature(vector):\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "label2id = dict( zip(label, range(len(label))) )\n",
    "\n",
    "def make_Xy(df):\n",
    "    X_str = []\n",
    "    y = []\n",
    "\n",
    "    for la, pre, hypo in zip(df.label, df.pre, df.hypo):\n",
    "        if la not in label2id:\n",
    "            continue\n",
    "        X_str += [pre, hypo]\n",
    "        y.append(label2id[la])\n",
    "    # X_str_all = X_str_all[:250]\n",
    "    # X_all_str = sum(X_str, [])\n",
    "    x_length = len(X_str)//2\n",
    "    X_vec = sbert.encode(X_str).reshape(x_length, 2, -1)\n",
    "    X = np.array([ vec2feature(vec) for vec in X_vec ])\n",
    "    # print(X_str_all)\n",
    "    return torch.from_numpy(X), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c49f70be8344f5b67a43cf9e4a1b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/33313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = make_Xy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(SNLIModel, self).__init__()    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hid1= embedding_dim*2\n",
    "        self.hid2 = embedding_dim//2\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, self.hid1)\n",
    "        self.fc2 = nn.Linear(self.hid1, self.hid2)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        # self.hidden2tag = nn.Linear(self.hid2+self.fb_dim, tagset_size)\n",
    "        self.hidden2tag = nn.Linear(self.hid2, tagset_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # fb = x[:, :self.fb_dim]\n",
    "        y = F.relu(self.fc1(x))\n",
    "        # y = F.relu(self.fc1(x[]))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.hidden2tag( y )\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "epoch_ = 400\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304 3\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 768*3\n",
    "OUTPUT_DIM = 3\n",
    "print(EMBEDDING_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SNLIModel(EMBEDDING_DIM, OUTPUT_DIM)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 117.86921394594538\n",
      "epoch 100 \t loss 60.91275814241726\n",
      "epoch 150 \t loss 51.86729562044343\n",
      "epoch 200 \t loss 40.43765252748881\n",
      "epoch 250 \t loss 32.63210014801841\n",
      "epoch 300 \t loss 34.79018809754049\n",
      "epoch 350 \t loss 35.62214689530017\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b23753e11ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscore_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mall_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(epoch_): \n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        # X_t_tensor = torch.tensor(data[0], device='cuda:0')\n",
    "        X_t_tensor = data[0].cuda()\n",
    "        # y_t_tensor = torch.tensor(data[1], device='cuda:0')\n",
    "        y_t_tensor = data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        score_ = model(X_t_tensor)\n",
    "        loss_ = loss_function(score_, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score_\n",
    "        del loss_\n",
    "        \n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.75 GiB (GPU 0; 6.00 GiB total capacity; 2.03 GiB already allocated; 1.63 GiB free; 2.10 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-39cdd7178763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;31m# 推論\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d8762df0c904>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# fb = x[:, :self.fb_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# y = F.relu(self.fc1(x[]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.75 GiB (GPU 0; 6.00 GiB total capacity; 2.03 GiB already allocated; 1.63 GiB free; 2.10 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[45702  6780  2293]\n",
      " [ 7832 40749  6159]\n",
      " [ 2486  5618 46786]]\n",
      "accuracy =  0.8104193911377391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- そのまま SBERT でもこれくらいは出る\n",
    "\n",
    "        confusion matrix = \n",
    "        [[365  21  44]\n",
    "        [ 35 331  32]\n",
    "        [ 53  29 265]]\n",
    "        accuracy =  0.8178723404255319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/context/sbert_snli_dnn3.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/context/\"\n",
    "model_name = \"sbert_snli_dnn3.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
