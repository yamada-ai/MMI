{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../../corpus/SNLI/\"\n",
    "data_name = \"dev_sentence.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(corpus_path+data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_contradict_df =  df.query('label == \"entailment\" | label == \"neutral\"')\n",
    "contradict_df = df.query('label == \"contradiction\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([not_contradict_df, contradict_df.sample(frac=0.3)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[700] 2022-01-11 01:17:40,334 Info sentence_transformers.SentenceTransformer :Load pretrained SentenceTransformer: ../../corpus/pretrained/sbert_snli\n",
      "[700] 2022-01-11 01:17:41,157 Info sentence_transformers.SentenceTransformer :Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "bert_path = \"../../corpus/pretrained/sbert_snli\"\n",
    "sbert = SentenceTransformer(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    sentences = []\n",
    "    if isinstance(text, str):\n",
    "        sentences = [text]\n",
    "    elif isinstance(text, list):\n",
    "        sentences = text\n",
    "    \n",
    "    return sbert.encode(sentences)\n",
    "\n",
    "def text2feature(text):\n",
    "    vector = text2vec(text)\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])\n",
    "\n",
    "\n",
    "def vec2feature(vector):\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "label2id = dict( zip(label, range(len(label))) )\n",
    "\n",
    "def make_Xy(df):\n",
    "    X_str_all = []\n",
    "    y = []\n",
    "\n",
    "    for la, pre, hypo in zip(df.label, df.pre, df.hypo):\n",
    "        X_str_all += [pre, hypo]\n",
    "        y.append(label2id[la])\n",
    "    # X_str_all = X_str_all[:250]\n",
    "    X_all = text2vec(X_str_all)\n",
    "    X_vec = X_all.reshape(len(X_all)//2, 2, -1)\n",
    "    X = np.array( [  vec2feature(xv) for xv in X_vec ] )\n",
    "    # print(X_str_all)\n",
    "    return torch.from_numpy(X), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878a306c358f40998577ac88205ac3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = make_Xy(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(SNLIModel, self).__init__()    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hid1= embedding_dim*2\n",
    "        self.hid2 = embedding_dim//2\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, self.hid1)\n",
    "        self.fc2 = nn.Linear(self.hid1, self.hid2)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        # self.hidden2tag = nn.Linear(self.hid2+self.fb_dim, tagset_size)\n",
    "        self.hidden2tag = nn.Linear(self.hid2, tagset_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # fb = x[:, :self.fb_dim]\n",
    "        y = F.relu(self.fc1(x))\n",
    "        # y = F.relu(self.fc1(x[]))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.hidden2tag( y )\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 155\n",
    "epoch_ = 400\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304 3\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 768*3\n",
    "OUTPUT_DIM = 3\n",
    "print(EMBEDDING_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SNLIModel(EMBEDDING_DIM, OUTPUT_DIM)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 0.07406122155953199\n",
      "epoch 100 \t loss 0.01210484333569184\n",
      "epoch 150 \t loss 0.00220325274131028\n",
      "epoch 200 \t loss 0.001133141926402459\n",
      "epoch 250 \t loss 0.0006164507703942945\n",
      "epoch 300 \t loss 0.00033941578658414073\n",
      "epoch 350 \t loss 0.00019922770025004866\n",
      "epoch 400 \t loss 0.0001320763590229035\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "for epoch in range(epoch_): \n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        # X_t_tensor = torch.tensor(data[0], device='cuda:0')\n",
    "        X_t_tensor = data[0].cuda()\n",
    "        # y_t_tensor = torch.tensor(data[1], device='cuda:0')\n",
    "        y_t_tensor = data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        score_ = model(X_t_tensor)\n",
    "        loss_ = loss_function(score_, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score_\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[384  30  16]\n",
      " [ 37 346  16]\n",
      " [ 21  24  59]]\n",
      "accuracy =  0.8456591639871383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- そのまま SBERT でもこれくらいは出る\n",
    "\n",
    "        confusion matrix = \n",
    "        [[365  21  44]\n",
    "        [ 35 331  32]\n",
    "        [ 53  29 265]]\n",
    "        accuracy =  0.8178723404255319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/context/sbert_snli_dnn2.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/context/\"\n",
    "model_name = \"sbert_snli_dnn2.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
