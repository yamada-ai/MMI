{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"../../corpus/SNLI/\"\n",
    "data_name = \"dev_sentence.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(corpus_path+data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_contradict_df =  df.query('label == \"entailment\" | label == \"neutral\"')\n",
    "contradict_df = df.query('label == \"contradiction\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([not_contradict_df, contradict_df.sample(frac=0.3)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[700] 2022-01-11 00:53:22,121 Info sentence_transformers.SentenceTransformer :Load pretrained SentenceTransformer: ../../corpus/pretrained/sbert_snli\n",
      "[700] 2022-01-11 00:53:22,915 Info sentence_transformers.SentenceTransformer :Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "bert_path = \"../../corpus/pretrained/sbert_snli\"\n",
    "sbert = SentenceTransformer(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    sentences = []\n",
    "    if isinstance(text, str):\n",
    "        sentences = [text]\n",
    "    elif isinstance(text, list):\n",
    "        sentences = text\n",
    "    \n",
    "    return sbert.encode(sentences)\n",
    "\n",
    "def text2feature(text):\n",
    "    vector = text2vec(text)\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])\n",
    "\n",
    "\n",
    "def vec2feature(vector):\n",
    "    diff = np.abs( vector[0] - vector[1] )\n",
    "    return np.concatenate([vector.flatten(), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "label2id = dict( zip(label, range(len(label))) )\n",
    "\n",
    "def make_Xy(df):\n",
    "    X_str_all = []\n",
    "    y = []\n",
    "\n",
    "    for la, pre, hypo in zip(df.label, df.pre, df.hypo):\n",
    "        X_str_all += [pre, hypo]\n",
    "        y.append(label2id[la])\n",
    "    # X_str_all = X_str_all[:250]\n",
    "    X_all = text2vec(X_str_all)\n",
    "    X_vec = X_all.reshape(len(X_all)//2, 2, -1)\n",
    "    X = np.array( [  vec2feature(xv) for xv in X_vec ] )\n",
    "    # print(X_str_all)\n",
    "    return torch.from_numpy(X), torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6936121afe4b4f34a2cef18196b64720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = make_Xy(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(SNLIModel, self).__init__()    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hid1= embedding_dim*2\n",
    "        self.hid2 = embedding_dim//2\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, self.hid1)\n",
    "        self.fc2 = nn.Linear(self.hid1, self.hid2)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        # self.hidden2tag = nn.Linear(self.hid2+self.fb_dim, tagset_size)\n",
    "        self.hidden2tag = nn.Linear(self.hid2, tagset_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # fb = x[:, :self.fb_dim]\n",
    "        y = F.relu(self.fc1(x))\n",
    "        # y = F.relu(self.fc1(x[]))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.hidden2tag( y )\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 155\n",
    "epoch_ = 400\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304 3\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 768*3\n",
    "OUTPUT_DIM = 3\n",
    "print(EMBEDDING_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SNLIModel(EMBEDDING_DIM, OUTPUT_DIM)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 \t loss 0.05929013807326555\n",
      "epoch 100 \t loss 0.005847996071679518\n",
      "epoch 150 \t loss 0.002102630169247277\n",
      "epoch 200 \t loss 0.0008981823775684461\n",
      "epoch 250 \t loss 0.0004039243267470738\n",
      "epoch 300 \t loss 0.00020194501348669291\n",
      "epoch 350 \t loss 0.00010623251728247851\n",
      "epoch 400 \t loss 5.9595895663733245e-05\n",
      "epoch 450 \t loss 3.350107965616189e-05\n",
      "epoch 500 \t loss 2.0358067672532343e-05\n",
      "epoch 550 \t loss 1.1231615218321167e-05\n",
      "epoch 600 \t loss 6.750903338570424e-06\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "for epoch in range(epoch_): \n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        # X_t_tensor = torch.tensor(data[0], device='cuda:0')\n",
    "        X_t_tensor = data[0].cuda()\n",
    "        # y_t_tensor = torch.tensor(data[1], device='cuda:0')\n",
    "        y_t_tensor = data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        score_ = model(X_t_tensor)\n",
    "        loss_ = loss_function(score_, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score_\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[362  22  46]\n",
      " [ 34 328  36]\n",
      " [ 54  24 269]]\n",
      "accuracy =  0.8161702127659575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- そのまま SBERT でもこれくらいは出る\n",
    "\n",
    "        confusion matrix = \n",
    "        [[365  21  44]\n",
    "        [ 35 331  32]\n",
    "        [ 53  29 265]]\n",
    "        accuracy =  0.8178723404255319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../models/context/sbert_snli_dnn2.pickle\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models/context/\"\n",
    "model_name = \"sbert_snli_dnn2.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "modelM.save_data(model_name, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
