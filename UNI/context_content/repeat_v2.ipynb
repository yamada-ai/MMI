{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from utterance.error_tools import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../eval_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.366666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "191*120/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章ごとに n-gram を考えてみる\n",
    "def get_ngram_set(doc, N=3):\n",
    "    if isinstance(doc, str):\n",
    "        doc = nlp(doc)\n",
    "    surfaces = [token.text for token in doc]\n",
    "    ngram_set = set()\n",
    "    filled = [\"FOS\", *surfaces, \"EOS\"]\n",
    "    # print(filled)\n",
    "    for i in range(len(filled)-N+1):\n",
    "        f = \"_\".join(filled[i:i+N])\n",
    "        ngram_set.add(f)\n",
    "    return ngram_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_repeat_rate(target:set, history:list, border=0.7):\n",
    "    t_list = list(target)\n",
    "    for prev_set in history:\n",
    "        size = len(prev_set)\n",
    "        hit = 0\n",
    "        for t in t_list:\n",
    "            if t in prev_set:\n",
    "                hit+=1\n",
    "        if hit/size >= border:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = \"Repetition\"\n",
    "y = []\n",
    "for conv in convs:\n",
    "    for ut in conv:\n",
    "        if not ut.is_system():\n",
    "            continue\n",
    "        # \n",
    "        if ut.is_exist_error():\n",
    "            if ut.is_error_included(error):\n",
    "                # print(ut.errors)\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1386"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_path = \"../../corpus/wiki/idf_wiki_v2.json\"\n",
    "with open(idf_path, \"r\") as f:\n",
    "    idf_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_under_idf_border_morpheme(text, idf_border):\n",
    "    for token in mecab_tokenize(text):\n",
    "        key = token\n",
    "        if key in idf_dict:\n",
    "            if idf_dict[key] > idf_border:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_repeat_rate_ret_i(target:set, history:list, border=0.7):\n",
    "    t_list = list(target)\n",
    "    for i, prev_set in enumerate(history):\n",
    "        size = len(prev_set)\n",
    "        hit = 0\n",
    "        for t in t_list:\n",
    "            if t in prev_set:\n",
    "                hit+=1\n",
    "        if hit/size >= border:\n",
    "            return i\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:29<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "y_pred = []\n",
    "border = 0.8\n",
    "\n",
    "border_10 = 14.62592894814336\n",
    "border_1 = 9.88253708481772\n",
    "border_005 = 5.340630805533431\n",
    "\n",
    "pair_list = []\n",
    "\n",
    "for conv in tqdm(convs):\n",
    "    ngram_sets = []\n",
    "    prev_sents = []\n",
    "    for ut in conv:\n",
    "        if not ut.is_system():\n",
    "            continue\n",
    "        utt = ut.utt\n",
    "        doc = nlp(utt)\n",
    "        if ut.is_exist_error():\n",
    "            y_pred.append(0)\n",
    "        \n",
    "        for sent in doc.sents:\n",
    "            # idf が小さい場合は，スルーしましょう\n",
    "            if is_under_idf_border_morpheme(sent.orth_, border_005):\n",
    "                # print(sent)\n",
    "                continue\n",
    "            ngram_set = get_ngram_set(sent, N=3)\n",
    "            # これまでのセットで重複が大きいものがあるかチェック！\n",
    "            if ut.is_exist_error():\n",
    "                ngram_checked = check_repeat_rate_ret_i(target=ngram_set, history=ngram_sets, border=0.8)\n",
    "                # if check_repeat_rate_ret_i(target=ngram_set, history=ngram_sets, border=0.8):\n",
    "                    # print(ut, ut.errors)\n",
    "                if ngram_checked >= 0:\n",
    "                    y_pred[-1] = 1\n",
    "                    pair_list.append([sent.orth_, prev_sents[ngram_checked], \"ngram\"])\n",
    "\n",
    "                if y_pred[-1] == 0:\n",
    "                    for i, prev in enumerate( prev_sents ) :\n",
    "                        if Levenshtein.ratio(sent.orth_, prev) >= 0.8:\n",
    "                            pair_list.append([sent.orth_, prev_sents[i], \"leven\"])\n",
    "                            y_pred[-1] = 1\n",
    "                \n",
    "\n",
    "            ngram_sets.append(ngram_set)\n",
    "            prev_sents.append(sent.orth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[1296   34]\n",
      " [  10   46]]\n",
      "accuracy =  0.9682539682539683\n",
      "precision =  0.575\n",
      "recall =  0.8214285714285714\n",
      "f1 score =  0.676470588235294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ngram  border 0.8\n",
    "\n",
    "        confusion matrix = \n",
    "        [[2131   21]\n",
    "        [  29   19]]\n",
    "        accuracy =  0.9772727272727273\n",
    "        precision =  0.475\n",
    "        recall =  0.3958333333333333\n",
    "        f1 score =  0.4318181818181817\n",
    "\n",
    "    - 再現率が欲しい\n",
    "\n",
    "- Levenshtein bordr 0.8\n",
    "    \n",
    "        confusion matrix = \n",
    "        [[2102   50]\n",
    "        [  19   29]]\n",
    "        accuracy =  0.9686363636363636\n",
    "        precision =  0.3670886075949367\n",
    "        recall =  0.6041666666666666\n",
    "        f1 score =  0.45669291338582674\n",
    "\n",
    "    - 悪くないが，適合率が低い\n",
    "\n",
    "- ngram  border 0.8 and Levenshtein bordr 0.8 and idf 005%\n",
    "    - 仮定 : 「そうですよね」のように，全く情報量がない発話が繰り返された場合は不要な繰り返しの可能性が低い\n",
    "        - idf 辞書の活用\n",
    "    - 予想 : 誤検出が減る\n",
    "    \n",
    "            confusion matrix = \n",
    "            [[2091   61]\n",
    "            [  15   33]]\n",
    "            accuracy =  0.9654545454545455\n",
    "            precision =  0.35106382978723405\n",
    "            recall =  0.6875\n",
    "            f1 score =  0.46478873239436624\n",
    "\n",
    "\n",
    "    - 評価データでの実行\n",
    "            \n",
    "            confusion matrix = \n",
    "            [[2080   64]\n",
    "            [  10   46]]\n",
    "            accuracy =  0.9663636363636363\n",
    "            precision =  0.41818181818181815\n",
    "            recall =  0.8214285714285714\n",
    "            f1 score =  0.5542168674698795\n",
    "\n",
    "\n",
    "    - 誤検出が増えたが，未検出が減った\n",
    "        - len(sent) <3 の中に，情報量があり，似た発話があるが不要ではない\n",
    "        - len(sent) <3 の中に検出するべきエラーが存在した\n",
    "    \n",
    "    - 今後\n",
    "        - どのような発話が雑談において不要ではないのかの検討が出来ていない\n",
    "            - 共起辞書が活用できるか？\n",
    "                - データを見た限り，そう簡単にはいかない\n",
    "        - 非常に近い距離で，動詞や形容詞だけが違うという場合が検出出来ていない\n",
    "            - 検出された発話中で，名詞や動詞などを比較するべきか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "よく検出した！えらいぞ 1502868266\n",
      "['こんにちは。ちょうど退屈してたんだ。', 'こんにちは。元気ですか？', '元気ですかは元気です', '元気そうでよかった。', '元気ですかは元気ですね']\n",
      "['元気ですかは元気ですね', '元気ですかは元気です', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1502868266\n",
      "['こんにちは。ちょうど退屈してたんだ。', 'こんにちは。元気ですか？', '元気ですかは元気です', '元気そうでよかった。', '元気ですかは元気ですね', 'いまなにしてたの？', 'もちろんですってのが元気ですかにいいですね', 'そうなんだ。どうして？', 'もちろんですってのが元気ですかにいいらしいですよ']\n",
      "['もちろんですってのが元気ですかにいいらしいですよ', 'もちろんですってのが元気ですかにいいですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1502869359\n",
      "['夏休みは楽しいですね', '夏休みは欲しいですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470623771\n",
      "['こんにちは。海へ行きたいね。', '海はいいですね。泳ぎは得意ですか。', '泳ぎはいいですね', '気持ちいいですよね。', '泳ぎが上手ですね', 'ありがとう。クロールが得意なんです。', 'クロールは得意ですね', 'そう、スイミングで習ってるんです。', '朝からスイミングで泳ぎます？？', '泳ぎますよ。目が覚めていいですよ。', '目は覚めてるんですね。スイミングは楽しいですね', 'ですよね。そういえばオリンピックの水泳も楽しみですね。', 'スイミングがいいですね', '金メダルとれるといいですよね。', 'スイミングは楽しいですね']\n",
      "['スイミングは楽しいですね', 'スイミングは楽しいですね', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1502868964\n",
      "['こんにちは。声かけてくれるのを待ってたんだ。', 'こんにちは。調子はどうですか？', '何か普段の生活で気をつけていることはありますか。', '健康には特に気を付けています。', '和食、洋食、中華どれが食べたいですか？', 'そうですねぇ。和食ですかね。', '和食ですか。和食でヘルシーですね', 'そうですね。あなたはどれが食べたいですか？', '和食でヘルシーです']\n",
      "['和食でヘルシーです', '和食でヘルシーですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1502868520\n",
      "['天ぷらは食べるのが好きですね', '天ぷらは食べるのが美味しいですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470622968\n",
      "['こんにちは！気軽に声かけてね。', 'こんにちは', 'こんにちはありです', 'よろしくお願いします', 'こちらこそ', '今日の気分はどうですか', 'そうですね、あだ名はありますよ。', 'あだ名はなんですか', 'そうですね、あだ名はありますよ。']\n",
      "['そうですね、あだ名はありますよ。', 'そうですね、あだ名はありますよ。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470622968\n",
      "['こんにちは！気軽に声かけてね。', 'こんにちは', 'こんにちはありです', 'よろしくお願いします', 'こちらこそ', '今日の気分はどうですか', 'そうですね、あだ名はありますよ。', 'あだ名はなんですか', 'そうですね、あだ名はありますよ。', '何と呼べばいいですか', 'あだ名を持ちます', 'あだ名、教えてください', '職場で同僚をあだ名で呼ぶのは、どうかと思うよ。', 'そうですね。反省します。', '職場で同僚をあだ名で呼ぶのは、どうかと思うよ。']\n",
      "['職場で同僚をあだ名で呼ぶのは、どうかと思うよ。', '職場で同僚をあだ名で呼ぶのは、どうかと思うよ。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470624191\n",
      "['かけ声をだしたことありますね', 'かけ声を覚えたことあります', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470624191\n",
      "['かけ声をあげるかもしれない', 'かけ声を覚えるかもしれない', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470624191\n",
      "['かけ声を聞きますよねー', 'かけ声を聞きます', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470624033\n",
      "['こんにちは。声かけてくれるのを待ってたんだ。', 'こんにちは。最近興味のあることってありますか？', '興味が湧いてないかもです', 'そうですかー。映画とか気になるのありません？', '映画が楽しみです', '今いろんな映画やっていますもんね', '映画は大丈夫です', '映画でポップコーン食べるのが好きです。', '映画は元気ですね', '私も元気な映画を見るのは好きですよ', '映画が楽しみですね']\n",
      "['映画が楽しみですね', '映画が楽しみです', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470624033\n",
      "['映画は音楽がいいですね', '映画は一人がいいですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470647225\n",
      "['こんばんは！海へ行きたいね。', '海は気持ちが良いですからね。', '海は楽しいですね', '海に行って何をしたら楽しいですか？', '海は大好きですね', '私も好きです。', 'ありがとう', '海は、ただ眺めてるだけでも良いですよね。', '海は好きですね']\n",
      "['海は好きですね', '海は大好きですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470623130\n",
      "['仲間由紀恵は美しいですね', '仲間由紀恵は怖いですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470649921\n",
      "['こんばんは。ちょうど退屈してたんだ。', 'こんばんは。よろしく。', '料理はできますか？', '簡単なものならできます。', '料理はできてるんですね。料理で使えてますか？', '毎日料理は作ってます。', '料理を作ってるんですね。料理は奥深いですね', 'そうですね。', 'ねー', '同じ料理でも作り方によっていろいろなものになりますね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'そうですね。時間がないときはよく使います。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', 'いいものを使うとやりやすいですね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。']\n",
      "['カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470649921\n",
      "['こんばんは。ちょうど退屈してたんだ。', 'こんばんは。よろしく。', '料理はできますか？', '簡単なものならできます。', '料理はできてるんですね。料理で使えてますか？', '毎日料理は作ってます。', '料理を作ってるんですね。料理は奥深いですね', 'そうですね。', 'ねー', '同じ料理でも作り方によっていろいろなものになりますね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'そうですね。時間がないときはよく使います。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', 'いいものを使うとやりやすいですね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'いまのインスタント食品はいろいろ味がよくできていますね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。']\n",
      "['カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470649921\n",
      "['こんばんは。ちょうど退屈してたんだ。', 'こんばんは。よろしく。', '料理はできますか？', '簡単なものならできます。', '料理はできてるんですね。料理で使えてますか？', '毎日料理は作ってます。', '料理を作ってるんですね。料理は奥深いですね', 'そうですね。', 'ねー', '同じ料理でも作り方によっていろいろなものになりますね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'そうですね。時間がないときはよく使います。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', 'いいものを使うとやりやすいですね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'いまのインスタント食品はいろいろ味がよくできていますね。', 'カップラーメンでもインスタントカレーでも、立派な料理だよね。', 'やっぱり自分で作ったほうが美味しいものができますね。', '料理は美味しいですね', 'その時によって美味しくできる時とあんまり美味しくない時といろいろありますね。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。']\n",
      "['料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470661075\n",
      "['こんばんはー。気軽に声かけてね。', '分かりました。', 'よろしい', '最近の調子はどうですか？', 'そういえば思い出したんですけど、遊園地にある大きな池は、防災も兼ねてるらしいですよ。', 'そういえば、聞いたことがあります。防災は大切ですよね。', '外で見ようですよ', '何か見るのですか？', '池は寒いです', '夏の時期は気持ちが良いかもしれません。', '池に住むのです', 'それは面白そうです。', '池はいいですね', 'ボートの使えるところもありますね。', '活性が高いですね', 'どのような活性ですか？', '活性は高いです']\n",
      "['活性は高いです', '活性が高いですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470661075\n",
      "['こんばんはー。気軽に声かけてね。', '分かりました。', 'よろしい', '最近の調子はどうですか？', 'そういえば思い出したんですけど、遊園地にある大きな池は、防災も兼ねてるらしいですよ。', 'そういえば、聞いたことがあります。防災は大切ですよね。', '外で見ようですよ', '何か見るのですか？', '池は寒いです', '夏の時期は気持ちが良いかもしれません。', '池に住むのです', 'それは面白そうです。', '池はいいですね', 'ボートの使えるところもありますね。', '活性が高いですね', 'どのような活性ですか？', '活性は高いです', '活発なのはいいことです。', '活性が全体的に低いです', 'そういえば、家の近くでお祭りがありました。', '活性は高いですね']\n",
      "['活性は高いですね', '活性が高いですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1502870626\n",
      "['こんにちは。熱中症に気をつけて。', '気をつかってくれてありがとうございます。', '熱中症に気をつけてたいですか？', 'なるべく元気でいたいと思っています。', '熱中症が心配されます？？', '今日は涼しかったので大丈夫です。', '大丈夫ですか。熱中症が出てますか？', 'あなたは体調は大丈夫ですか？', 'あなたは、多少体調が悪くても、会社や学校に行くタイプ？', 'その時によります。', 'あなたは、多少体調が悪くても、会社や学校に行くタイプ？']\n",
      "['活性は高いですね', '活性は高いです', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1502872236\n",
      "['あなたは、多少体調が悪くても、会社や学校に行くタイプ？', 'あなたは、多少体調が悪くても、会社や学校に行くタイプ？', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1502869239\n",
      "['コミュニケーションは得意です', 'コミュニケーションは難しいですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1502869239\n",
      "['自動販売機はほしいですね', '自動販売機はいいですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1502868713\n",
      "['こんにちは。ちょうど退屈してたんだ。', 'こんにちは、今日も暑いですね。', '話は変わりますけど、１２月１日は映画の日だって、知ってました？', 'すみませ〜ん、知りません。', '得意料理はなんですか？', '餃子です。あなたの得意料理はなんですか？', '料理は不得手です', 'ところで好きな映画はなんですか？', '料理は下手です']\n",
      "['自動販売機は何気ないですね', '自動販売機はいいですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470623211\n",
      "['自動販売機は何気ないですね', '自動販売機はほしいですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470623211\n",
      "['料理は下手です', '料理は不得手です', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1502869481\n",
      "['こんにちは。夏といえばスイカだね。', 'スイカは好きですか？', 'スイカはうまいですね', 'はい美味しいですね。', 'スイカは食べるのがおいしいですね', '夏といえばスイカ以外に何を思い浮かべますか？', '家で食べます', '一人暮らしですか？', '一人暮らしは食生活が偏るのです', '自炊してますか？', '自炊は安上がりです', '安上がりですけど面倒ですよね？', '自炊はお金がかからないんですよねぇ', '得意料理は何ですか？', 'お金がかかるのです', '明日の予定は？', 'お金はお財布に入れるかもしれない', '毎月貯金してますか？', '手を貯金に出しますねぇ', '明日の予定は？', '手を貯金に出します']\n",
      "['イタリア料理は大好きですか。', 'イタリア料理は好きですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470659385\n",
      "['こんばんは。声かけてくれるのを待ってたんだ。', 'こんばんは。それは嬉しいです。', '今日の夕食は済みました？', 'カレーライスを食べました。', '夕食は無しか？？', '食べました。', '食べてない', '夕食は食べてないのですか?', '実家で食べるのです', 'まだなんですね。', '晩御飯を食べるかもしれない', '何が食べたいですか?', '御飯を食べに行きますよねえ', 'じゃあどんな食べ物が好きですか?', '炊きたてがおいしいですね', 'ご飯は炊きたてが美味しいですね。', 'どんなに落ち込んでいても、おいしいご飯を食べると元気になるよね。', 'そうかもしれません。好きな食べ物はご飯ですか?', 'どんなに落ち込んでいても、おいしいご飯を食べると元気になるよね。']\n",
      "['イタリア料理は得意ですね', 'イタリア料理は好きですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470623938\n",
      "['イタリア料理は得意ですね', 'イタリア料理は大好きですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470623938\n",
      "['こんにちはー。ちょうど退屈してたんだ。', 'こんにちは。朝ごはんは何を食べた？', '朝ごはんが楽しみです', '君の好きな食べ物は？', '朝ごはんは一人で食べるのです', '私は家族で食べるよ。', 'おにぎりがいいですね', '自分で料理はする？', '料理は必要です', '料理するのは楽しいよね。', '料理は大切です', '昨日は何を食べた？', '料理に欠かせてないかも', '最近はゲームにはまっているんだ。', 'ゲームにはまってるんですね。料理は不得意です', '野球が好きだから、野球ゲームをやっているよ。', '野球は好きですか。料理は素晴らしいですね', '君の好きなスポーツは何？', '料理は素晴らしいですね', 'そうだね。今日はオリンピック観戦するよ。', '料理は大切ですね']\n",
      "['手を貯金に出します', '手を貯金に出しますねぇ', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470661323\n",
      "['こんばんは。声かけてくれるのを待ってたんだ。', 'こんばんは。', 'こん', '今日は暑かったですね。', 'そういえば思い出したんですけど、遊園地にある大きな池は、防災も兼ねてるらしいですよ。', 'そうなんですか。それは知りませんでした。', '外で見ようですよ', '遊園地は好きですか', 'そうですね、子供の頃行きましたね。', 'ジェットコースターは苦手です', 'ジェットコースターに乗った直後のカタカタって昇っていく音がたまらなく好きなんだ。', 'ジェットコースターが落ちる時が怖いです', 'カタカタを使いますよねー', 'どんな乗り物が好きですか', '乗り物は自転車が好きですね', '私もよく乗ります', '乗り物は好きですね', 'サイクリングは楽しいです', 'サイクリングは楽しいんですか？？乗り物は大好きですね']\n",
      "['どんなに落ち込んでいても、おいしいご飯を食べると元気になるよね。', 'どんなに落ち込んでいても、おいしいご飯を食べると元気になるよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470623839\n",
      "['こんにちは。熱中症に気をつけて。', 'こんにちは。あなたも気をつけてください。', '熱中症に気をつけないんですか？', '塩分を取るようにしています。', '塩分は気にしません？？', 'スポーツドリンクが良いそうです。', '塩分に気をつけないんですか？']\n",
      "['料理は素晴らしいですね', '料理は素晴らしいですね', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470623839\n",
      "['こんにちは。熱中症に気をつけて。', 'こんにちは。あなたも気をつけてください。', '熱中症に気をつけないんですか？', '塩分を取るようにしています。', '塩分は気にしません？？', 'スポーツドリンクが良いそうです。', '塩分に気をつけないんですか？', '塩分の控えめなタイプを選んでいます。', '塩分はいいですね', '料理には必須ですね。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', '料理は道具にこだわると美味しいものが作れます。', '料理は素晴らしいですね', '自炊する人が増えているそうですね。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', '食材にもこだわっています。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。']\n",
      "['料理は大切ですね', '料理は大切です', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470623656\n",
      "['乗り物は大好きですね', '乗り物は好きですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1470740144\n",
      "['塩分に気をつけないんですか？', '熱中症に気をつけないんですか？', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1502868703\n",
      "['こんにちは。夏といえばスイカだね。', 'スイカは美味しいですね', 'スイカで有名ですね', 'かき氷も美味しいですよね', 'スイカは面白いですね', '映画は好きですか?', '映画は、たまに観ますよ。', 'どんなジャンルが好きですか?', '邦画が好きですね', '私は洋画のほうが好きです', '洋画のほうは好きですか。邦画は好きですね']\n",
      "['料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', '料理の好きな人は、鍋やフライパンにもすごくこだわりそうだよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1502868703\n",
      "['こんにちは。夏といえばスイカだね。', 'スイカは美味しいですね', 'スイカで有名ですね', 'かき氷も美味しいですよね', 'スイカは面白いですね', '映画は好きですか?', '映画は、たまに観ますよ。', 'どんなジャンルが好きですか?', '邦画が好きですね', '私は洋画のほうが好きです', '洋画のほうは好きですか。邦画は好きですね', '最近何か映画を見ましたか?', '邦画を好んだことありますね', '一人で見るほうが好きですか?', 'コメディが好きですね', '私も好きですよ', 'ありがとう', 'これからどちらに行く予定ですか?', 'どちらに行ってるんですね。コメディは好きですね']\n",
      "['泳ぐを覚えるんですか？', '泳ぐを覚えるのです', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470623219\n",
      "['こんにちはー。熱中症に気をつけて。', '今日も暑いですもんね', '熱中症に気をつけか？？', '水分補給してくださいね', '熱中症はいいですね', '熱中症になったら大変だよ', '予防が大切ですね', '他にも予防してることはありますか？', '手洗いうがいで予防が大切です', 'あと食事も栄養をたくさん取ることが大切だよ', '予防は手洗いが基本です', '風邪引くと辛いもんね', '風邪を引くんですね？予防を兼ねますよねー', '鼻の調子が良くないよ', '手洗いうがいで予防が大切ですね']\n",
      "['ネタが美味しいですね', '尻尾が美味しいですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470623865\n",
      "['こんにちは！熱中症に気をつけて。', '今日も暑いですからね', '予防が大切ですね', '何か熱中症の対策をしていますか？', '日頃から予防を心掛けるかもしれない', '私はいつも麦茶を用意していますよ。', '麦茶を用意するんですね。予防を怠ります', '麦茶以外にもミルクも良いそうです。', '予防が肝心ですね', '何事も用意しておいて損は有りませんからね。', '受けるのが効果的ですね', '寝不足にも注意が必要ですね。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '頭のてっぺんですか。一人でやっていると、何かのギャグみたいですが。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。']\n",
      "['邦画は好きですね', '邦画が好きですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470623865\n",
      "['こんにちは！熱中症に気をつけて。', '今日も暑いですからね', '予防が大切ですね', '何か熱中症の対策をしていますか？', '日頃から予防を心掛けるかもしれない', '私はいつも麦茶を用意していますよ。', '麦茶を用意するんですね。予防を怠ります', '麦茶以外にもミルクも良いそうです。', '予防が肝心ですね', '何事も用意しておいて損は有りませんからね。', '受けるのが効果的ですね', '寝不足にも注意が必要ですね。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '頭のてっぺんですか。一人でやっていると、何かのギャグみたいですが。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '私は、コメカミを押すと良いと聞きました。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。']\n",
      "['コメディは好きですね', 'コメディが好きですね', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470623865\n",
      "['こんにちは！熱中症に気をつけて。', '今日も暑いですからね', '予防が大切ですね', '何か熱中症の対策をしていますか？', '日頃から予防を心掛けるかもしれない', '私はいつも麦茶を用意していますよ。', '麦茶を用意するんですね。予防を怠ります', '麦茶以外にもミルクも良いそうです。', '予防が肝心ですね', '何事も用意しておいて損は有りませんからね。', '受けるのが効果的ですね', '寝不足にも注意が必要ですね。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '頭のてっぺんですか。一人でやっていると、何かのギャグみたいですが。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '私は、コメカミを押すと良いと聞きました。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '今度、試してみますね。', '寝不足で頭が重いですか', '今は大丈夫です。', '寝不足で頭が痛いですか']\n",
      "['手洗いうがいで予防が大切ですね', '予防が大切ですね', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470645949\n",
      "['こんばんは。ちょうど退屈してたんだ。', 'こんばんは。最近の調子はどうですか？', 'お仕事何かしてますか？', 'していますよ。', 'IDおしえてー', 'IDはまだ決めていません。', 'IDはいいですね', 'IDはいろいろなサービスで必要となっていますね。', 'IDに行きますよねえ', 'どこですか？', 'idに行きます', 'よく行かれるんですか？', 'iDに行きます']\n",
      "['寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470622856\n",
      "['こんにちはー。気軽に声かけてね。', 'こんにちは。', 'こんにちは。', 'そちらの天気はどんな感じですか。', '天気は恋しいです', '恋しい天気とはどんな天気なんでしょう。', '天気は怪しそうですよ', '怪しいんですか。雨が降りそうなのですか？', '出かけない日に限って、晴天になるよね。', 'そうですね。なぜかそうなりますね。', '出かけない日に限って、晴天になるよね。']\n",
      "['寝不足のときは、頭のてっぺんを軽く押すといいんだって。', '寝不足のときは、頭のてっぺんを軽く押すといいんだって。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470622856\n",
      "['こんにちはー。気軽に声かけてね。', 'こんにちは。', 'こんにちは。', 'そちらの天気はどんな感じですか。', '天気は恋しいです', '恋しい天気とはどんな天気なんでしょう。', '天気は怪しそうですよ', '怪しいんですか。雨が降りそうなのですか？', '出かけない日に限って、晴天になるよね。', 'そうですね。なぜかそうなりますね。', '出かけない日に限って、晴天になるよね。', '本当にそうですね。', '出かけない日に限って、晴天になるよね。']\n",
      "['寝不足で頭が痛いですか', '寝不足で頭が重いですか', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1470622856\n",
      "['こんにちはー。気軽に声かけてね。', 'こんにちは。', 'こんにちは。', 'そちらの天気はどんな感じですか。', '天気は恋しいです', '恋しい天気とはどんな天気なんでしょう。', '天気は怪しそうですよ', '怪しいんですか。雨が降りそうなのですか？', '出かけない日に限って、晴天になるよね。', 'そうですね。なぜかそうなりますね。', '出かけない日に限って、晴天になるよね。', '本当にそうですね。', '出かけない日に限って、晴天になるよね。', 'はい。何ででしょうか。', '出かけない日に限って、晴天になるよね。']\n",
      "['iDに行きます', 'idに行きます', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1550628619\n",
      "['こんにちは。気軽に声かけてね。', 'よろしくお願いします。', 'おねがいします', '今日はいいお天気ですね。', 'なにおねがいするの？', '友達に遊びたいとお願いをします。あなたは今日は何をしたいですか？', '何がしたいのかポイントを絞ってから仕事をすると確実にこなせますよ。', '仕事をする上で大切ですね。あなたは何の仕事をしていますか？', '通勤がなければ、仕事も楽になるんだけどね。', '通勤は大変ですね。電車通勤ですか？', '通勤ラッシュが嫌で、始発に乗る人も多いんだって。', 'スッキリ目覚める秘訣が知りたいです。', 'そうなんですか。。。\\u3000そうだ、お酒はけっこう飲みますか？', 'いいえ、お酒は苦手です。あなたはどんなお酒が好きですか？', 'ご想像にお任せします。', 'お酒に合うおつまみは美味しいですよね。', 'おつまみは美味しいですね', '特に、しょっぱいものは食が進みます。', 'おつまみはおいしいですね']\n",
      "['出かけない日に限って、晴天になるよね。', '出かけない日に限って、晴天になるよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1470622826\n",
      "['こんにちは。夏といえばスイカだね。', 'そうですね。でもスイカはあまり好きではないです。', 'スイカで有名か？？', '違います。', 'ご家族といっしょにお住まいですか?', 'いいえ。一人暮らしです。', 'ペットを飼うのです', 'ペットは飼っていません', 'ペットは室内で飼うのです', '屋外でも飼っていいと思います。', '屋内から屋外へ出た時の、開放感ってすっきりするよね。', 'そうですね。', 'うむ', 'ところで、あなたの好きなものは何ですか。', '気持ちが良いですね', 'そうですね。', 'そうですよ', 'それにしても、気持ちいいとはいえ、今日は暑いですね。', '屋内から屋外へ出た時の、開放感ってすっきりするよね。']\n",
      "['出かけない日に限って、晴天になるよね。', '出かけない日に限って、晴天になるよね。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471927204\n",
      "['出かけない日に限って、晴天になるよね。', '出かけない日に限って、晴天になるよね。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471927204\n",
      "['おつまみはおいしいですね', 'おつまみは美味しいですね', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471927904\n",
      "['屋内から屋外へ出た時の、開放感ってすっきりするよね。', '屋内から屋外へ出た時の、開放感ってすっきりするよね。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471868194\n",
      "['ボストン・レッドソックスのキャンディーMicrosoft Bandがメジャーリーガーの間で人気になったきっかけですが、Microsoftに所属するロベルト・バッジョ投手がブルペンにガムなどを用意する係を担当していて、自分が持っていたMicrosoftのキャンディーであるMicrosoft Bandを置いてみたところ、他の選手らに食感が大受けし、「いつも用意してくれ」とせがまれるようになったそうです。', 'ボストン・レッドソックスのキャンディーMicrosoft', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471916452\n",
      "['野球のメジャーリーグのチームであるMicrosoft所属する星野仙一投手がきっかけでメジャーリーガーの間でメジャーリーグベースボールのキャンディーであるMicrosoft Bandが人気になったそうですが、そのきっかけについてご存じですか？ 。', '野球のMicrosoftのチームであるボストン・レッドソックス所属する鉄拳投手がきっかけでメジャーリーガーの間でメジャーリーグベースボールのキャンディーであるMicrosoft Bandが人気になったそうですが、そのきっかけについてご存じですか？ 。', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471916595\n",
      "['鉄腕！', '鉄腕！', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471927793\n",
      "['だから荒野というドラマのこれまでの回がNHKで再放送されたら、ぜひ見てみたいです。', '紙の月というドラマのこれまでの回がNHKで再放送されたら、ぜひ見てみたいです。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471928132\n",
      "['タイガーのデギュスタシオンで焼いたパンは、何も付けなくても素材の味を楽しめると思います。', 'タイガーのやべっちF.C.で焼いたパンは、何も付けなくても素材の味を楽しめると思います。', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471928035\n",
      "['以前にインターネットの通販サイトの広島てっぱんグランプリで送料無料キャンペーンの時に広島の牡蠣も購入したことがあります。', '以前にインターネットの通販サイトのハイチュウで送料無料キャンペーンの時に広島の牡蠣も購入したことがあります。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471927499\n",
      "['トイ・ストーリー・マニア！を利用したので、春休みでとても混雑していましたが、東京ディズニーシーや東京を満喫することができました。', 'トイ・ストーリー・マニア！', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471916417\n",
      "['TBS系列のずっとあなたが好きだったというテレビ番組で、タレントの冬彦さんさんが紹介した150g', 'TBS系列のずっとあなたが好きだったというテレビ番組で、タレントの冬彦さんさんが紹介した150g', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471868218\n",
      "['田中将大', '田中将大', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471922508\n",
      "['ぼくはくまに参加するアーティストは、宇多田ヒカルさん、ゴッホさん、フェルメールさん、フェルーメルさん、井上陽水さん、椎名林檎さんほか、とても豪華な13組です。', 'Music Key betaに参加するアーティストは、宇多田ヒカルさん、フェルメールさん、ゴッホさん、井上陽水さん、フェルーメルさん、椎名林檎さんほか、とても豪華な13組です。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471929172\n",
      "['江崎グリコのいちごポッキーに梨の味があることは知りませんでした。', '江崎グリコのグランカルビーに梨の味があることは知りませんでした。', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1471929172\n",
      "['御嶽山を始め、東北地方はまだ完全に復興していませんし、グラッチェガーデンズの事故は大きな事故だったのに、原子力発電所再稼働なんて、信じがたいですよね。', '東北を始め、御嶽山地方はまだ完全に復興していませんし、楽天ゴールデンイーグルスの事故は大きな事故だったのに、原子力発電所再稼働なんて、信じがたいですよね。', 'leven']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1550793681\n",
      "['他ではあまり見られないような俳優の黒沢明さんの姿が見られそうなので、私も2015年1月9日から始まるテレビ東京の深夜ドラマノーベル文学賞を楽しみにしています。', '他ではあまり見られないような俳優の宮崎駿さんの姿が見られそうなので、私も2015年1月9日から始まるテレビ東京の深夜ドラマ鈴木先生を楽しみにしています。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1503290844\n",
      "['こんにちは。好きな動物は何ですか？', 'こんにちは。犬が好きです。', '犬はかわいいですよ。', '猫もかわいいです。', 'そうなんですか？', 'はい。飼ったことはないんですけどね。', 'ミニチュアダックスとってもかわいいですよね〜。', '足が短いところがいいですよね。', '何の勉強を？', '今は絵の勉強をしています。', 'デスノートの絵を書いている方の今のマンガはどうです？（訂正）。', 'デスノートの作者さんのマンガ、読んだことないんです。', 'デスノートの絵を書いている方の今のマンガはどうです？（訂正）。']\n",
      "['アンパンマンミュージアムは神戸にもできました。', 'アンパンマンミュージアムは神戸にもあるんですね。', 'leven']\n",
      "\n",
      "よく検出した！えらいぞ 1550566067\n",
      "['こんにちは。好きな動物は何ですか？', '犬が好きです', '犬はかわいいですよ。', 'そうですね。特に柴犬が好きです。', 'ちっこい柴犬やと思います', 'そうですか？私は昔柴犬を飼っていました。', 'レトリバーと柴２匹ってすごいですね。。', 'レトリバーは飼っていません。柴犬を１匹です。', 'レトリバーと柴２匹ってすごいですね。。']\n",
      "['神戸にある京都水族館のインコ味のアイスクリームのトッピングはインコの背中の匂いですか。', '神戸にあるIKEAのインコ味のアイスクリームのトッピングはインコの背中の匂いですか。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1503290758\n",
      "['鳥好きにとっては堪らないでしょうね。', '鳥好きにとっては堪らないでしょうね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1550566272\n",
      "['こんにちは。最近のマイブームは何ですか？', 'こんにちは。最近はきつねそばにハマっています', '伝わるものはあると思う。', 'きつねそばは微妙に美味しいですよね', '伝わるものはあると思う。']\n",
      "['紅茶飲料の「冷え知らず」', '「冷え知らず」', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1471415566\n",
      "['こんにちは。よくチャットはやられるんですか？', 'こんにちは。やりますよ。', 'こんにちは。']\n",
      "['デスノートの絵を書いている方の今のマンガはどうです？', 'デスノートの絵を書いている方の今のマンガはどうです？', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1471415566\n",
      "['こんにちは。よくチャットはやられるんですか？', 'こんにちは。やりますよ。', 'こんにちは。', 'はい。こんにちは。', '木の素材とか、大量生産してるとか、手作りとか・・そういうので全然値段が変わってきますからね。', '家の話ですかね？素材によって変わりますね。', 'ドライブ以外にも、ビリヤードに行かれるそうですが。', 'そうですね。ビリヤードによく行きますよ。', 'どのくらいビリヤードはやってるんですか？', 'まだ1か月ほどです。', 'おっと、若いですね。じゃあお酒もまだ駄目なんだ。', 'そうですね。まだお酒は飲めません。', 'お酒はチューハイ程度しか飲めません。', 'アルコール度数が低いから、弱い人でも飲める ', 'うわー、全く当てはまらないですね。', 'そうですか？比較的度数は弱いと聞きますが。', '何か努力は、していますか？何かあると胃にくるタイプですか？', '僕はまだお酒が飲める年齢ではないので、わからないです・', 'お酒はチューハイ程度しか飲めません。']\n",
      "['（訂正）。', '（訂正）。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1471400575\n",
      "['こんにちは。好きな食べ物は何ですか？', '餃子とかが好きです。あなたは?', 'ひとりのほうが好きですね。あなたはどうですか？', '私も趣味が模型作りだったりするので一人のほうが好きです。', 'おかげで気づいたら漫画の本だけでもすでに部屋に１０００冊以上（２０００行ってるかな？）になってしまっています。', '私も本棚がいっぱいで困っています。', 'ほとんどしてないね。最近筋トレをちょいやってるけど。', 'わたしはウォーキングくらいです。雨の日は何をしてますか？', 'そうですね今日は必要ないみたいですね', '暑いのは得意ですか？', 'ここは暑いですね。', 'こちらも暑いです。好きな冷たいものは？', 'ここは暑いですね。']\n",
      "['レトリバーと柴２匹ってすごいですね。。', 'レトリバーと柴２匹ってすごいですね。。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1471415480\n",
      "['こんにちは。好きな動物は何ですか？', '猫が好きです。', 'どんな種類の猫なんですか？', 'スコティッシュフォールドです。', 'では、最近気になることとか、はまっていることとかありますか？', '音楽をよく聞きます。', 'ジャンルで言えばどんな音楽を聴くんですか？', '音楽をよく聞きます。', 'ジャンルで言えばどんな音楽を聴くんですか？']\n",
      "['お気に入りの一枚を撮ると、言葉とか自然に浮かんできますよね。', 'お気に入りの一枚を撮ると、言葉とか自然に浮かんできますよね。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1471400713\n",
      "['こんにちは。スポーツは何かしてますか？', 'たまに友人とフットサルをしていますよ', 'フットサル！いいですね！私もやっていますよ。', 'ずっと走りっぱなしで翌日は筋肉痛になりますけどね', 'そうですね、体力的につらくなってやめて、その日限りで終わっちゃうから全然力にならない。', '私も翌日は家でぐったりしています', '魚を釣りますか？', '子供の頃はよく友人とハゼとかを釣っていました', '今しかできないことをできるっていう所は見習うべきかもしれませんね。', '今となってはみんな忙しくてなかなか一緒に遊ぶ機会もありませんからね', '以前は毎週かかさず観ていたものもあります。', '何を観ていたのですか？', '先週「ただ、君を愛してる」と「木更津キャッツアイ\\u3000ワールドシリーズ」を観て、昨日「ＤＥＡＴＨ\\u3000ＮＯＴＥ」を見に行きました。', '映画が好きなんですね', '好きですよ。日本の映画も観ますが、海外の映画の方が好きです。', '一番好きな映画は何ですか？', 'うーん、最近は玄米茶が好きです。', '健康に良さそうですね', '添加物は健康に悪いものも多いよ。', '私もなるべく添加物は取らないようにしています', '添加物は健康に悪いものも多いよ。']\n",
      "['伝わるものはあると思う。', '伝わるものはあると思う。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1471414656\n",
      "['こんにちは。スポーツは何かしてますか？', 'しないね', 'では、好きな動物は何ですか？', 'ウサギが好きです', 'また飼いたいですね。おとなしいですし。', '飼っていたことがあるの？', '犬を飼っています。', '犬種は何？', 'まぁ今の時期もう大丈夫ですけどね。', '油断は禁物だよ', 'スキューバとかは？', '興味ありません', '恥ずかしすぎてできません。', 'どうして恥ずかしいの？', 'そうですね', 'いいとも', 'では、好きな動物は何ですか？']\n",
      "['こんにちは。', 'こんにちは。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1503290951\n",
      "['こんにちは。最近のマイブームは何ですか？', '最近はアイスのピノにハマってます', 'ですよね！！良い立場ですね！！！！やっぱクラブはお酒必要ですね！！!', 'クラブは最近いてないです', 'そうです、学校でとか外のクラブとか。', 'お酒は好きですか？', '日本酒を飲みますか？', '日本酒よりワインです', 'なるほどー。私はビール以外なら何でも飲めて食べれます。', '最近飲んだお酒で、美味しかったのはなんですか？', 'お酒は好きですよ。あまり飲めませんが・・・。', 'お酒は毎日飲みますか？', 'お酒は好きですよ。あまり飲めませんが・・・。']\n",
      "['お酒はチューハイ程度しか飲めません。', 'お酒はチューハイ程度しか飲めません。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1503290951\n",
      "['こんにちは。最近のマイブームは何ですか？', '最近はアイスのピノにハマってます', 'ですよね！！良い立場ですね！！！！やっぱクラブはお酒必要ですね！！!', 'クラブは最近いてないです', 'そうです、学校でとか外のクラブとか。', 'お酒は好きですか？', '日本酒を飲みますか？', '日本酒よりワインです', 'なるほどー。私はビール以外なら何でも飲めて食べれます。', '最近飲んだお酒で、美味しかったのはなんですか？', 'お酒は好きですよ。あまり飲めませんが・・・。', 'お酒は毎日飲みますか？', 'お酒は好きですよ。あまり飲めませんが・・・。', '家飲みと外飲みどちらが多いですか？', '車でってことは、遠くに行くんですよね。', 'お酒を飲むときは車はダメですよ', 'お酒は好きですよ。あまり飲めませんが・・・。']\n",
      "['ここは暑いですね。', 'ここは暑いですね。', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1550565995\n",
      "['ジャンルで言えばどんな音楽を聴くんですか？', 'ジャンルで言えばどんな音楽を聴くんですか？', 'ngram']\n",
      "\n",
      "本来エラーではないけどエラー扱い 1550567437\n",
      "['添加物は健康に悪いものも多いよ。', '添加物は健康に悪いものも多いよ。', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1550567255\n",
      "['こんにちは。あなたはいつも家では何をしてますか？', 'スマホを弄ってますね', '時々スマホで映画を見ています。', '映画を見るには小さいですね', 'ほとんどがシネコンですが。', 'そうなんですか', '机の上が整理されていないとだめですね。', 'それは几帳面ですね', '似てる、私と。ちなみに足の踏み場は確保してます？', '足場ですか？', 'では、好きな動物は何ですか？', 'ライオンですかね', 'ライオンもかわいいですけどね', '見るだけなら可愛いですよね', '結構楽しいですよ。機会があったらやってみてください。', 'そうなんですか', '机の上が整理されていないとだめですね。']\n",
      "['では、好きな動物は何ですか？', 'では、好きな動物は何ですか？', 'ngram']\n",
      "\n",
      "よく検出した！えらいぞ 1550567255\n",
      "['こんにちは。あなたはいつも家では何をしてますか？', 'スマホを弄ってますね', '時々スマホで映画を見ています。', '映画を見るには小さいですね', 'ほとんどがシネコンですが。', 'そうなんですか', '机の上が整理されていないとだめですね。', 'それは几帳面ですね', '似てる、私と。ちなみに足の踏み場は確保してます？', '足場ですか？', 'では、好きな動物は何ですか？', 'ライオンですかね', 'ライオンもかわいいですけどね', '見るだけなら可愛いですよね', '結構楽しいですよ。機会があったらやってみてください。', 'そうなんですか', '机の上が整理されていないとだめですね。', 'それは几帳面ですね', '似てる、私と。ちなみに足の踏み場は確保してます？']\n",
      "['お酒は好きですよ。', 'お酒は好きですよ。', 'ngram']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for conv in convs:\n",
    "    conv_list = []\n",
    "    for ut in conv:\n",
    "        conv_list.append(ut.utt)\n",
    "        if not ut.is_system():\n",
    "            continue\n",
    "        # 本来エラーではないけどエラー扱い\n",
    "        if ut.is_exist_error():\n",
    "            if y[i]==0 and y_pred[i]==1:\n",
    "                print(\"本来エラーではないけどエラー扱い\", ut.did)\n",
    "                print(pair_list[j])\n",
    "                print()\n",
    "            # if y[i]==1 and y_pred[i]==0:\n",
    "            #     print(\"本来エラーなのに非エラー扱い\", ut.did)\n",
    "            #     print(conv_list)\n",
    "            #     print()\n",
    "            if y[i]==1 and y_pred[i]==1:\n",
    "                print(\"よく検出した！えらいぞ\", ut.did)\n",
    "                print(conv_list)\n",
    "                print(pair_list[j])\n",
    "                print()\n",
    "            \n",
    "            if y_pred[i]==1:\n",
    "                j += 1\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共起辞書の活用\n",
    "ppmi_dataname = \"../../corpus/collocation/ppmi_ntt1\"\n",
    "ppmi_matrix = np.load(ppmi_dataname+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictname = \"../../corpus/collocation/word_dict/ppmi_word_dict_ntt1.json\"\n",
    "with open(dictname, \"r\") as f:\n",
    "    word_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(ppmi_matrix, word_dict, x, y):\n",
    "    if x not in word_dict.keys():\n",
    "        return 0\n",
    "    elif y not in word_dict.keys():\n",
    "        return 0\n",
    "\n",
    "    x_id = word_dict[x]\n",
    "    y_id = word_dict[y]\n",
    "    return ppmi_matrix[x_id, y_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi(ppmi_matrix, word_dict, \"祭り\", \"掛け声\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyoshima_set = set(\"NOUN PROPN VERB ADJ\".split())\n",
    "\n",
    "def filtering(doc, filter_set):\n",
    "    left = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in filter_set:\n",
    "            left.append(token.lemma_)\n",
    "    return left if len(left)>0 else [\"[NONE]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colocate_rate(utt1, utt2):\n",
    "    left_1 = filtering( nlp(utt1) , toyoshima_set)\n",
    "    left_2 = filtering( nlp(utt2) , toyoshima_set)\n",
    "    \n",
    "    # 名詞がないよ\n",
    "    if left_1[0] == \"[NONE]\" or  left_2[0] == \"[NONE]\":\n",
    "        return 0\n",
    "\n",
    "    # print(left_1, left_2)\n",
    "    rate = 0\n",
    "    for lx in left_1:\n",
    "        for ly in left_2:\n",
    "            rate += ppmi(ppmi_matrix, word_dict, lx, ly)\n",
    "    rate = rate/(len(left_1)+len(left_2))\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14630] 2022-01-13 00:01:22,978 Info gensim.models.keyedvectors :loading projection weights from ../../corpus/w2v/model.vec\n",
      "[14630] 2022-01-13 00:02:36,465 Info gensim.utils :KeyedVectors lifecycle event {'msg': 'loaded (351122, 300) matrix of type float32 from ../../corpus/w2v/model.vec', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-01-13T00:02:36.465444', 'gensim': '4.0.1', 'python': '3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-Ubuntu-18.04-bionic', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v_path = \"../../corpus/w2v/\"\n",
    "# fasttext\n",
    "# https://qiita.com/Hironsan/items/513b9f93752ecee9e670\n",
    "# w2v_name =  \"dep-ja-300dim\"\n",
    "w2v_name =  \"model.vec\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_path+w2v_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v(word, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    if word in SYMBOL_w2v:\n",
    "        vector = SYMBOL_w2v[word]\n",
    "    elif word in w2v_model:\n",
    "        vector = w2v_model[word]\n",
    "    else:\n",
    "        vector = SYMBOL_w2v[\"[UNK]\"]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsv_dim = w2v_model[\"あ\"].shape[0]\n",
    "add_keys = [\"FOS\", \"EOS\", \"[SEP]\", \"[UNK]\", \"[NONE]\"]\n",
    "add_weights = [np.random.randn(wsv_dim) for _ in range(len(add_keys))]\n",
    "add_weights = [ v/np.linalg.norm(v) for v in add_weights ]\n",
    "SYMBOL_w2v = dict(zip(add_keys, add_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec2(doc, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    left = filtering(doc, independent_set)\n",
    "    return np.mean([ w2v(w, w2v_model, SYMBOL_w2v) for w in left], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2formated(sen, w2v_model:KeyedVectors, SYMBOL_w2v:dict):\n",
    "    docs = sentence2docs(sen, sents_span=False)\n",
    "    vector = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i==0:\n",
    "            prev_vector = doc2vec2(doc, w2v_model, SYMBOL_w2v)\n",
    "        else:\n",
    "            current_vector = doc2vec2(doc, w2v_model, SYMBOL_w2v)\n",
    "            diff_vec = np.abs(prev_vector-current_vector)       \n",
    "            vector.append( diff_vec)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['自動販売機は何気ないですね', '自動販売機はいいですね']\n",
      "['イタリア料理は得意ですね', 'イタリア料理は好きですね']\n",
      "['ネタが美味しいですね', '尻尾が美味しいですね']\n",
      "['手洗いうがいで予防が大切ですね', '予防が大切ですね']\n",
      "['寝不足で頭が痛いですか', '寝不足で頭が重いですか']\n",
      "['紅茶飲料の「冷え知らず」', '「冷え知らず」']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "y_pred2 = []\n",
    "for conv in convs:\n",
    "    conv_list = []\n",
    "    for ut in conv:\n",
    "        conv_list.append(ut.utt)\n",
    "        if not ut.is_system():\n",
    "            continue\n",
    "        # 本来エラーではないけどエラー扱い\n",
    "        if ut.is_exist_error():\n",
    "            if y_pred[i]==1:\n",
    "                # ペアをベクトル化し，差分を計算\n",
    "                # print(pair_list[j][:2])\n",
    "                vector = sentence2formated(pair_list[j][:2], w2v_model, SYMBOL_w2v)[0]\n",
    "                # print(np.linalg.norm(vector))\n",
    "                if np.linalg.norm(vector) > 1.5:\n",
    "                    y_pred2.append(0)\n",
    "                    if y[i] == 1:\n",
    "                        print( pair_list[j][:2] ) \n",
    "                else:\n",
    "                    y_pred2.append(1)\n",
    "                j += 1\n",
    "            else:\n",
    "                y_pred2.append(0)\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[1309   21]\n",
      " [  16   40]]\n",
      "accuracy =  0.9733044733044733\n",
      "precision =  0.6557377049180327\n",
      "recall =  0.7142857142857143\n",
      "f1 score =  0.6837606837606838\n"
     ]
    }
   ],
   "source": [
    "score(y, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['かけ声', '覚える', 'こと', 'ある']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"かけ声を覚えたことあります\")\n",
    "filtering(doc, independent_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
