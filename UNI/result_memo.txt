
Twitter API の準備は完了
名大対話コーパスの jsonデータ化も実施


発話　
    文法エラー
    解釈不能

    confusion matrix = 
    [[1357  839]
    [   0    4]]
    accuracy =  0.6186363636363637
    EM: 0.6186363636363637
    F-measure:  0.009445100354191265

応答
    英語のキーワードから，質問，依頼，提案のサンプルとなる1文をそれぞれ約300セット取得
    (./response/ques_logit.ipynb)
    1. 質問 or 依頼 or 提案 or それ以外　を判定する分類子Aを作成(ロジスティック回帰)
        特徴量としては，https://www.anlp.jp/proceedings/annual_meeting/2016/pdf_dir/A7-1.pdf　を参考にした(個々の対話行為の特徴を考慮した自由対話における対話行為推定)
        
        ここのやつバグってるから，それは要修正
        confusion matrix = 
        [[ 59   4  13  18]
        [  6  13   1   4]
        [ 11   0  70   6]
        [  1   1   3 274]]
        accuracy =  0.859504132231405

    
    (./response/ana_req.ipynb)
    2. 各前向き発話に対する後ろ向き発話を取得して，後ろ向き発話を学習した分類子Bを作成(LSTM)
        正解データ : Aで質問と判断されたシステム発話に対するユーザ発話
        不正解データ : Aで質問と判断されたユーザ発話に対して破綻したシステム発話
        confusion matrix = 
        [[23 19]
        [ 9 51]]
        accuracy =  0.7254901960784313
        precision =  0.7285714285714285
        recall =  0.85
        f1 score =  0.7846153846153846

    質問無視 (./response/question.ipynb)
        1. 分類子A, B が共に1となった時に破綻とするルールベース
            corrent_n: 157
            all_tp_one: 306
            rate c: 0.5130718954248366
            rate bad: 0.235
            
        2. 分類子A, B の推定値(確率) + ユーザ，システムの発話ベクトルの差分(770次元)
            confusion matrix = 
            [[328  18]
            [ 22  32]]
            accuracy =  0.9

            corrent_n: 32
            all_tp_one: 54
            rate c: 0.5925925925925926

    依頼無視
        応答と同じような手法で出来ないか検討中

    提案無視
        応答と同じような手法で出来ないか検討中

    
    ＊上の問題を，対話行為推定(Dialogue Act)と絡めて定式化しようと考えているが，無料で使用出来る対話行為タグがついたコーパスが見つからず，テキスト分類のタスクの組み合わせで実現しようと試みている．

    期待無視


文脈 ./context
    話題遷移エラー
        名大対話コーパスを使用した．(./context/nucc_data.ipynb)
        1. コーパス中，対話人数が二人のファイルのみを抽出
        2. ginzaでの形態素解析して，内容語のものを含む発話且つ，それが特定の長さ(3, 4, 5)続く対話を抽出．
        3. 2で抽出した各対話の前半を正例として，後半の各対話の最終発話をランダムに入れ替えた対話を負例(話題遷移エラー)とした

        tp_dnn3.ipynb
            3. の正例，負例で対話長 3, 4, 5 で学習した LSTM モデル
            精度: 0.7677966101694915
        このモデルをそのまま適用したら50%でした．(これもう一度確かめるべき)
        ↓
        全対話長
        test_mddel.ipynb
        全対話例に対して適用した結果
            confusion matrix = 
            [[937 871]
            [ 65 127]]
            accuracy =  0.532
        *備考　全て 0 にした場合，accuracy =  0.904

        2. 全対話に対して適用した結果
            2000対話のうち，破綻数が192 => 9:1=正:負で学習し直し 

            連続4対話の場合
               confusion matrix = 
                [[1733   75]
                [ 181   11]]
                accuracy =  0.872
                EM: 0.872
                F-measure:  0.07913669064748202
            
            ↑について，どうやら
            [U_話題A, S_話題A, U_話題B, S_話題A] 際に検出出来ていない
            →後半の [U_話題B, S_話題A] に限定して，ベクトルの差分で検出

            confusion matrix = 
                [[1658  150]
                [ 167   25]]
                accuracy =  0.8415
                F-measure:  0.1362397820163488
            
            巻き添えが増えて，未検出が減った　が非常に多い
            

            
            もし2発話の差分で行うならば，ゼロ照応を解析する必要がありそう
                ['どうやって覚えたの？', '泳ぐを繰り返すようですよ']
                →['泳ぎをどうやって覚えたの？', '泳ぐを繰り返すようですよ']
            ただそれは面倒なので，精度の関係上
    
    発話意図不明確
        まだ思いついていない


    情報不足
        まだ思いついていない
    

    前向き発話 or 後ろ向き発話の分類をするべき？
    かと思ったので，["質問", "依頼", "提案"]を手動でアノテーションしました
    
    それぞれの数はこんな感じ
    質問
        sys: 286
        usr: 595
    依頼
        sys: 4
        usr: 7
    提案
        sys: 8
        usr: 13
    データが少なすぎるなー

    エラーではない前向きシステム発話 + ユーザの前向き発話 = 全体の前向き発話(214)
    前向きなシステム発話に対するユーザの発話 = 後ろ向き発話(264)

    confusion matrix = 
        [[55  4]
        [ 7 78]]
        accuracy =  0.9236111111111112
        precision =  0.9512195121951219
        recall =  0.9176470588235294
        f1 score =  0.9341317365269461
    
    テストデータ上では，うまく動作しているように見える
    全データでは

    confusion matrix = 
        [[2856  408]
        [ 149  787]]
        accuracy =  0.8673809523809524
        precision =  0.6585774058577406
        recall =  0.8408119658119658
        f1 score =  0.7386203660253403
    
    ちょっと precision が低い
    もうちょっと表層の特徴を見るべきか


---------------
    
    自己矛盾 - 相手の発話との矛盾
        論理的な推論をするモデルを応用すればいけるかも
    
    
    繰り返し
        発話のベクトルの比較で検出可能だろう

        Don’t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training

        話題の切り替えがされているかの検出が必要


        n-gramによる比較
        過去発話中の各文との n-gram(n=3) の集合の一致率
        一致率=0.80 で最大F値
        confusion matrix = 
            [[2131   21]
            [  29   19]]
            accuracy =  0.9772727272727273
            F-measure:  0.43181818181818177
        
        レーベンシュタイン距離の類似度による比較
        confusion matrix = 
            [[2081   71]
            [  17   31]]
            accuracy =  0.96
            F-measure:  0.41333333333333333
        
        組み合わせ(ロジスティック回帰)
        confusion matrix = 
            [[1959  193]
            [  13   35]]
            accuracy =  0.9063636363636364
            precision =  0.15350877192982457
            recall =  0.7291666666666666
            f1 score =  0.2536231884057971

        組み合わせ2(ngram_rate>=0.8 or leven_rate>=0.9:)
            confusion matrix = 
            [[2127   25]
            [  24   24]]
            accuracy =  0.9777272727272728
            precision =  0.4897959183673469
            recall =  0.5
            f1 score =  0.4948453608247423
        
        sentenceBERT
        confusion matrix = 
        [[1788  364]
        [  38   10]]
        accuracy =  0.8172727272727273
        F-measure:  0.04739336492890995

        話題の切り替えを追えていないのが問題



社会
    社会性欠如



出来るだけ1つずつ丁寧に行おうとしてますが，正直パンクしそうです(泣)
