{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# from ..tools.preprocess import Preprocessor\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from tools.maneger import DataManager\n",
    "# from utterance.feature import Feature\n",
    "from feature import Feature"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def json2data(path):\n",
    "    cols = [\"text\", \"label\", \"subLabel\"]\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "    files = os.listdir(path)\n",
    "    for cop in files:\n",
    "        if \".\" not in cop:\n",
    "            continue\n",
    "        with open(path+cop, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            mode = cop.split(\".\")[0]\n",
    "            max_ = 300\n",
    "            for i, data in enumerate( json_data[mode] ) :\n",
    "                if i > max_:\n",
    "                    break\n",
    "                text = data[\"data\"]\n",
    "                label = data[\"label\"][0]\n",
    "                # if label == \"plain\":\n",
    "                #     break\n",
    "                subLabel = \"\"\n",
    "                df = df.append(pd.DataFrame([text, label, subLabel], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "label_list = \"YN WH please proposal plain\".split()\n",
    "label_dict = dict( zip(label_list, range(len(label_list))) )\n",
    "\n",
    "def extract_X_y(df):\n",
    "    X = []\n",
    "    y = []\n",
    "    for te, la in zip(df.text, df.label):\n",
    "        X.append(te)\n",
    "        # if la == \"WH\":\n",
    "        #     y.append(0)\n",
    "        # else:\n",
    "        #     y.append(label_dict[la])\n",
    "        y.append(label_dict[la])\n",
    "    return X, y\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "corpus_root = \"../../corpus\"\n",
    "# name = \"question/short\"\n",
    "name = \"question\"\n",
    "data_path = \"/\".join([corpus_root, name]) + \"/\"\n",
    "data_path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../../corpus/question/'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = json2data(data_path)\n",
    "df\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>subLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>メニューを見せていただけますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>おいでいただけますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>マッシュポテトをもらえますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>伝言を預かっていただけますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ご一緒しませんか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>メンバーになりたいかい？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>明日スタートなさいますか？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>トレイがいりますか？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2階も見たいですか？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>なでてみたい？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text   label subLabel\n",
       "0     メニューを見せていただけますか？  please         \n",
       "1          おいでいただけますか？  please         \n",
       "2      マッシュポテトをもらえますか？  please         \n",
       "3      伝言を預かっていただけますか？  please         \n",
       "4            ご一緒しませんか？  please         \n",
       "...                ...     ...      ...\n",
       "1236      メンバーになりたいかい？      YN         \n",
       "1237     明日スタートなさいますか？      YN         \n",
       "1238        トレイがいりますか？      YN         \n",
       "1239        2階も見たいですか？      YN         \n",
       "1240           なでてみたい？      YN         \n",
       "\n",
       "[1241 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X, y = extract_X_y(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "F_path = \"../X_y_data/response/\"\n",
    "F_name = \"typeClassify_F2.dill\"\n",
    "featureM = DataManager(F_path, format_=\"dill\")\n",
    "\n",
    "# if featureM.is_exist(F_name):\n",
    "#     F = featureM.load_data(F_name)\n",
    "# else:\n",
    "#     F = Feature()\n",
    "#     F.make_features(X_train_str)\n",
    "#     featureM.save_data(F_name, F)\n",
    "\n",
    "F = Feature()\n",
    "F.make_features(X_train_str)\n",
    "# featureM.save_data(F_name, F)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Argument 'text' has incorrect type (expected str, got list)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-77678c805c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# featureM.save_data(F_name, F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MMI/UNI/response/feature.py\u001b[0m in \u001b[0;36mmake_features\u001b[0;34m(self, sentences, len_)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"order\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtype_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MMI/UNI/response/feature.py\u001b[0m in \u001b[0;36mf_normalize_Noun_order\u001b[0;34m(self, sentences, len_)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_normalize_Noun_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun2normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mrandom_deleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiller_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_deleted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MMI/UNI/tools/preproc.py\u001b[0m in \u001b[0;36mnoun2normal\u001b[0;34m(self, sen)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnoun2normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mnormalize_sen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mnormalize_sen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"名詞\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;31m#call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \"\"\"\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/spacy/lang/ja/__init__.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/spacy/lang/ja/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# convert sudachipy.morpheme.Morpheme to DetailedToken and merge continuous spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0msudachipy_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mdtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dtokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msudachipy_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dtokens_and_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'text' has incorrect type (expected str, got list)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "featureM.save_data(F_name, F)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../X_y_data/response/typeClassify_F2.dill\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(F.feature_num)\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i, x_t_str in enumerate( X_train_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_train.append(x)\n",
    "for i, x_t_str in enumerate( X_test_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_test.append(x)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "31690\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr = LogisticRegression(solver='sag', max_iter=10000)\n",
    "lr.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='sag')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = lr.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(label_dict)\n",
    "for y_p, x_s in zip(y_pred[:30], X_test_str[:30]):\n",
    "    print(\"{0} : {1}\".format(y_p, x_s))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'YN': 0, 'WH': 1, 'please': 2, 'proposal': 3, 'plain': 4}\n",
      "3 : お名前は何とおっしゃいますか？\n",
      "4 : 先週いっしょにつくったでしょ。\n",
      "3 : 同じ美容院へ行ったらどう、お父さん?\n",
      "2 : 本題に入ってくれないか？\n",
      "2 : 日曜日に、映画にごいっしょしていただけますか？\n",
      "3 : 青森にいるあなたのお兄さんのヒデキを訪ねるのはどうかしら？\n",
      "0 : これって本当にあなたなの？\n",
      "3 : 日本語を習ってみたら？\n",
      "4 : 申し訳ないけど、知りませんね。\n",
      "0 : ぼくといっしょに取り組まないか？\n",
      "0 : そんなことが信じられるだろうか？\n",
      "0 : エミ叔母ちゃんは何時に来る予定なの？\n",
      "4 : カイはすごく欲しかったんだ。\n",
      "0 : もう質問は終わったかい？\n",
      "2 : それはどんなものだったのか私に説明してもらえますか？\n",
      "3 : 私といっしょに食卓の用意をしてくれない？\n",
      "3 : チケットを取りましょうか？\n",
      "3 : いっしょに散歩に出かけましょうか？\n",
      "2 : 皆さんに自己紹介をお願いできますか？\n",
      "0 : そこにはゲームセンターはある？\n",
      "4 : 「さあ入って、パーティーはちょうど始まるところ。コートを預かりましょうか？」\n",
      "3 : こちらに座りましょうか？\n",
      "4 : わたしの家で課題をしましょうよ。\n",
      "2 : 伝言を預かっていただけますか？\n",
      "3 : よく眠れた？\n",
      "3 : どうしてロボコーパスが戦わなくちゃいけないんだ？\n",
      "0 : 写真をとることはできるかな？\n",
      "0 : 質問してもいいですか？\n",
      "4 : ７月25日だよ。\n",
      "3 : 日本の古い怪談映画の特別プログラムを上映しない？\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[70  5  8  6  2]\n",
      " [11 14  0  6  0]\n",
      " [ 7  0 47  4  2]\n",
      " [ 8  1  4 86  2]\n",
      " [ 0  0  0  1 89]]\n",
      "accuracy =  0.8203753351206434\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_path = \"../models/response/\"\n",
    "model_name = \"typeClassify_M.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "typeClassify_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelM.save_data(model_name, lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/response/typeClassify_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# accuracy =  0.7913907284768212\n",
    "# accuracy =  0.8326446280991735\n",
    "# accuracy =  0.8367768595041323"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# F2_path = \"../X_y_data/response/\"\n",
    "# F2_name = \"typeClassify_F2.dill\"\n",
    "# featureM2 = DataManager(F2_path, format_=\"dill\")\n",
    "\n",
    "# F2 = Feature()\n",
    "# # F2.make_features(X_train_str[:3])\n",
    "# featureM2.save_data(F2_name, F2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "F2.featurization(\"そうですね．最近熱いですから\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'F2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0261a63548d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"そうですね．最近熱いですから\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'F2' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from pyknp import Juman\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import scipy.spatial\n",
    "# model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "# Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "# emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# X_bert = Nmodel.encode(X_train_str)\n",
    "# X_bert_test = Nmodel.encode(X_test_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "est = SVC(kernel=\"rbf\", random_state=2, C=1, gamma=0.01)\n",
    "clf = OneVsRestClassifier(est)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1, gamma=0.01, random_state=2))"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_b = clf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred_b))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred_b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[62  3 10 13  3]\n",
      " [10 15  0  5  1]\n",
      " [ 4  0 48  5  3]\n",
      " [ 4  2  8 84  3]\n",
      " [ 0  0  0  1 89]]\n",
      "accuracy =  0.7989276139410187\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(label_dict)\n",
    "for y_p, x_s in zip(y_pred_b[:30], X_test_str[:30]):\n",
    "    print(\"{0} : {1}\".format(y_p, x_s))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'YN': 0, 'WH': 1, 'please': 2, 'proposal': 3, 'plain': 4}\n",
      "1 : お名前は何とおっしゃいますか？\n",
      "4 : 先週いっしょにつくったでしょ。\n",
      "3 : 同じ美容院へ行ったらどう、お父さん?\n",
      "2 : 本題に入ってくれないか？\n",
      "2 : 日曜日に、映画にごいっしょしていただけますか？\n",
      "3 : 青森にいるあなたのお兄さんのヒデキを訪ねるのはどうかしら？\n",
      "0 : これって本当にあなたなの？\n",
      "3 : 日本語を習ってみたら？\n",
      "4 : 申し訳ないけど、知りませんね。\n",
      "3 : ぼくといっしょに取り組まないか？\n",
      "0 : そんなことが信じられるだろうか？\n",
      "1 : エミ叔母ちゃんは何時に来る予定なの？\n",
      "4 : カイはすごく欲しかったんだ。\n",
      "0 : もう質問は終わったかい？\n",
      "2 : それはどんなものだったのか私に説明してもらえますか？\n",
      "3 : 私といっしょに食卓の用意をしてくれない？\n",
      "3 : チケットを取りましょうか？\n",
      "3 : いっしょに散歩に出かけましょうか？\n",
      "2 : 皆さんに自己紹介をお願いできますか？\n",
      "0 : そこにはゲームセンターはある？\n",
      "4 : 「さあ入って、パーティーはちょうど始まるところ。コートを預かりましょうか？」\n",
      "1 : こちらに座りましょうか？\n",
      "4 : わたしの家で課題をしましょうよ。\n",
      "2 : 伝言を預かっていただけますか？\n",
      "3 : よく眠れた？\n",
      "3 : どうしてロボコーパスが戦わなくちゃいけないんだ？\n",
      "0 : 写真をとることはできるかな？\n",
      "0 : 質問してもいいですか？\n",
      "4 : ７月25日だよ。\n",
      "3 : 日本の古い怪談映画の特別プログラムを上映しない？\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2_path = \"../models/response/\"\n",
    "model2_name = \"typeClassify_SVC.pickle\"\n",
    "model2M = DataManager(model2_path)\n",
    "print(model2_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "typeClassify_SVC.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2M.save_data(model2_name, clf)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/response/typeClassify_SVC.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}