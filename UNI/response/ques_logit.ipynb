{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# from ..tools.preprocess import Preprocessor\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from tools.maneger import DataManager\n",
    "# from utterance.feature import Feature\n",
    "from feature import Feature"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def json2data(path):\n",
    "    cols = [\"text\", \"label\", \"subLabel\"]\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "    files = os.listdir(path)\n",
    "    for cop in files:\n",
    "        if \".\" not in cop:\n",
    "            continue\n",
    "        with open(path+cop, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            mode = cop.split(\".\")[0]\n",
    "            max_ = 300\n",
    "            for i, data in enumerate( json_data[mode] ) :\n",
    "                if i > max_:\n",
    "                    break\n",
    "                text = data[\"data\"]\n",
    "                label = data[\"label\"][0]\n",
    "                # if label == \"plain\":\n",
    "                #     break\n",
    "                subLabel = \"\"\n",
    "                df = df.append(pd.DataFrame([text, label, subLabel], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "label_list = \"YN WH please proposal plain\".split()\n",
    "label_dict = dict( zip(label_list, range(len(label_list))) )\n",
    "\n",
    "def extract_X_y(df):\n",
    "    X = []\n",
    "    y = []\n",
    "    for te, la in zip(df.text, df.label):\n",
    "        X.append(te)\n",
    "        # if la == \"WH\":\n",
    "        #     y.append(0)\n",
    "        # else:\n",
    "        #     y.append(label_dict[la])\n",
    "        y.append(label_dict[la])\n",
    "    return X, y\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "corpus_root = \"../../corpus\"\n",
    "# name = \"question/short\"\n",
    "name = \"question\"\n",
    "data_path = \"/\".join([corpus_root, name]) + \"/\"\n",
    "data_path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../../corpus/question/'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df = json2data(data_path)\n",
    "df\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>subLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>メニューを見せていただけますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>おいでいただけますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>マッシュポテトをもらえますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>伝言を預かっていただけますか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ご一緒しませんか？</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>メンバーになりたいかい？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>明日スタートなさいますか？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>トレイがいりますか？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>2階も見たいですか？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>なでてみたい？</td>\n",
       "      <td>YN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text   label subLabel\n",
       "0     メニューを見せていただけますか？  please         \n",
       "1          おいでいただけますか？  please         \n",
       "2      マッシュポテトをもらえますか？  please         \n",
       "3      伝言を預かっていただけますか？  please         \n",
       "4            ご一緒しませんか？  please         \n",
       "...                ...     ...      ...\n",
       "1236      メンバーになりたいかい？      YN         \n",
       "1237     明日スタートなさいますか？      YN         \n",
       "1238        トレイがいりますか？      YN         \n",
       "1239        2階も見たいですか？      YN         \n",
       "1240           なでてみたい？      YN         \n",
       "\n",
       "[1241 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X, y = extract_X_y(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "F_path = \"../X_y_data/response/\"\n",
    "F_name = \"typeClassify_F.dill\"\n",
    "featureM = DataManager(F_path, format_=\"dill\")\n",
    "\n",
    "# if featureM.is_exist(F_name):\n",
    "#     F = featureM.load_data(F_name)\n",
    "# else:\n",
    "#     F = Feature()\n",
    "#     F.make_features(X_train_str)\n",
    "#     featureM.save_data(F_name, F)\n",
    "\n",
    "F = Feature()\n",
    "F.make_features(X_train_str)\n",
    "featureM.save_data(F_name, F)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n",
      "success save : ../X_y_data/response/typeClassify_F.dill\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(F.feature_num)\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i, x_t_str in enumerate( X_train_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_train.append(x)\n",
    "for i, x_t_str in enumerate( X_test_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_test.append(x)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "31696\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "lr = LogisticRegression(solver='sag', max_iter=10000)\n",
    "lr.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='sag')"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "y_pred = lr.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(label_dict)\n",
    "for y_p, x_s in zip(y_pred[:30], X_test_str[:30]):\n",
    "    print(\"{0} : {1}\".format(y_p, x_s))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'YN': 0, 'WH': 1, 'please': 2, 'proposal': 3, 'plain': 4}\n",
      "0 : お名前は何とおっしゃいますか？\n",
      "4 : 先週いっしょにつくったでしょ。\n",
      "3 : 同じ美容院へ行ったらどう、お父さん?\n",
      "2 : 本題に入ってくれないか？\n",
      "2 : 日曜日に、映画にごいっしょしていただけますか？\n",
      "3 : 青森にいるあなたのお兄さんのヒデキを訪ねるのはどうかしら？\n",
      "0 : これって本当にあなたなの？\n",
      "3 : 日本語を習ってみたら？\n",
      "4 : 申し訳ないけど、知りませんね。\n",
      "0 : ぼくといっしょに取り組まないか？\n",
      "0 : そんなことが信じられるだろうか？\n",
      "1 : エミ叔母ちゃんは何時に来る予定なの？\n",
      "4 : カイはすごく欲しかったんだ。\n",
      "0 : もう質問は終わったかい？\n",
      "2 : それはどんなものだったのか私に説明してもらえますか？\n",
      "3 : 私といっしょに食卓の用意をしてくれない？\n",
      "3 : チケットを取りましょうか？\n",
      "3 : いっしょに散歩に出かけましょうか？\n",
      "2 : 皆さんに自己紹介をお願いできますか？\n",
      "0 : そこにはゲームセンターはある？\n",
      "4 : 「さあ入って、パーティーはちょうど始まるところ。コートを預かりましょうか？」\n",
      "0 : こちらに座りましょうか？\n",
      "4 : わたしの家で課題をしましょうよ。\n",
      "2 : 伝言を預かっていただけますか？\n",
      "3 : よく眠れた？\n",
      "3 : どうしてロボコーパスが戦わなくちゃいけないんだ？\n",
      "0 : 写真をとることはできるかな？\n",
      "2 : 質問してもいいですか？\n",
      "4 : ７月25日だよ。\n",
      "3 : 日本の古い怪談映画の特別プログラムを上映しない？\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "# print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[69  5  7  8  2]\n",
      " [12 13  0  6  0]\n",
      " [ 5  0 46  7  2]\n",
      " [ 6  1  7 84  3]\n",
      " [ 0  0  0  1 89]]\n",
      "accuracy =  0.806970509383378\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "model_path = \"../models/response/\"\n",
    "model_name = \"typeClassify_M.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "typeClassify_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "modelM.save_data(model_name, lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/response/typeClassify_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# accuracy =  0.7913907284768212\n",
    "# accuracy =  0.8326446280991735\n",
    "# accuracy =  0.8367768595041323"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "F2_path = \"../X_y_data/response/\"\n",
    "F2_name = \"typeClassify_F2.dill\"\n",
    "featureM2 = DataManager(F2_path, format_=\"dill\")\n",
    "\n",
    "F2 = Feature()\n",
    "F2.make_features(X_train_str[:3])\n",
    "featureM2.save_data(F2_name, F2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n",
      "success save : ../X_y_data/response/typeClassify_F2.dill\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "F2.featurization(\"そうですね．最近熱いですから\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "from pyknp import Juman\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "X_bert = Nmodel.encode(X_train_str)\n",
    "X_bert_test = Nmodel.encode(X_test_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "est = SVC(kernel=\"rbf\", random_state=2, C=1, gamma=0.01)\n",
    "clf = OneVsRestClassifier(est)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "clf.fit(X_bert, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1, gamma=0.01, random_state=2))"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "y_pred_b = clf.predict(X_bert_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred_b))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred_b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[40  0 13 14 24]\n",
      " [11  7  2  4  7]\n",
      " [ 8  0 33  9 10]\n",
      " [16  2 12 50 21]\n",
      " [ 3  1  0  2 84]]\n",
      "accuracy =  0.5737265415549598\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}