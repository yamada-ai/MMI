{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../datatools')\n",
    "from maneger import DataManager\n",
    "from preproc import Preprocessor\n",
    "# from utterance.feature import Feature\n",
    "from feature import Feature"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'preproc'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ada7466d5de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpreproc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from utterance.feature import Feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/MMI/UNI/response/feature.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdont_write_bytecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'preproc'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "path = '../error_category_classification/dbdc5_ja_dev_labeled/'\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "# datalist = ['DCM']\n",
    "    # List of error types\n",
    "error_types = ['Unclear intention', 'Wrong information',\n",
    "    'Ignore question', 'Topic transition error', \n",
    "    'Lack of information', 'Repetition', \n",
    "    'Contradiction', 'Self-contradiction',\n",
    "    'Lack of common sense', 'Semantic error',\n",
    "    'Grammatical error', 'Ignore proposal', \n",
    "    'Ignore offer', 'Lack of sociality', \n",
    "    'Uninterpretable', 'Ignore greeting', \n",
    "    'No-Err']\n",
    "\n",
    "pre = Preprocessor()\n",
    "df = pre.read_json_with_NoErr(path, datalist)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "F_path = \"../X_y_data/response/\"\n",
    "F_name = \"typeClassify_F.dill\"\n",
    "featureM = DataManager(F_path, format_=\"dill\")\n",
    "\n",
    "F = featureM.load_data(F_name)\n",
    "F.set_preprocessor(pre)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success load : ../X_y_data/response/typeClassify_F.dill\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model_path = \"../models/response/\"\n",
    "model_name = \"typeClassify_M.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "\n",
    "lr = modelM.load_data(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success load : ../models/response/typeClassify_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "label_list = \"YN WH please proposal plain\".split()\n",
    "label_dict = dict( zip(label_list, range(len(label_list))) )\n",
    "label_dict2 = dict( zip(range(len(label_list)), label_list) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def extract_no_error_particular(df, mode):\n",
    "    prev_u = \"\"\n",
    "    utterances = []\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        # print(type(u))\n",
    "        f = F.featurization(s)\n",
    "        y = lr.predict(f.reshape(1,-1))\n",
    "        if mode==\"question\":\n",
    "            if y == 0 or y == 1:\n",
    "                # print(\"y: {0}, s: {1}, \\n u: {2}\\n\".format(label_dict2[int(y)], s, prev_u))\n",
    "                utterances.append([s, prev_u])\n",
    "        elif mode==\"please\":\n",
    "            if y == 2:\n",
    "                utterances.append([s, prev_u])\n",
    "        elif mode==\"proposal\":\n",
    "            if y == 3:\n",
    "                utterances.append([s, prev_u])\n",
    "        prev_u = u\n",
    "    return utterances\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "def extract_error(df, errors):\n",
    "    utterances = []\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        for err in errors:\n",
    "            if err in e:\n",
    "                utterances.append([u, s])\n",
    "    return utterances"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "errors = [\"Ignore proposal\"]\n",
    "mode = \"please\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['海に行かないんですね？', ''],\n",
       " ['外でとります', 'そうらしいですね。いつもスイカの種を噛んで食べていますか？'],\n",
       " ['外食は二人で行きますねぇ', '栄養面を考えて食事をとることは大切ですよね。'],\n",
       " ['海に行かないんですね？', '手洗いは基本だよ。'],\n",
       " ['家族で買い物に行きます？？', '週末、行く予定だよ。'],\n",
       " ['家族で食事に行きますか？', '家族と行く予定です。'],\n",
       " ['家族でどこかに出かけます？？', '買物はたいてい家族と一緒だね。'],\n",
       " ['家族で食べに行きますか？', 'たまに家族で外食に行くよ。'],\n",
       " ['家族で初詣に行くんですか？', 'おばあちゃんちに行くつもりです。'],\n",
       " ['家族で初詣に行ってるんですね。家族で旅行に行ってるのですか？', '食べに行ったり、温泉行ったりします。'],\n",
       " ['退屈を嫌いますか？', 'そうだね。子供を持って初めて、家族の大切さが分かった気がします。'],\n",
       " ['お名前はco.jpに添えます', 'そうですね、海外旅行に行った時なんかは危険が多いのでいろいろ考えながらケースバイケースに対応しますね。'],\n",
       " ['旅行に参加しちゃった', '私はアトムといいます'],\n",
       " ['旅行を振り返りますか', 'どこにいったの？'],\n",
       " ['しりとりでもしましょうか', '奇遇ですね、私も退屈してたとこです。'],\n",
       " ['しりとりを楽しみましょうね', 'じゃあ、果物しりとりしましょう。'],\n",
       " ['紅玉を求めるかもしれない', 'あなたの負けでいいですか？'],\n",
       " ['そういえば、この間、旅行したと伺いましたが、奇遇に驚きます', '何をもらったら喜ぶ？'],\n",
       " ['お天気の良さはどうですか？', 'こんにちは'],\n",
       " ['そういえば、あなたは美味しいものを食べるのが好きでしたよね？スイカは大好きですね', 'スイカは大好きだよ。'],\n",
       " ['ももを探します', 'ぶどうはきらいですか？'],\n",
       " ['熱中症に気をつけないんですか？', 'だよね〜'],\n",
       " ['エゾシカを見ます', 'うん。けっこう会えるよ。'],\n",
       " ['熱中症に気をつけか？？', '子供は好きですか？'],\n",
       " ['爆音で流します', '沢田研二は好きですか'],\n",
       " ['爆音が流れます', 'よく聞く音楽は何ですか'],\n",
       " ['海に行かないんですね？', '爆音で聞く理由は何ですか'],\n",
       " ['労働基準法がわかります', '残業はごくたまにありますね。'],\n",
       " ['朝から海に行きますか？？', '楽しそうですね'],\n",
       " ['仕事ができます', 'こんにちはー'],\n",
       " ['男がすたります', 'あなたは男ですか？女ですか？'],\n",
       " ['日頃から予防を心掛けるらしいです', 'いいですってどっち？'],\n",
       " ['予防を怠るようです', '告白に対して予防が大切！つまり君もどきどきしたってこと？'],\n",
       " ['予防を怠ります', 'ああ。周りの女子の話か。そう？'],\n",
       " ['予防に勝ります', 'いきなり怠るの！？つまり現在はオープン？'],\n",
       " ['予防を心掛けますよねえ', 'つまり間接的なＯＫって思ってよい？'],\n",
       " ['普段から予防を行いますよねー', '勝っちゃたんだ！つまり君は僕よりもどきどきしてるという意味？'],\n",
       " ['胃が悲鳴を上げます', 'こんにちは。今日は体調が良くないんだ。'],\n",
       " ['お酒で有名です', 'もうお酒飲まないのかい？'],\n",
       " ['オリンピックでメダルを目指します', 'それは失礼しました'],\n",
       " ['メダルが決まります', 'オリンピック見てますか？'],\n",
       " ['ほう。\\u3000ところで、登山はお好きですか？', 'こんにちは。'],\n",
       " ['山好きの社員が登山に行きたいです', '本格的ですね。'],\n",
       " ['海に行きませんか？？', 'いいですよね。特に春の桜が好きです。'],\n",
       " ['お祭りをみます', '私は特に打ち上げ花火が見たいです。'],\n",
       " ['「こんにちは」をWikipediaで検索した結果は、「久しぶりこんにちは', '北海道に行ってみたいです。'],\n",
       " ['宮崎で張ります', '山でキャンプはどう？'],\n",
       " ['そういえば、毎日、音楽聴くって話をしてたと思うんですけど、相性が悪いと思いますか？', 'はい'],\n",
       " ['芸を身につけたなあ', '犬のどこが好きですか'],\n",
       " ['海に行かないんですね？', '趣味はいいですね'],\n",
       " ['車で迎えに行きます', '行きますよ。'],\n",
       " ['車で買い物に行くのです', '何で行くの？電車？車？'],\n",
       " ['通り道をふさぎます', '通り道のコンビニで買えばいいですか？'],\n",
       " ['熱中症に気をつけか？？', 'そちらも熱中症に気を付けて下さい。'],\n",
       " ['熱中症に気をつけないんですか？', '明るくて元気そうで良かったです'],\n",
       " ['最近きになるニュースとかあります？', 'あなたは熱中症になったことありますか？'],\n",
       " ['わけぎを使います', '満を待つって何や？'],\n",
       " ['熱中症に気をつけないんですか？', '多いって今言うたやんけ'],\n",
       " ['熱中症に気をつけか？？', 'こんにちわ。毎日暑いよね。'],\n",
       " ['うーむ、なるほど。\\u3000そういえば、最近映画見に行ったりしましたか？', 'ありがとう'],\n",
       " ['海外や外国人にフォーカスをあてた番組として、フジテレビのYouTubeや、→Pia-no-jaC←の世界行ってみたらホントはこんなトコだった！？などありますね。',\n",
       "  'どっきりが好きならYouTubeの動画もおすすめだよ。'],\n",
       " ['どんな本を読みますか？', '沢山の魚やサンゴが観察できるよ'],\n",
       " ['行きましょう', 'バイキングってつい欲張りになって、色々食べ過ぎますよね'],\n",
       " ['そうします', '行くかどうかどうかは時と場合によりますね'],\n",
       " ['どんな本を読みますか？', 'インドア派だから外出はあまりしませんね'],\n",
       " ['ひとりのほうが好きですね。あなたはどうですか？', 'それは先ほどお聞きしてますが、スポーツの話題には詳しいのですね'],\n",
       " ['最後に、マンガでプロになろうと思ってます？', 'やってませんよ。でもジャズも好きです。'],\n",
       " ['ひとりのほうが好きですね。あなたはどうですか？', '私はタケシの番組をよく見ますよ'],\n",
       " ['そうですね〜サーブを思いっきり打って入ったら結構快感ですよ!', 'こんにちは。最近はサイクリングにはまっています。'],\n",
       " ['なぜでしょう？', 'そんなに衝撃的ですか？'],\n",
       " ['飼ってみたら猫好きになりました', '散歩です。私は海沿いを歩くのが大好きです。'],\n",
       " ['最後に、マンガでプロになろうと思ってます？', '楽しいですよ'],\n",
       " ['そうします', '夏も半分終わりましたね'],\n",
       " ['最後に、マンガでプロになろうと思ってます？', '私もほとんど知りません'],\n",
       " ['一緒に夕食を食べに行きますか。', 'スカイプはゲームをする時に良く使います']]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "igque = extract_error(df, errors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "igque_no = extract_no_error_particular(df, mode=mode)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size, batch_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True, bidirectional=True )\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        # self.softmax = \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        _, hidden_layer = self.lstm(x)\n",
    "        # print(hidden_layer)\n",
    "        bilstm_out = torch.cat([hidden_layer[0][0], hidden_layer[0][1]], dim=1)\n",
    "        # y = self.hidden2tag(hidden_layer[0].view(batch_size, -1))\n",
    "\n",
    "        y = self.hidden2tag(bilstm_out)\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from pyknp import Juman\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def make_X(convs):\n",
    "    X_data = []\n",
    "    \n",
    "    for conv in convs :\n",
    "        sentence_vectors = Nmodel.encode(conv)\n",
    "        X_data.append(sentence_vectors)\n",
    "    return np.array(X_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "data_path = \"../X_y_data/response/\"\n",
    "data_name = \"{0}1.pickle\".format(mode)\n",
    "dataM = DataManager(data_path)\n",
    "print(data_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "proposal1.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "if dataM.is_exist(data_name):\n",
    "    \n",
    "    DATA_Xy = dataM.load_data(data_name)\n",
    "    X = DATA_Xy[0]\n",
    "    y = DATA_Xy[1]\n",
    "else:\n",
    "    # X_data, y_data = pre.extract_X_y(df, error_types, seq_len)\n",
    "    X = make_X(igque + igque_no)\n",
    "    y = np.concatenate( [ np.ones(len(igque)), np.zeros(len(igque_no)) ] )\n",
    "    dataM.save_data(data_name, [X, y])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../X_y_data/response/proposal1.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "leng = len(y_train)\n",
    "print(leng)\n",
    "for i, v in enumerate(y_train):\n",
    "    if leng %(i+1) == 0:\n",
    "        print(i+1, end=\", \")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "62\n",
      "1, 2, 31, 62, "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "BATCH_SIZE = 81\n",
    "epoch_ = 600\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "EMBEDDING_DIM = emb_dim\n",
    "HIDDEN_DIM = emb_dim*4\n",
    "OUTPUT_DIM = 2\n",
    "# seq_len = length"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, BATCH_SIZE)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "# print(\"error[{0}]\".format(error_types[error_i]))\n",
    "for epoch in range(epoch_):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        X_t_tensor = torch.tensor(data[0], device='cuda:0').float()\n",
    "        # y_t_tensor = torch.tensor(data[1].reshape(batch_size, 1), device='cuda:0').float()\n",
    "        y_t_tensor = torch.tensor(data[1], device='cuda:0').long()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        # print(X_t_tensor.shape)\n",
    "\n",
    "        score = model(X_t_tensor)\n",
    "        loss_ = loss_function(score, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 50 \t loss 0.00019598204744397663\n",
      "epoch 100 \t loss 6.844669951533433e-05\n",
      "epoch 150 \t loss 3.473496917649754e-05\n",
      "epoch 200 \t loss 2.006154136324767e-05\n",
      "epoch 250 \t loss 1.3079136238047795e-05\n",
      "epoch 300 \t loss 9.018269224725373e-06\n",
      "epoch 350 \t loss 6.440148411002156e-06\n",
      "epoch 400 \t loss 4.748263336296077e-06\n",
      "epoch 450 \t loss 3.605651585303349e-06\n",
      "epoch 500 \t loss 2.7720707862499694e-06\n",
      "epoch 550 \t loss 2.122307236618326e-06\n",
      "epoch 600 \t loss 1.6839117193967468e-06\n",
      "done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[56 16]\n",
      " [13 49]]\n",
      "accuracy =  0.7835820895522388\n",
      "precision =  0.7538461538461538\n",
      "recall =  0.7903225806451613\n",
      "f1 score =  0.7716535433070866\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "model_path = \"../models/response/\"\n",
    "model_name = \"{0}1_M.pickle\".format(mode)\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "question1_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "modelM.save_data(model_name, model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/response/question1_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}