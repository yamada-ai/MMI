{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from tools.maneger import DataManager\n",
    "from tools.preproc import Preprocessor\n",
    "# from utterance.feature import Feature\n",
    "from feature import Feature"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path = '../error_category_classification/dbdc5_ja_dev_labeled/'\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "# datalist = ['DCM']\n",
    "    # List of error types\n",
    "error_types = ['Unclear intention', 'Wrong information',\n",
    "    'Ignore question', 'Topic transition error', \n",
    "    'Lack of information', 'Repetition', \n",
    "    'Contradiction', 'Self-contradiction',\n",
    "    'Lack of common sense', 'Semantic error',\n",
    "    'Grammatical error', 'Ignore proposal', \n",
    "    'Ignore offer', 'Lack of sociality', \n",
    "    'Uninterpretable', 'Ignore greeting', \n",
    "    'No-Err']\n",
    "\n",
    "pre = Preprocessor()\n",
    "df = pre.read_json_with_NoErr(path, datalist)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "F_path = \"../X_y_data/response/\"\n",
    "F_name = \"typeClassify_F.dill\"\n",
    "featureM = DataManager(F_path, format_=\"dill\")\n",
    "\n",
    "F = featureM.load_data(F_name)\n",
    "F.set_preprocessor(pre)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success load : ../X_y_data/response/typeClassify_F.dill\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model_path = \"../models/response/\"\n",
    "model_name = \"typeClassify_M.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "\n",
    "lr = modelM.load_data(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success load : ../models/response/typeClassify_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "label_list = \"YN WH please plain\".split()\n",
    "label_dict = dict( zip(label_list, range(len(label_list))) )\n",
    "label_dict2 = dict( zip(range(len(label_list)), label_list) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def extract_no_error_particular(df, mode):\n",
    "    prev_u = \"\"\n",
    "    utterances = []\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        # print(type(u))\n",
    "        f = F.featurization(s)\n",
    "        y = lr.predict(f.reshape(1,-1))\n",
    "        if mode==\"question\":\n",
    "            if y == 0 or y == 1:\n",
    "                # print(\"y: {0}, s: {1}, \\n u: {2}\\n\".format(label_dict2[int(y)], s, prev_u))\n",
    "                utterances.append([s, prev_u])\n",
    "        elif mode==\"please\":\n",
    "            if y == 3:\n",
    "                utterances.append([s, prev_u])\n",
    "        prev_u = u\n",
    "    return utterances\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def extract_error(df, errors):\n",
    "    utterances = []\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        for err in errors:\n",
    "            if err in e:\n",
    "                utterances.append([u, s])\n",
    "    return utterances"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "errors = [\"Ignore question\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "igque = extract_error(df, errors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "igque_no = extract_no_error_particular(df, mode=\"question\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size, batch_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。    \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim//2, batch_first=True, bidirectional=True )\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        # self.softmax = \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
    "        batch_size, seq_len = x.shape[0], x.shape[1]\n",
    "        _, hidden_layer = self.lstm(x)\n",
    "        # print(hidden_layer)\n",
    "        bilstm_out = torch.cat([hidden_layer[0][0], hidden_layer[0][1]], dim=1)\n",
    "        # y = self.hidden2tag(hidden_layer[0].view(batch_size, -1))\n",
    "\n",
    "        y = self.hidden2tag(bilstm_out)\n",
    "        y = F.log_softmax(y, dim=1)\n",
    "        return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from pyknp import Juman\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "model_path = \"/home/yamada/Downloads/training_bert_japanese\"\n",
    "Nmodel = SentenceTransformer(model_path, show_progress_bar=False)\n",
    "emb_dim = Nmodel.encode([\"お辞儀をしている男性会社員\"])[0].shape[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def make_X(convs):\n",
    "    X_data = []\n",
    "    \n",
    "    for conv in convs :\n",
    "        sentence_vectors = Nmodel.encode(conv)\n",
    "        X_data.append(sentence_vectors)\n",
    "    return np.array(X_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "data_path = \"../X_y_data/response/\"\n",
    "data_name = \"question1.pickle\"\n",
    "dataM = DataManager(data_path)\n",
    "print(data_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "question1.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "if dataM.is_exist(data_name):\n",
    "    \n",
    "    DATA_Xy = dataM.load_data(data_name)\n",
    "    X = DATA_Xy[0]\n",
    "    y = DATA_Xy[1]\n",
    "else:\n",
    "    # X_data, y_data = pre.extract_X_y(df, error_types, seq_len)\n",
    "    X = make_X(igque + igque_no)\n",
    "    y = np.concatenate( [ np.ones(len(igque)), np.zeros(len(igque_no)) ] )\n",
    "    dataM.save_data(data_name, [X, y])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success load : ../X_y_data/response/question1.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "leng = len(y_train)\n",
    "print(leng)\n",
    "for i, v in enumerate(y_train):\n",
    "    if leng %(i+1) == 0:\n",
    "        print(i+1, end=\", \")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "405\n",
      "1, 3, 5, 9, 15, 27, 45, 81, 135, 405, "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "BATCH_SIZE = 81\n",
    "epoch_ = 600\n",
    "trainset = Datasets(X_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "EMBEDDING_DIM = emb_dim\n",
    "HIDDEN_DIM = emb_dim*4\n",
    "OUTPUT_DIM = 2\n",
    "# seq_len = length"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, BATCH_SIZE)\n",
    "if torch.cuda.is_available():\n",
    "   model.cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "losses = []\n",
    "loss_border = 0.0001\n",
    "# print(\"error[{0}]\".format(error_types[error_i]))\n",
    "for epoch in range(epoch_):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    all_loss = 0\n",
    "    for data in trainloader:\n",
    "        X_t_tensor = torch.tensor(data[0], device='cuda:0').float()\n",
    "        # y_t_tensor = torch.tensor(data[1].reshape(batch_size, 1), device='cuda:0').float()\n",
    "        y_t_tensor = torch.tensor(data[1], device='cuda:0').long()\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        # print(X_t_tensor.shape)\n",
    "\n",
    "        score = model(X_t_tensor)\n",
    "        loss_ = loss_function(score, y_t_tensor)\n",
    "        loss_.backward()\n",
    "        all_loss += loss_.item()\n",
    "        optimizer.step()\n",
    "        del score\n",
    "        del loss_\n",
    "    losses.append(all_loss)\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"epoch\", epoch+1, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/home/yamada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 50 \t loss 0.00013331559421203565\n",
      "epoch 100 \t loss 5.521647744899383e-05\n",
      "epoch 150 \t loss 2.9905065275670495e-05\n",
      "epoch 200 \t loss 1.8595072333482676e-05\n",
      "epoch 250 \t loss 1.2578740324897808e-05\n",
      "epoch 300 \t loss 8.98923917702632e-06\n",
      "epoch 350 \t loss 6.70514157263824e-06\n",
      "epoch 400 \t loss 5.128935185894079e-06\n",
      "epoch 450 \t loss 4.006016581570293e-06\n",
      "epoch 500 \t loss 3.1906852768770477e-06\n",
      "epoch 550 \t loss 2.5799228069445235e-06\n",
      "epoch 600 \t loss 2.113388404723082e-06\n",
      "done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_history(losses):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    epochs = np.arange(1, len(losses) + 1)\n",
    "\n",
    "    # 損失の推移\n",
    "    ax.set_title(\"Loss\")\n",
    "    ax.plot(epochs, losses)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "plot_history(losses)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device='cuda:0').float()\n",
    "    y_tensor = torch.tensor(y_test, dtype=torch.long, device='cuda:0')\n",
    "            # 推論\n",
    "    y_pred= np.array(model(X_tensor).cpu()).argmax(axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('precision = ', precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('recall = ', recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('f1 score = ', f1_score(y_true=y_test, y_pred=y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[23 19]\n",
      " [ 9 51]]\n",
      "accuracy =  0.7254901960784313\n",
      "precision =  0.7285714285714285\n",
      "recall =  0.85\n",
      "f1 score =  0.7846153846153846\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "model_path = \"../models/response/\"\n",
    "model_name = \"question1_M.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "question1_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "modelM.save_data(model_name, model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/response/question1_M.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}