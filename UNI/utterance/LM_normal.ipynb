{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "# from datatools.analyzer import clean_text\n",
    "from error_tools import *"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from nltk.lm        import Vocabulary\n",
    "from nltk.lm.models import MLE\n",
    "from nltk.util      import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Utterance:\n",
    "    utt_level = [\"Wrong information\", \"Semantic error\", \"Uninterpretable\", \"Grammatical error\"]\n",
    "    def __init__(self, did, sp, utt, errors, type_) -> None:\n",
    "        self.did = did\n",
    "        self.sp = sp\n",
    "        self.utt = utt\n",
    "        self.errors = errors\n",
    "        self.type_ = type_\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"{0}: {1}\".format(self.sp, self.utt)\n",
    "\n",
    "    def is_system(self):\n",
    "        return True if self.sp==\"S\" else False\n",
    "    \n",
    "    def is_error_included(self, error):\n",
    "        # Null 対応\n",
    "        if not self.errors:\n",
    "            return False\n",
    "        return error in self.errors\n",
    "    \n",
    "    def is_exist_error(self):\n",
    "        return True if self.errors else False\n",
    "    \n",
    "    def is_type_included(self, type_):\n",
    "        return type_ in self.type_\n",
    "    \n",
    "    def is_utt_level_error(self):\n",
    "        for e in Utterance.utt_level:\n",
    "            if self.is_error_included(e):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "def read_conv(path:str, datalist:list):\n",
    "    convs = []\n",
    "    for p in datalist:\n",
    "        datapath = Path(path + p + '/')\n",
    "        for file_ in datapath.glob(\"*.json\"):\n",
    "            conv = []\n",
    "            with open(file_, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                did = json_data[\"did\"]\n",
    "                for t in json_data[\"turns\"]:\n",
    "                    sp = t[\"speaker\"]\n",
    "                    utt = t[\"utterance\"]\n",
    "                    errors = t[\"error_category\"]\n",
    "                    type_ = t[\"type\"]\n",
    "                    one = Utterance(did, sp, utt, errors, type_)\n",
    "                    conv.append(one)\n",
    "            convs.append(conv)\n",
    "    return convs  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path = \"../hand_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "error_types = ['Unclear intention', 'Wrong information',\n",
    " 'Ignore question', 'Topic transition error', \n",
    " 'Lack of information', 'Repetition', \n",
    " 'Contradiction', 'Self-contradiction',\n",
    "  'Lack of common sense', 'Semantic error',\n",
    "   'Grammatical error', 'Ignore proposal', \n",
    "   'Ignore offer', 'Lack of sociality', \n",
    "   'Uninterpretable', 'Ignore greeting', \n",
    "   'No-Err']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "convs = read_conv(path, datalist)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "usr_utt = []\n",
    "for conv in convs:\n",
    "    for i, ut in enumerate(conv):\n",
    "        if not ut.is_system():\n",
    "            usr_utt.append(clean_text(ut.utt))\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "usr_utt[:15]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['そうですね。最近とても暑いですから。',\n",
       " '休日に行きたいと思います。',\n",
       " 'はい。あなたは海に行きますか？',\n",
       " '何故ですか？',\n",
       " 'そうですか。山に行くのはどうでしょうか？',\n",
       " '山はお好きなのですか？',\n",
       " '山の御勧めのスポットは御存知ですか？',\n",
       " 'どこに行くといいですか？',\n",
       " '明日はとても暑くなるみたいですね。',\n",
       " '涼しくなってきたら、一緒に山へ行きたいですね。',\n",
       " '美味しいですね。',\n",
       " 'でも高いですね',\n",
       " '1000円ぐらいかな？',\n",
       " '意味が分かりません',\n",
       " 'サスペンスが好きです']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "filled_normal = fill_SYMBOL( sentence2normalize_nv(usr_utt) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def create_language_model(sentences, N):\n",
    "    vocab = Vocabulary([word for sent in sentences for word in sent])\n",
    "    text_ngrams = [ngrams(sent, N) for sent in sentences]\n",
    "    lm = MLE(order=N, vocabulary=vocab)\n",
    "    lm.fit(text_ngrams)\n",
    "    return lm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "lm = create_language_model(filled_normal, N=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "context = (\"そう\", 'です')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "usr_utt[:15]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['そうですね。最近とても暑いですから。',\n",
       " '休日に行きたいと思います。',\n",
       " 'はい。あなたは海に行きますか？',\n",
       " '何故ですか？',\n",
       " 'そうですか。山に行くのはどうでしょうか？',\n",
       " '山はお好きなのですか？',\n",
       " '山の御勧めのスポットは御存知ですか？',\n",
       " 'どこに行くといいですか？',\n",
       " '明日はとても暑くなるみたいですね。',\n",
       " '涼しくなってきたら、一緒に山へ行きたいですね。',\n",
       " '美味しいですね。',\n",
       " 'でも高いですね',\n",
       " '1000円ぐらいかな？',\n",
       " '意味が分かりません',\n",
       " 'サスペンスが好きです']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(context, '->')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "prob_list = []\n",
    "for word in lm.context_counts(lm.vocab.lookup(context)): # 文脈に続く単語一覧の取得\n",
    "    prob_list.append((word, lm.score(word, context))) # 単語のその出現する確率を格納\n",
    "\n",
    "prob_list.sort(key=lambda x: x[1], reverse=True) # 出現確率順にソート\n",
    "for word, prob in prob_list:\n",
    "    print('\\t{:s}: {:f}'.format(word, prob))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tね: 0.734513\n",
      "\tか: 0.150442\n",
      "\tよ: 0.070796\n",
      "\t。: 0.017699\n",
      "\tけど: 0.008850\n",
      "\tEOS: 0.008850\n",
      "\tが: 0.008850\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import math\n",
    "def sentence2score(sentence, l, N):\n",
    "    filled = fill_SYMBOL( sentence2normalize_nv(sentence) )\n",
    "    ngram_text = []\n",
    "    for L in filled:\n",
    "        for i in range(len(L)-N+1):\n",
    "            # print(L[i:i+N])\n",
    "            ngram_text.append(L[i:i+N])\n",
    "    \n",
    "    all_score = 0\n",
    "    for ngram in ngram_text:\n",
    "        context = (ngram[:-1])\n",
    "        # print(context)\n",
    "        # for word in lm.context_counts(lm.vocab.lookup(context)): # 文脈に続く単語一覧の取得\n",
    "            \n",
    "        score = lm.score(ngram[-1], context) + 1e-4\n",
    "        print(score)\n",
    "        log_score = math.log2(score)\n",
    "        all_score += log_score\n",
    "    print(all_score/len(ngram_text))\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "sentence = \"そうですね。最近とても暑いですから。\"\n",
    "sentence2score(sentence, lm, N=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4251\n",
      "0.7346132743362832\n",
      "0.6097256684491978\n",
      "0.9932972789115646\n",
      "0.005335602094240838\n",
      "1.0001\n",
      "1.0001\n",
      "0.13343333333333332\n",
      "0.2223222222222222\n",
      "1.0001\n",
      "-1.502732464507734\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "sentence = \"もちろんですってのが元気ですかにいくないですよ\"\n",
    "sentence2score(sentence, lm, N=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3334333333333333\n",
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "0.3334333333333333\n",
      "0.2778777777777778\n",
      "0.0001\n",
      "0.0001\n",
      "0.007974015748031495\n",
      "0.1876\n",
      "0.21749130434782607\n",
      "0.1781821917808219\n",
      "-7.601315602452995\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "sentence = \"パスタが好きですね\"\n",
    "sentence2score(sentence, lm, N=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1070364161849711\n",
      "0.2246508982035928\n",
      "0.6870565217391305\n",
      "0.056350000000000004\n",
      "0.28619625668449195\n",
      "-2.374786563949037\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}