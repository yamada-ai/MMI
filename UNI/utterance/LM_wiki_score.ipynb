{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from datatools.analyzer import *\n",
    "from datatools.maneger import DataManager\n",
    "# from datatools.analyzer import clean_text\n",
    "from error_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm        import Vocabulary\n",
    "# from nltk.lm.models import MLE\n",
    "from nltk.lm.models import KneserNeyInterpolated\n",
    "from nltk.util      import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../eval_labeled/\"\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "convs = read_conv(path, datalist)\n",
    "\n",
    "error = \"Grammatical error\"\n",
    "errors = ['Grammatical error', \"Uninterpretable\"]\n",
    "sys_utt = []\n",
    "y = []\n",
    "for conv in convs:\n",
    "    for ut in conv:\n",
    "        if ut.is_system() and ut.is_exist_error():\n",
    "            if not ut.utt[-1] in [\"？\", \"！\", \"。\", \"!\"]:\n",
    "                sys_utt.append( clean_text( ut.utt+\"。\" ))\n",
    "                # sys_utt.append(ut.utt)\n",
    "            else:   \n",
    "                sys_utt.append(ut.utt)\n",
    "            if ut.is_error_included(errors):\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success load : ../models/utterance/KLM_phrase_nucc_wiki_n=3_noun1.pickle\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "modelM = DataManager(\"../models/utterance/\")\n",
    "model_name = \"KLM_phrase_nucc_wiki_n={0}_noun1.pickle\".format(n)\n",
    "lm = modelM.load_data(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_analyzer = Analyzer(tokenizer_)\n",
    "# 一文ずつしか送られて来ない読み\n",
    "def sentence2normalize_noun_mecab(sentences):\n",
    "    normalize_sen = []\n",
    "    if isinstance(sentences, str):\n",
    "        # df = mecab_analyzer.analyze_with_dataframe(sentences)\n",
    "        # words = []\n",
    "        # for txt, pos in zip(df.surface, df.part_of_speech):\n",
    "        #     if \"名詞\" in pos:\n",
    "        #         words.append(pos)\n",
    "        #     else:\n",
    "        #         words.append(txt)\n",
    "        # return words\n",
    "        sentences = [sentences]\n",
    "\n",
    "    for sen in sentences:\n",
    "        df = mecab_analyzer.analyze_with_dataframe(sen)\n",
    "        words = []\n",
    "        for txt, pos in zip(df.surface, df.part_of_speech):\n",
    "            if \"名詞\" in pos:\n",
    "                words.append(pos)\n",
    "            else:\n",
    "                words.append(txt)\n",
    "        normalize_sen.append(words)\n",
    "    return normalize_sen\n",
    "\n",
    "def sentence2pos_mecab(sentences):\n",
    "    normalize_sen = []\n",
    "    if isinstance(sentences, str):\n",
    "        sentences = [sentences]\n",
    "    for sen in sentences:\n",
    "        df = mecab_analyzer.analyze_with_dataframe(sen)\n",
    "        words = []\n",
    "        for txt, pos in zip(df.surface, df.part_of_speech):\n",
    "            words.append(pos)\n",
    "        normalize_sen.append(words)\n",
    "    return normalize_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mecab_analyzer = Analyzer(tokenizer_)\n",
    "\n",
    "def last_pos(pos_split):\n",
    "    last = len(pos_split) - 1 \n",
    "    for i, _ in enumerate(pos_split):\n",
    "        if pos_split[last-i] != \"*\":\n",
    "            return \"[\"+pos_split[last-i]+\"]\"\n",
    "def sentence2normalize_noun_mecab(sentences):\n",
    "    normalize_sen = []\n",
    "    for sen in tqdm(sentences):\n",
    "        df = mecab_analyzer.analyze_with_dataframe(sen)\n",
    "        words = []\n",
    "        for txt, pos in zip(df.surface, df.part_of_speech):\n",
    "            pos_split = pos.split(\"-\")\n",
    "            if pos_split[1] == \"固有名詞\" or pos_split[1] == \"一般\":\n",
    "                # words.append(pos)\n",
    "                words.append(last_pos(pos_split))\n",
    "            else:\n",
    "                words.append(txt)\n",
    "        normalize_sen.append(words)\n",
    "    return normalize_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pprint\n",
    "\n",
    "\n",
    "def sentence2score(sentence, lm, N):\n",
    "    # filled = fill_SYMBOL( sentence2normalize_independent(sentence) )\n",
    "    filled = fill_SYMBOL_ONE( sentence2normalize_noun_mecab(sentence) )\n",
    "    # filled = fill_SYMBOL( sentence2morpheme(sentence) )\n",
    "    filled_pos = fill_SYMBOL_ONE( sentence2pos_mecab(sentence) )\n",
    "    # print(filled)\n",
    "    # print(filled_pos)\n",
    "    ngram_text = []\n",
    "    ngram_pos = []\n",
    "    for L, P in zip(filled,filled_pos):\n",
    "        for i in range(len(L)-N+1):\n",
    "            # print(L[i:i+N])\n",
    "            ngram_text.append(L[i:i+N])\n",
    "            ngram_pos.append(P[i:i+N])\n",
    "    # pprint.pprint(ngram_text)\n",
    "    all_score = 0\n",
    "    function_score = 0\n",
    "    # デフォルトで1\n",
    "    function_num = 1\n",
    "\n",
    "    under = 1 / (1000*len( lm.vocab.counts ) )\n",
    "\n",
    "    for ngram, pgram in zip(ngram_text, ngram_pos):\n",
    "        context = (ngram[:-1])\n",
    "        context_pos = pgram[:-1]\n",
    "        # print(context)\n",
    "        # for word in lm.context_counts(lm.vocab.lookup(context)): # 文脈に続く単語一覧の取得\n",
    "            \n",
    "        score = lm.score(ngram[-1], context) + under\n",
    "        log_score = math.log2(score)\n",
    "        # print(\"context : {0}|{1} ->\".format(context, ngram[-1:]), log_score)\n",
    "\n",
    "        if \"助動詞\" in context_pos[1] or \"助詞\" in context_pos[1] or \"助動詞\" in context_pos[0] or \"助詞\" in context_pos[0]:\n",
    "            # print(\"\\tcontext : {0}| ->\".format(context), log_score)\n",
    "            function_score += log_score\n",
    "            function_num += 1\n",
    "\n",
    "        all_score += log_score\n",
    "    # print(all_score/len(ngram_text))\n",
    "    return all_score/len(ngram_text)\n",
    "    # return function_score/function_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.536978645638182"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"最近とても暑いですから。\"\n",
    "# sentence = \"魚はおいしいんですか？？海は素晴らしいですね。\"\n",
    "sentence = \"魚はおいんですか？？海は素晴らしいですね。\"\n",
    "sentence2score(sentence, lm, N=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1386/1386 [00:03<00:00, 412.15it/s]\n"
     ]
    }
   ],
   "source": [
    "y_scores = []\n",
    "for utt in tqdm(sys_utt):\n",
    "    y_scores.append(sentence2score(utt, lm, N=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_plain(test, pred):\n",
    "    return f1_score(y_true=test, y_pred=pred)\n",
    "\n",
    "def recall_score_plain(test, pred):\n",
    "    return recall_score(y_true=test, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 57/1000 [00:00<00:01, 566.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLM_phrase_nucc_wiki_n=3_noun1.pickle\n",
      "f1 score:0.013961605584642232, border:-5.0\n",
      "f1 score:0.014625228519195614, border:-5.1\n",
      "f1 score:0.015355086372360846, border:-5.2\n",
      "f1 score:0.016129032258064516, border:-5.3\n",
      "f1 score:0.01663201663201663, border:-5.4\n",
      "f1 score:0.017204301075268814, border:-5.5\n",
      "f1 score:0.01809954751131222, border:-5.6\n",
      "f1 score:0.018518518518518517, border:-7.1\n",
      "f1 score:0.01904761904761905, border:-7.2\n",
      "f1 score:0.02040816326530612, border:-7.300000000000001\n",
      "f1 score:0.0213903743315508, border:-7.4\n",
      "f1 score:0.022598870056497175, border:-7.5\n",
      "f1 score:0.024096385542168676, border:-7.6\n",
      "f1 score:0.02547770700636943, border:-7.7\n",
      "f1 score:0.0273972602739726, border:-7.800000000000001\n",
      "f1 score:0.028368794326241138, border:-7.9\n",
      "f1 score:0.03053435114503817, border:-8.0\n",
      "f1 score:0.031496062992125984, border:-8.1\n",
      "f1 score:0.034482758620689655, border:-8.2\n",
      "f1 score:0.03636363636363636, border:-8.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 701.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "base = -5\n",
    "epoch = 1000\n",
    "# y_pred = np.zeros(len(y)) + 1\n",
    "y_pred = np.zeros(len(y))\n",
    "max_f1 = 0\n",
    "\n",
    "print(model_name)\n",
    "for e in tqdm(range(epoch)):\n",
    "    y_pred = np.zeros(len(y))\n",
    "\n",
    "    for i, score_ in enumerate(y_scores):\n",
    "        # border 未満をエラーでとする\n",
    "        border = (base - 0.1*e)\n",
    "        if score_ < border :\n",
    "            y_pred[i] = 1\n",
    "    f1 = f1_score_plain(y, y_pred)\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        print(\"f1 score:{0}, border:{1}\".format(max_f1, border))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.zeros(len(y))\n",
    "\n",
    "for i, score_ in enumerate(y_scores):\n",
    "    if score_ < -8 :\n",
    "        y_pred2[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[1257  122]\n",
      " [   5    2]]\n",
      "accuracy =  0.9083694083694084\n",
      "precision =  0.016129032258064516\n",
      "recall =  0.2857142857142857\n",
      "f1 score =  0.03053435114503817\n"
     ]
    }
   ],
   "source": [
    "score(y, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
