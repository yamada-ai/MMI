{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "# from tools.preproc import Preprocessor\n",
    "from tools import preproc\n",
    "# from tools.preproc import Preprocessor\n",
    "from tools.maneger import DataManager\n",
    "import spacy\n",
    "# import importlib\n",
    "pre = preproc.Preprocessor()\n",
    "import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ja_ginza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_POS(texts):\n",
    "    \n",
    "    pos_list = []\n",
    "    print(\"aaa\")\n",
    "    docs = list(nlp.pipe(texts, disable=['ner']))\n",
    "    for doc in docs:\n",
    "        pos_list.append([ token.tag_ for token in doc ])\n",
    "        \n",
    "    return pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div2sentence(text):\n",
    "    if isinstance(text, str):\n",
    "        doc = nlp(text)\n",
    "        sentence_list = [str(s)  for s in doc.sents]\n",
    "\n",
    "    elif isinstance(text, list):\n",
    "        sentence_list  = []\n",
    "        docs = list(nlp.pipe(text, disable=['ner']))\n",
    "            # return [ self.get_POS(sen_) for sen_ in sen]\n",
    "        for doc in docs:\n",
    "            sentence_list.extend( [str(s) for s in doc.sents] )\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return sentence_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token_set(texts):\n",
    "    token_set = set()\n",
    "    docs = list(nlp.pipe(texts, disable=['ner']))\n",
    "    for doc in docs:\n",
    "        for token in doc:\n",
    "            token_set.add(token.text)\n",
    "    return token_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ave_length(texts):\n",
    "    docs = list(nlp.pipe(texts, disable=['ner']))\n",
    "    ave_length = 0\n",
    "    for doc in docs:\n",
    "        ave_length += len(doc)\n",
    "    ave_length = int(ave_length/len(doc)) + 1\n",
    "    # ave_length = ave_length/len(doc)\n",
    "    return ave_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_sentence(token_list, length):\n",
    "    samples = random.choices(token_list, k=length)\n",
    "    return \"\".join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature(sentence_list):\n",
    "    features = []\n",
    "    docs = list(nlp.pipe(sentence_list, disable=['ner']))\n",
    "    # 名詞\n",
    "    # for doc in docs:\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yamada/Documents/MMI/UNI'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"/\".join(os.getcwd().split(\"/\")[:-1])\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = root + '/error_category_classification/dbdc5_ja_dev_labeled/'\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "error_types = ['Unclear intention', 'Wrong information',\n",
    " 'Ignore question', 'Topic transition error', \n",
    " 'Lack of information', 'Repetition', \n",
    " 'Contradiction', 'Self-contradiction',\n",
    "  'Lack of common sense', 'Semantic error',\n",
    "   'Grammatical error', 'Ignore proposal', \n",
    "   'Ignore offer', 'Lack of sociality', \n",
    "   'Uninterpretable', 'Ignore greeting', \n",
    "   'No-Err']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pre.read_json_with_NoErr(path, datalist)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./X_y_data/dialogue/\n"
     ]
    }
   ],
   "source": [
    "vec_mode = \"ginza\"\n",
    "data_mode_list = [\"dialogue\", \"wiki\"]\n",
    "data_mode = data_mode_list[0]\n",
    "data_path = \"./X_y_data/{0}/\".format(data_mode)\n",
    "dataM = DataManager(data_path)\n",
    "print(data_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザ発話のみ取得し，操作\n",
    "\n",
    "usr_list = []\n",
    "for d, u, s, ec in zip(df.did, df.usr, df.sys, df.ec):\n",
    "    usr_list.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['そうですね。',\n",
      " '最近とても暑いですから。',\n",
      " '休日に行きたいと思います。',\n",
      " 'はい。',\n",
      " 'あなたは海に行きますか？',\n",
      " '何故ですか？',\n",
      " 'そうですか。',\n",
      " '山に行くのはどうでしょうか？',\n",
      " '山はお好きなのですか？',\n",
      " '山のおすすめのスポットはご存知ですか？',\n",
      " 'どこに行くといいですか？',\n",
      " '明日はとても暑くなるみたいですね。',\n",
      " '涼しくなってきたら、一緒に山へ行きたいですね。']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = usr_list[:10]\n",
    "text = div2sentence(text)\n",
    "pprint.pprint(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['どう', 'スポット', '暑い', '明日', '。', '涼しく', 'へ', 'ね', '何故', 'ます', 'から', 'て', 'き', '行き', '思い', 'とても', 'と', '好き', 'です', '山', 'お', '？', 'な', '海', 'おすすめ', '行く', '一緒', 'どこ', 'あなた', 'か', '最近', 'たら', '、', 'でしょう', '休日', 'みたい', 'はい', 'そう', 'の', 'に', '暑く', 'なっ', 'たい', 'いい', 'は', 'ご存知', 'なる']\n"
     ]
    }
   ],
   "source": [
    "token_set = make_token_set(text)\n",
    "token_list = list(token_set)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_length = get_ave_length(text)\n",
    "ave_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行き海たらスポットてどうどこ\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['動詞-非自立可能', '接尾辞-名詞的-一般', '助詞-副助詞', '名詞-普通名詞-一般', '助詞-副助詞', '副詞', '代名詞']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_sen = make_random_sentence(token_list, ave_length)\n",
    "print(rand_sen)\n",
    "get_POS(rand_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}