{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim import models\n",
    "# from janome.tokenizer import Tokenizer\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatools.analyzer import *\n",
    "\n",
    "from datatools.maneger import DataManager\n",
    "from datatools.preproc import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = \"../../corpus/wiki/wiki_40b_train_normal.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "test_corpus = []\n",
    "from tqdm import tqdm\n",
    "with open(file_path, \"r\") as f:\n",
    "    raw_data = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_plain(text):\n",
    "    text_ = neologdn.normalize(text)\n",
    "    text_ = re.sub(r'\\(.*\\)', \"\", text_)\n",
    "    text_ = re.sub(r'\\d+', \"0\", text_)\n",
    "    return text_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'これが噂の0年もののワインか....'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_plain(\"これが噂の20年もののワイン(ブドウ）か....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622451/622451 [04:11<00:00, 2478.21it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for txt in tqdm(raw_data[::3]):\n",
    "    documents.append(mecab_tokenize(clean_text_plain(txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = rhetoricasl_and_words(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622451"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success save : ../../corpus/wiki/idf_corpus_v3.pickle\n"
     ]
    }
   ],
   "source": [
    "document_path = \"../../corpus/wiki/\"\n",
    "document_name = \"idf_corpus_v3.pickle\"\n",
    "documentM = DataManager(document_path)\n",
    "documentM.save_data(document_name, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1025] 2022-01-14 23:14:55,782 Info gensim.corpora.dictionary :adding document #0 to Dictionary(0 unique tokens: [])\n",
      "[1025] 2022-01-14 23:14:56,547 Info gensim.corpora.dictionary :adding document #10000 to Dictionary(83595 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:14:57,277 Info gensim.corpora.dictionary :adding document #20000 to Dictionary(129359 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:14:58,012 Info gensim.corpora.dictionary :adding document #30000 to Dictionary(166161 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:14:58,775 Info gensim.corpora.dictionary :adding document #40000 to Dictionary(198724 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:14:59,517 Info gensim.corpora.dictionary :adding document #50000 to Dictionary(228552 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:00,271 Info gensim.corpora.dictionary :adding document #60000 to Dictionary(255004 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:01,034 Info gensim.corpora.dictionary :adding document #70000 to Dictionary(279990 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:01,784 Info gensim.corpora.dictionary :adding document #80000 to Dictionary(302493 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:02,512 Info gensim.corpora.dictionary :adding document #90000 to Dictionary(324356 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:03,250 Info gensim.corpora.dictionary :adding document #100000 to Dictionary(345115 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:03,999 Info gensim.corpora.dictionary :adding document #110000 to Dictionary(365360 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:04,743 Info gensim.corpora.dictionary :adding document #120000 to Dictionary(384609 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:05,493 Info gensim.corpora.dictionary :adding document #130000 to Dictionary(402925 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:06,249 Info gensim.corpora.dictionary :adding document #140000 to Dictionary(420390 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:07,019 Info gensim.corpora.dictionary :adding document #150000 to Dictionary(438355 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:07,789 Info gensim.corpora.dictionary :adding document #160000 to Dictionary(455483 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:08,568 Info gensim.corpora.dictionary :adding document #170000 to Dictionary(472388 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:09,339 Info gensim.corpora.dictionary :adding document #180000 to Dictionary(488380 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:10,114 Info gensim.corpora.dictionary :adding document #190000 to Dictionary(504116 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:10,873 Info gensim.corpora.dictionary :adding document #200000 to Dictionary(519128 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:11,649 Info gensim.corpora.dictionary :adding document #210000 to Dictionary(534272 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:12,434 Info gensim.corpora.dictionary :adding document #220000 to Dictionary(549093 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:13,214 Info gensim.corpora.dictionary :adding document #230000 to Dictionary(563667 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:14,005 Info gensim.corpora.dictionary :adding document #240000 to Dictionary(578476 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:14,777 Info gensim.corpora.dictionary :adding document #250000 to Dictionary(592197 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:15,560 Info gensim.corpora.dictionary :adding document #260000 to Dictionary(606515 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:16,324 Info gensim.corpora.dictionary :adding document #270000 to Dictionary(619805 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:17,100 Info gensim.corpora.dictionary :adding document #280000 to Dictionary(632927 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:17,879 Info gensim.corpora.dictionary :adding document #290000 to Dictionary(645807 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:18,651 Info gensim.corpora.dictionary :adding document #300000 to Dictionary(658480 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:19,415 Info gensim.corpora.dictionary :adding document #310000 to Dictionary(671717 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:20,187 Info gensim.corpora.dictionary :adding document #320000 to Dictionary(683868 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:20,938 Info gensim.corpora.dictionary :adding document #330000 to Dictionary(695887 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:21,742 Info gensim.corpora.dictionary :adding document #340000 to Dictionary(708245 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:22,489 Info gensim.corpora.dictionary :adding document #350000 to Dictionary(719982 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:23,244 Info gensim.corpora.dictionary :adding document #360000 to Dictionary(732217 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:24,032 Info gensim.corpora.dictionary :adding document #370000 to Dictionary(743965 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:24,809 Info gensim.corpora.dictionary :adding document #380000 to Dictionary(755621 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:25,590 Info gensim.corpora.dictionary :adding document #390000 to Dictionary(766979 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:26,371 Info gensim.corpora.dictionary :adding document #400000 to Dictionary(778277 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:27,135 Info gensim.corpora.dictionary :adding document #410000 to Dictionary(789115 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:27,915 Info gensim.corpora.dictionary :adding document #420000 to Dictionary(800221 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:28,696 Info gensim.corpora.dictionary :adding document #430000 to Dictionary(811020 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:29,466 Info gensim.corpora.dictionary :adding document #440000 to Dictionary(821687 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:30,224 Info gensim.corpora.dictionary :adding document #450000 to Dictionary(832018 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:30,992 Info gensim.corpora.dictionary :adding document #460000 to Dictionary(842398 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:31,778 Info gensim.corpora.dictionary :adding document #470000 to Dictionary(852553 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:32,565 Info gensim.corpora.dictionary :adding document #480000 to Dictionary(862813 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:33,337 Info gensim.corpora.dictionary :adding document #490000 to Dictionary(872878 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:34,107 Info gensim.corpora.dictionary :adding document #500000 to Dictionary(882954 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:34,885 Info gensim.corpora.dictionary :adding document #510000 to Dictionary(892988 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:35,655 Info gensim.corpora.dictionary :adding document #520000 to Dictionary(903278 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:36,435 Info gensim.corpora.dictionary :adding document #530000 to Dictionary(913335 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:37,222 Info gensim.corpora.dictionary :adding document #540000 to Dictionary(923101 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:38,015 Info gensim.corpora.dictionary :adding document #550000 to Dictionary(932705 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:38,782 Info gensim.corpora.dictionary :adding document #560000 to Dictionary(942012 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:39,537 Info gensim.corpora.dictionary :adding document #570000 to Dictionary(951153 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:40,306 Info gensim.corpora.dictionary :adding document #580000 to Dictionary(960456 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:41,089 Info gensim.corpora.dictionary :adding document #590000 to Dictionary(969790 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:41,855 Info gensim.corpora.dictionary :adding document #600000 to Dictionary(978760 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:42,627 Info gensim.corpora.dictionary :adding document #610000 to Dictionary(987944 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:43,412 Info gensim.corpora.dictionary :adding document #620000 to Dictionary(997138 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...)\n",
      "[1025] 2022-01-14 23:15:43,617 Info gensim.corpora.dictionary :built Dictionary(999441 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...) from 622451 documents (total 74923882 corpus positions)\n",
      "[1025] 2022-01-14 23:15:43,624 Info gensim.utils :Dictionary lifecycle event {'msg': \"built Dictionary(999441 unique tokens: ['0', '0回', 'No.', 'PINKY', 'SEVENTEEN']...) from 622451 documents (total 74923882 corpus positions)\", 'datetime': '2022-01-14T23:15:43.618974', 'gensim': '4.0.1', 'python': '3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-Ubuntu-18.04-bionic', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "dictionary_ = corpora.Dictionary(documents)\n",
    "corpus = list(map(dictionary_.doc2bow,documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1025] 2022-01-14 23:16:17,118 Info gensim.models.tfidfmodel :collecting document frequencies\n",
      "[1025] 2022-01-14 23:16:17,120 Info gensim.models.tfidfmodel :PROGRESS: processing document #0\n",
      "[1025] 2022-01-14 23:16:17,206 Info gensim.models.tfidfmodel :PROGRESS: processing document #10000\n",
      "[1025] 2022-01-14 23:16:17,295 Info gensim.models.tfidfmodel :PROGRESS: processing document #20000\n",
      "[1025] 2022-01-14 23:16:17,386 Info gensim.models.tfidfmodel :PROGRESS: processing document #30000\n",
      "[1025] 2022-01-14 23:16:17,475 Info gensim.models.tfidfmodel :PROGRESS: processing document #40000\n",
      "[1025] 2022-01-14 23:16:17,571 Info gensim.models.tfidfmodel :PROGRESS: processing document #50000\n",
      "[1025] 2022-01-14 23:16:17,662 Info gensim.models.tfidfmodel :PROGRESS: processing document #60000\n",
      "[1025] 2022-01-14 23:16:17,754 Info gensim.models.tfidfmodel :PROGRESS: processing document #70000\n",
      "[1025] 2022-01-14 23:16:17,845 Info gensim.models.tfidfmodel :PROGRESS: processing document #80000\n",
      "[1025] 2022-01-14 23:16:17,935 Info gensim.models.tfidfmodel :PROGRESS: processing document #90000\n",
      "[1025] 2022-01-14 23:16:18,023 Info gensim.models.tfidfmodel :PROGRESS: processing document #100000\n",
      "[1025] 2022-01-14 23:16:18,117 Info gensim.models.tfidfmodel :PROGRESS: processing document #110000\n",
      "[1025] 2022-01-14 23:16:18,212 Info gensim.models.tfidfmodel :PROGRESS: processing document #120000\n",
      "[1025] 2022-01-14 23:16:18,303 Info gensim.models.tfidfmodel :PROGRESS: processing document #130000\n",
      "[1025] 2022-01-14 23:16:18,394 Info gensim.models.tfidfmodel :PROGRESS: processing document #140000\n",
      "[1025] 2022-01-14 23:16:18,486 Info gensim.models.tfidfmodel :PROGRESS: processing document #150000\n",
      "[1025] 2022-01-14 23:16:18,579 Info gensim.models.tfidfmodel :PROGRESS: processing document #160000\n",
      "[1025] 2022-01-14 23:16:18,676 Info gensim.models.tfidfmodel :PROGRESS: processing document #170000\n",
      "[1025] 2022-01-14 23:16:18,766 Info gensim.models.tfidfmodel :PROGRESS: processing document #180000\n",
      "[1025] 2022-01-14 23:16:18,858 Info gensim.models.tfidfmodel :PROGRESS: processing document #190000\n",
      "[1025] 2022-01-14 23:16:18,947 Info gensim.models.tfidfmodel :PROGRESS: processing document #200000\n",
      "[1025] 2022-01-14 23:16:19,037 Info gensim.models.tfidfmodel :PROGRESS: processing document #210000\n",
      "[1025] 2022-01-14 23:16:19,129 Info gensim.models.tfidfmodel :PROGRESS: processing document #220000\n",
      "[1025] 2022-01-14 23:16:19,221 Info gensim.models.tfidfmodel :PROGRESS: processing document #230000\n",
      "[1025] 2022-01-14 23:16:19,315 Info gensim.models.tfidfmodel :PROGRESS: processing document #240000\n",
      "[1025] 2022-01-14 23:16:19,407 Info gensim.models.tfidfmodel :PROGRESS: processing document #250000\n",
      "[1025] 2022-01-14 23:16:19,498 Info gensim.models.tfidfmodel :PROGRESS: processing document #260000\n",
      "[1025] 2022-01-14 23:16:19,591 Info gensim.models.tfidfmodel :PROGRESS: processing document #270000\n",
      "[1025] 2022-01-14 23:16:19,686 Info gensim.models.tfidfmodel :PROGRESS: processing document #280000\n",
      "[1025] 2022-01-14 23:16:19,778 Info gensim.models.tfidfmodel :PROGRESS: processing document #290000\n",
      "[1025] 2022-01-14 23:16:19,869 Info gensim.models.tfidfmodel :PROGRESS: processing document #300000\n",
      "[1025] 2022-01-14 23:16:19,962 Info gensim.models.tfidfmodel :PROGRESS: processing document #310000\n",
      "[1025] 2022-01-14 23:16:20,054 Info gensim.models.tfidfmodel :PROGRESS: processing document #320000\n",
      "[1025] 2022-01-14 23:16:20,144 Info gensim.models.tfidfmodel :PROGRESS: processing document #330000\n",
      "[1025] 2022-01-14 23:16:20,246 Info gensim.models.tfidfmodel :PROGRESS: processing document #340000\n",
      "[1025] 2022-01-14 23:16:20,337 Info gensim.models.tfidfmodel :PROGRESS: processing document #350000\n",
      "[1025] 2022-01-14 23:16:20,429 Info gensim.models.tfidfmodel :PROGRESS: processing document #360000\n",
      "[1025] 2022-01-14 23:16:20,522 Info gensim.models.tfidfmodel :PROGRESS: processing document #370000\n",
      "[1025] 2022-01-14 23:16:20,618 Info gensim.models.tfidfmodel :PROGRESS: processing document #380000\n",
      "[1025] 2022-01-14 23:16:20,716 Info gensim.models.tfidfmodel :PROGRESS: processing document #390000\n",
      "[1025] 2022-01-14 23:16:20,809 Info gensim.models.tfidfmodel :PROGRESS: processing document #400000\n",
      "[1025] 2022-01-14 23:16:20,902 Info gensim.models.tfidfmodel :PROGRESS: processing document #410000\n",
      "[1025] 2022-01-14 23:16:20,996 Info gensim.models.tfidfmodel :PROGRESS: processing document #420000\n",
      "[1025] 2022-01-14 23:16:21,089 Info gensim.models.tfidfmodel :PROGRESS: processing document #430000\n",
      "[1025] 2022-01-14 23:16:21,183 Info gensim.models.tfidfmodel :PROGRESS: processing document #440000\n",
      "[1025] 2022-01-14 23:16:21,276 Info gensim.models.tfidfmodel :PROGRESS: processing document #450000\n",
      "[1025] 2022-01-14 23:16:21,371 Info gensim.models.tfidfmodel :PROGRESS: processing document #460000\n",
      "[1025] 2022-01-14 23:16:21,466 Info gensim.models.tfidfmodel :PROGRESS: processing document #470000\n",
      "[1025] 2022-01-14 23:16:21,560 Info gensim.models.tfidfmodel :PROGRESS: processing document #480000\n",
      "[1025] 2022-01-14 23:16:21,653 Info gensim.models.tfidfmodel :PROGRESS: processing document #490000\n",
      "[1025] 2022-01-14 23:16:21,747 Info gensim.models.tfidfmodel :PROGRESS: processing document #500000\n",
      "[1025] 2022-01-14 23:16:21,839 Info gensim.models.tfidfmodel :PROGRESS: processing document #510000\n",
      "[1025] 2022-01-14 23:16:21,931 Info gensim.models.tfidfmodel :PROGRESS: processing document #520000\n",
      "[1025] 2022-01-14 23:16:22,027 Info gensim.models.tfidfmodel :PROGRESS: processing document #530000\n",
      "[1025] 2022-01-14 23:16:22,121 Info gensim.models.tfidfmodel :PROGRESS: processing document #540000\n",
      "[1025] 2022-01-14 23:16:22,214 Info gensim.models.tfidfmodel :PROGRESS: processing document #550000\n",
      "[1025] 2022-01-14 23:16:22,308 Info gensim.models.tfidfmodel :PROGRESS: processing document #560000\n",
      "[1025] 2022-01-14 23:16:22,399 Info gensim.models.tfidfmodel :PROGRESS: processing document #570000\n",
      "[1025] 2022-01-14 23:16:22,491 Info gensim.models.tfidfmodel :PROGRESS: processing document #580000\n",
      "[1025] 2022-01-14 23:16:22,584 Info gensim.models.tfidfmodel :PROGRESS: processing document #590000\n",
      "[1025] 2022-01-14 23:16:22,681 Info gensim.models.tfidfmodel :PROGRESS: processing document #600000\n",
      "[1025] 2022-01-14 23:16:22,774 Info gensim.models.tfidfmodel :PROGRESS: processing document #610000\n",
      "[1025] 2022-01-14 23:16:22,870 Info gensim.models.tfidfmodel :PROGRESS: processing document #620000\n",
      "[1025] 2022-01-14 23:16:24,334 Info gensim.utils :TfidfModel lifecycle event {'msg': 'calculated IDF weights for 622451 documents and 999441 features (38630965 matrix non-zeros)', 'datetime': '2022-01-14T23:16:24.334699', 'gensim': '4.0.1', 'python': '3.6.9 (default, Jan 26 2021, 15:33:00) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-Ubuntu-18.04-bionic', 'event': 'initialize'}\n"
     ]
    }
   ],
   "source": [
    "test_model = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = test_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = test_model.idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict = dict()\n",
    "for id_ in idfs.keys():\n",
    "    # print( dictionary_[id_], idfs[id_] )\n",
    "    idf_dict[dictionary_[id_]] = idfs[id_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999441"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set を取っていない\n",
    "\n",
    "        の 0.9714308478032291\n",
    "        スワン 6.643856189774725\n",
    "        定理 6.643856189774725\n",
    "        神 6.643856189774725\n",
    "        神道流 6.643856189774725\n",
    "        道流 6.643856189774725\n",
    "        オーウェンス 6.643856189774725\n",
    "        ケビン 6.643856189774725\n",
    "        ケビン・オーウェンス 6.643856189774725\n",
    "        ・ 1.4739311883324122\n",
    "        , 4.058893689053568\n",
    "        . 1.4739311883324122\n",
    "        0 1.217591435072627\n",
    "        0,0丁 6.643856189774725\n",
    "        0丁以上 6.643856189774725\n",
    "        0年 2.1844245711374275\n",
    "        0年0月 3.3219280948873626\n",
    "        0年0月0日 2.736965594166206\n",
    "        0年頃 5.643856189774724\n",
    "        0日 5.058893689053569\n",
    "        0月 5.058893689053569\n",
    "        0月0日 4.321928094887363\n",
    "        、 1.1202942337177118\n",
    "        。 1.1202942337177118\n",
    "        「 2.321928094887362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"../../corpus/wiki/idf_wiki_v3.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(idf_dict,  f,  ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_path = \"../../corpus/wiki/idf_wiki_v3.json\"\n",
    "with open(idf_path, \"r\") as f:\n",
    "    idf_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idf = sorted(idf_dict.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999441"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('激モテ!セブンティーン学園', 19.247600745610452),\n",
       " ('ジャーディー', 19.247600745610452),\n",
       " ('煮くずれ', 19.247600745610452),\n",
       " ('GRiDSystems', 19.247600745610452),\n",
       " ('PenPointOS', 19.247600745610452),\n",
       " ('RobertCarr', 19.247600745610452),\n",
       " ('グラフィカルタブレット', 19.247600745610452),\n",
       " ('パーソナル・コミュニケータ', 19.247600745610452),\n",
       " ('ペルフルオロオクタン酸', 19.247600745610452),\n",
       " ('タイロン・レモント', 19.247600745610452),\n",
       " ('アテーナー・リンディア', 19.247600745610452),\n",
       " ('横浜スカイウォーク', 19.247600745610452),\n",
       " ('トダス・コントラ・メヒコ', 19.247600745610452),\n",
       " ('キャサリン・ドルー・ギルピン', 19.247600745610452),\n",
       " ('AssassinationNation', 19.247600745610452),\n",
       " ('alsee', 19.247600745610452),\n",
       " ('endifendforeachifT', 19.247600745610452),\n",
       " ('ndifendfunctionendclass', 19.247600745610452),\n",
       " ('returntrueelse', 19.247600745610452),\n",
       " ('threshold', 19.247600745610452),\n",
       " ('榛村', 19.247600745610452),\n",
       " ('丹土', 19.247600745610452),\n",
       " ('JINDAI', 19.247600745610452),\n",
       " ('プラウドブルー', 19.247600745610452),\n",
       " ('ラナウ', 19.247600745610452),\n",
       " ('ThreeCameHome', 19.247600745610452),\n",
       " ('サンダカン死の行進', 19.247600745610452),\n",
       " ('オタシナイ', 19.247600745610452),\n",
       " ('パンケウタシナイ', 19.247600745610452),\n",
       " ('かりあげ正太', 19.247600745610452)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idf[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_values = [idf[1]  for idf in sorted_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31466803191619763,\n",
       " 0.283491184275214,\n",
       " 0.1900425901095007,\n",
       " 0.17781535062714848,\n",
       " 0.03246356680871519]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_values[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25パーセント点 6.381608195259418\n",
      "75パーセント点 17.662638244889294\n",
      "四分位範囲 11.281030049629877\n"
     ]
    }
   ],
   "source": [
    "q75, q25 = np.percentile(idf_values, [25, 0.05])\n",
    "iqr = q75 - q25\n",
    "print(\"25パーセント点\", q25)\n",
    "print(\"75パーセント点\", q75)\n",
    "print(\"四分位範囲\", iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鬼\t名詞,普通名詞,一般,,,,オニ,鬼,鬼,オニ,鬼,オニ,和,\"\",\"\",\"\",\"\",\"\",\"\",体,オニ,オニ,オニ,オニ,\"2\",\"C3\",\"\",1408208140902912,5123\n",
      "滅\t名詞,普通名詞,一般,,,\n",
      "の\t助詞,格助詞,,,,,ノ,の,の,ノ,の,ノ,和,\"\",\"\",\"\",\"\",\"\",\"\",格助,ノ,ノ,ノ,ノ,\"\",\"名詞%F1\",\"\",7968444268028416,28989\n",
      "刃\t名詞,普通名詞,一般,,,,ハ,刃,刃,ハ,刃,ハ,和,\"ハ濁\",\"基本形\",\"\",\"\",\"\",\"\",体,ハ,ハ,ハ,ハ,\"1\",\"C3\",\"\",8060803244761600,29325\n",
      "も\t助詞,係助詞,,,,,モ,も,も,モ,も,モ,和,\"\",\"\",\"\",\"\",\"\",\"\",係助,モ,モ,モ,モ,\"\",\"動詞%F2@-1,形容詞%F4@-2,名詞%F1\",\"\",10324972564259328,37562\n",
      "いい\t形容詞,非自立可能,,,形容詞,終止形-一般,ヨイ,良い,いい,イー,いい,イー,和,\"\",\"\",\"\",\"\",\"\",\"\",相,イイ,イイ,イイ,イイ,\"1\",\"C3\",\"\",10716948459561643,38988\n",
      "けれど\t助詞,接続助詞,,,,,ケレド,けれど,けれど,ケレド,けれど,ケレド,和,\"\",\"\",\"\",\"\",\"\",\"\",接助,ケレド,ケレド,ケレド,ケレド,\"\",\"動詞%F2@0,形容詞%F2@-1\",\"\",3089095131800064,11238\n",
      "、\t補助記号,読点,,,,,,、,、,,、,,記号,\"\",\"\",\"\",\"\",\"\",\"\",補助,,,,,\"\",\"\",\"\",6605693395456,24\n",
      "約束\t名詞,普通名詞,サ変可能,,,,ヤクソク,約束,約束,ヤクソク,約束,ヤクソク,漢,\"\",\"\",\"\",\"\",\"\",\"\",体,ヤクソク,ヤクソク,ヤクソク,ヤクソク,\"0\",\"C2\",\"\",10495396866564608,38182\n",
      "の\t助詞,格助詞,,,,,ノ,の,の,ノ,の,ノ,和,\"\",\"\",\"\",\"\",\"\",\"\",格助,ノ,ノ,ノ,ノ,\"\",\"名詞%F1\",\"\",7968444268028416,28989\n",
      "ネバー\t名詞,普通名詞,一般,,,,ネバー,ネバー-never,ネバー,ネバー,ネバー,ネバー,外,\"\",\"\",\"\",\"\",\"\",\"\",体,ネバー,ネバー,ネバー,ネバー,\"1\",\"C1\",\"\",22987498225541632,83628\n",
      "ランド\t名詞,普通名詞,一般,,,,ランド,ランド-land,ランド,ランド,ランド,ランド,外,\"\",\"\",\"\",\"\",\"\",\"\",体,ランド,ランド,ランド,ランド,\"1\",\"C1\",\"\",10950044924649984,39836\n",
      "も\t助詞,係助詞,,,,,モ,も,も,モ,も,モ,和,\"\",\"\",\"\",\"\",\"\",\"\",係助,モ,モ,モ,モ,\"\",\"動詞%F2@-1,形容詞%F4@-2,名詞%F1\",\"\",10324972564259328,37562\n",
      "ね\t助詞,終助詞,,,,,ネ,ね,ね,ネ,ね,ネ,和,\"\",\"\",\"\",\"\",\"\",\"\",終助,ネ,ネ,ネ,ネ,\"\",\"動詞%F1,名詞%F1,形容詞%F1\",\"\",7903847959896576,28754\n",
      "EOS\n",
      "\n",
      "鬼滅の刃\tキメツノヤイバ\tキメツノヤイバ\t鬼滅の刃\t名詞-固有名詞-一般\t\t\n",
      "も\tモ\tモ\tも\t助詞-係助詞\t\t\n",
      "いい\tイー\tヨイ\t良い\t形容詞-非自立可能\t形容詞\t終止形-一般\n",
      "けれど\tケレド\tケレド\tけれど\t助詞-接続助詞\t\t\n",
      "、\t\t\t、\t補助記号-読点\t\t\n",
      "約束のネバーランド\tヤクソクノネバーランド\tヤクソクノネバーランド\t約束のネバーランド\t名詞-固有名詞-一般\t\t\n",
      "も\tモ\tモ\tも\t助詞-係助詞\t\t\n",
      "ね\tネ\tネ\tね\t助詞-終助詞\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "tagger1 = MeCab.Tagger()\n",
    "dicdir = '-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-unidic-neologd'\n",
    "tagger2 = MeCab.Tagger(dicdir)\n",
    "\n",
    "sample_txt = '鬼滅の刃もいいけれど、約束のネバーランドもね'\n",
    "print(tagger1.parse(sample_txt))\n",
    "print(tagger2.parse(sample_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = '鬼滅の刃もいいけれど、約束のネバーランドもね'\n",
    "\n",
    "# 基本的な使い方\n",
    "tokenizer_ = Tokenizer(use_neologd=True)\n",
    "token_filters = [POSKeepFilter('名詞')]\n",
    "analyzer = Analyzer(tokenizer_, token_filters=token_filters)\n",
    "df = analyzer.analyze_with_dataframe(sample_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>infl_type</th>\n",
       "      <th>infl_form</th>\n",
       "      <th>base_form</th>\n",
       "      <th>reading</th>\n",
       "      <th>phonetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鬼滅の刃</td>\n",
       "      <td>名詞-固有名詞-一般-*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>鬼滅の刃</td>\n",
       "      <td>[キメツノヤイバ, キメツノヤイバ]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>約束のネバーランド</td>\n",
       "      <td>名詞-固有名詞-一般-*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>約束のネバーランド</td>\n",
       "      <td>[ヤクソクノネバーランド, ヤクソクノネバーランド]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     surface part_of_speech infl_type infl_form  base_form  \\\n",
       "0       鬼滅の刃   名詞-固有名詞-一般-*         *         *       鬼滅の刃   \n",
       "1  約束のネバーランド   名詞-固有名詞-一般-*         *         *  約束のネバーランド   \n",
       "\n",
       "                      reading phonetic  \n",
       "0          [キメツノヤイバ, キメツノヤイバ]        *  \n",
       "1  [ヤクソクノネバーランド, ヤクソクノネバーランド]        *  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['鬼滅の刃', 'も', 'いい', 'けれど', '、', '約束のネバーランド', 'も', 'ね']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_tokenize(sample_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
