{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './error_category_classification/dbdc5_ja_dev_labeled/'\n",
    "# Names of the dialogue systems\n",
    "datalist = ['DCM', 'DIT', 'IRS']\n",
    "# datalist = ['DCM']\n",
    "# List of error types\n",
    "error_types = ['Ignore question', 'Unclear intention', 'Wrong information', 'Topic transition error', 'Lack of information', \n",
    "'Repetition', 'Semantic error', 'Self-contradiction', 'Contradiction', 'Grammatical error', 'Ignore offer', \n",
    "'Ignore proposal', 'Lack of sociality', 'Lack of common sense', 'Uninterpretable', 'Ignore greeting', \"No-Err\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path:str, datalist:list) -> pd.DataFrame:\n",
    "    cols = ['did', 'tid', 'usr', 'sys', 'ec']\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "    for p in datalist:\n",
    "        datapath = Path(path + p + '/')\n",
    "        for file in datapath.glob(\"*.json\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                did = json_data[\"dialogue-id\"]\n",
    "                for t in json_data[\"turns\"]:\n",
    "                    if t[\"turn-index\"] == 0:\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"U\":\n",
    "                        usr = t[\"utterance\"]\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"S\" and t[\"error_category\"] != None:\n",
    "                        tid = t[\"turn-index\"]\n",
    "                        sys = t[\"utterance\"]\n",
    "                        ec = t[\"error_category\"]\n",
    "                        df = df.append(pd.DataFrame([did, tid, usr, sys, ec], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_with_NoErr(path:str, datalist:list) -> pd.DataFrame:\n",
    "    cols = ['did', 'tid', 'usr', 'sys', 'ec']\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "    for p in datalist:\n",
    "        datapath = Path(path + p + '/')\n",
    "        for file in datapath.glob(\"*.json\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                did = json_data[\"dialogue-id\"]\n",
    "                for t in json_data[\"turns\"]:\n",
    "                    if t[\"turn-index\"] == 0:\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"U\":\n",
    "                        usr = t[\"utterance\"]\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"S\" :\n",
    "                        tid = t[\"turn-index\"]\n",
    "                        sys = t[\"utterance\"]\n",
    "                        if t[\"error_category\"]:\n",
    "                            ec = t[\"error_category\"]\n",
    "                        else:\n",
    "                            ec = [\"No-Err\"]\n",
    "                        df = df.append(pd.DataFrame([did, tid, usr, sys, ec], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>tid</th>\n",
       "      <th>usr</th>\n",
       "      <th>sys</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>2</td>\n",
       "      <td>そうですね。最近とても暑いですから。</td>\n",
       "      <td>海に行かないんですね？</td>\n",
       "      <td>[Contradiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>4</td>\n",
       "      <td>休日に行きたいと思います。</td>\n",
       "      <td>海は大丈夫ですね</td>\n",
       "      <td>[Lack of information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>6</td>\n",
       "      <td>はい。あなたは海に行きますか？</td>\n",
       "      <td>海は危険です</td>\n",
       "      <td>[Ignore question, Self-contradiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>8</td>\n",
       "      <td>何故ですか？</td>\n",
       "      <td>海はいけないです</td>\n",
       "      <td>[Ignore question]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>10</td>\n",
       "      <td>そうですか。山に行くのはどうでしょうか？</td>\n",
       "      <td>わあ！いいですね！</td>\n",
       "      <td>[No-Err]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>12</td>\n",
       "      <td>何を別売りしているの？</td>\n",
       "      <td>地下鉄で。名大前ができてすごく便利になりましたね、ここの大学。</td>\n",
       "      <td>[Repetition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>14</td>\n",
       "      <td>今は2回押してないよ</td>\n",
       "      <td>紅葉も遅いみたいですしね。私は、いつもベーッシクな色で変わりばえしないのですが。</td>\n",
       "      <td>[Topic transition error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>16</td>\n",
       "      <td>ベーシックだよね</td>\n",
       "      <td>何処にあるお店ですか？ベースコートもトップコートも塗ると持ちが違いますよ。</td>\n",
       "      <td>[Topic transition error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>18</td>\n",
       "      <td>君は女性なんだね</td>\n",
       "      <td>中間ですか？</td>\n",
       "      <td>[Lack of information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>20</td>\n",
       "      <td>両性なのか</td>\n",
       "      <td>では、スポーツは何かしてますか？</td>\n",
       "      <td>[Topic transition error]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             did tid                   usr  \\\n",
       "0     1470646494   2    そうですね。最近とても暑いですから。   \n",
       "1     1470646494   4         休日に行きたいと思います。   \n",
       "2     1470646494   6       はい。あなたは海に行きますか？   \n",
       "3     1470646494   8                何故ですか？   \n",
       "4     1470646494  10  そうですか。山に行くのはどうでしょうか？   \n",
       "...          ...  ..                   ...   \n",
       "1995  1503290726  12           何を別売りしているの？   \n",
       "1996  1503290726  14            今は2回押してないよ   \n",
       "1997  1503290726  16              ベーシックだよね   \n",
       "1998  1503290726  18              君は女性なんだね   \n",
       "1999  1503290726  20                 両性なのか   \n",
       "\n",
       "                                           sys  \\\n",
       "0                                  海に行かないんですね？   \n",
       "1                                     海は大丈夫ですね   \n",
       "2                                       海は危険です   \n",
       "3                                     海はいけないです   \n",
       "4                                    わあ！いいですね！   \n",
       "...                                        ...   \n",
       "1995           地下鉄で。名大前ができてすごく便利になりましたね、ここの大学。   \n",
       "1996  紅葉も遅いみたいですしね。私は、いつもベーッシクな色で変わりばえしないのですが。   \n",
       "1997     何処にあるお店ですか？ベースコートもトップコートも塗ると持ちが違いますよ。   \n",
       "1998                                    中間ですか？   \n",
       "1999                          では、スポーツは何かしてますか？   \n",
       "\n",
       "                                         ec  \n",
       "0                           [Contradiction]  \n",
       "1                     [Lack of information]  \n",
       "2     [Ignore question, Self-contradiction]  \n",
       "3                         [Ignore question]  \n",
       "4                                  [No-Err]  \n",
       "...                                     ...  \n",
       "1995                           [Repetition]  \n",
       "1996               [Topic transition error]  \n",
       "1997               [Topic transition error]  \n",
       "1998                  [Lack of information]  \n",
       "1999               [Topic transition error]  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = read_json_with_NoErr(path, datalist)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>tid</th>\n",
       "      <th>usr</th>\n",
       "      <th>sys</th>\n",
       "      <th>ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>2</td>\n",
       "      <td>そうですね。最近とても暑いですから。</td>\n",
       "      <td>海に行かないんですね？</td>\n",
       "      <td>[Contradiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>4</td>\n",
       "      <td>休日に行きたいと思います。</td>\n",
       "      <td>海は大丈夫ですね</td>\n",
       "      <td>[Lack of information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>6</td>\n",
       "      <td>はい。あなたは海に行きますか？</td>\n",
       "      <td>海は危険です</td>\n",
       "      <td>[Ignore question, Self-contradiction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>8</td>\n",
       "      <td>何故ですか？</td>\n",
       "      <td>海はいけないです</td>\n",
       "      <td>[Ignore question]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1470646494</td>\n",
       "      <td>12</td>\n",
       "      <td>山はお好きなのですか？</td>\n",
       "      <td>わあ！いいですね！</td>\n",
       "      <td>[Ignore question, Repetition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>12</td>\n",
       "      <td>何を別売りしているの？</td>\n",
       "      <td>地下鉄で。名大前ができてすごく便利になりましたね、ここの大学。</td>\n",
       "      <td>[Repetition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>14</td>\n",
       "      <td>今は2回押してないよ</td>\n",
       "      <td>紅葉も遅いみたいですしね。私は、いつもベーッシクな色で変わりばえしないのですが。</td>\n",
       "      <td>[Topic transition error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>16</td>\n",
       "      <td>ベーシックだよね</td>\n",
       "      <td>何処にあるお店ですか？ベースコートもトップコートも塗ると持ちが違いますよ。</td>\n",
       "      <td>[Topic transition error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>18</td>\n",
       "      <td>君は女性なんだね</td>\n",
       "      <td>中間ですか？</td>\n",
       "      <td>[Lack of information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1503290726</td>\n",
       "      <td>20</td>\n",
       "      <td>両性なのか</td>\n",
       "      <td>では、スポーツは何かしてますか？</td>\n",
       "      <td>[Topic transition error]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1348 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             did tid                 usr  \\\n",
       "0     1470646494   2  そうですね。最近とても暑いですから。   \n",
       "1     1470646494   4       休日に行きたいと思います。   \n",
       "2     1470646494   6     はい。あなたは海に行きますか？   \n",
       "3     1470646494   8              何故ですか？   \n",
       "4     1470646494  12         山はお好きなのですか？   \n",
       "...          ...  ..                 ...   \n",
       "1343  1503290726  12         何を別売りしているの？   \n",
       "1344  1503290726  14          今は2回押してないよ   \n",
       "1345  1503290726  16            ベーシックだよね   \n",
       "1346  1503290726  18            君は女性なんだね   \n",
       "1347  1503290726  20               両性なのか   \n",
       "\n",
       "                                           sys  \\\n",
       "0                                  海に行かないんですね？   \n",
       "1                                     海は大丈夫ですね   \n",
       "2                                       海は危険です   \n",
       "3                                     海はいけないです   \n",
       "4                                    わあ！いいですね！   \n",
       "...                                        ...   \n",
       "1343           地下鉄で。名大前ができてすごく便利になりましたね、ここの大学。   \n",
       "1344  紅葉も遅いみたいですしね。私は、いつもベーッシクな色で変わりばえしないのですが。   \n",
       "1345     何処にあるお店ですか？ベースコートもトップコートも塗ると持ちが違いますよ。   \n",
       "1346                                    中間ですか？   \n",
       "1347                          では、スポーツは何かしてますか？   \n",
       "\n",
       "                                         ec  \n",
       "0                           [Contradiction]  \n",
       "1                     [Lack of information]  \n",
       "2     [Ignore question, Self-contradiction]  \n",
       "3                         [Ignore question]  \n",
       "4             [Ignore question, Repetition]  \n",
       "...                                     ...  \n",
       "1343                           [Repetition]  \n",
       "1344               [Topic transition error]  \n",
       "1345               [Topic transition error]  \n",
       "1346                  [Lack of information]  \n",
       "1347               [Topic transition error]  \n",
       "\n",
       "[1348 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_json(path, datalist)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of breakdowns:  1348\n",
      "-- Frequency of labels --\n",
      "Unclear intention\t\t\t474\n",
      "Wrong information\t\t\t376\n",
      "Ignore question\t\t\t305\n",
      "Topic transition error\t\t\t192\n",
      "Lack of information\t\t\t54\n",
      "Repetition\t\t\t48\n",
      "Contradiction\t\t\t18\n",
      "Self-contradiction\t\t\t12\n",
      "Lack of common sense\t\t\t7\n",
      "Semantic error\t\t\t6\n",
      "Grammatical error\t\t\t4\n",
      "Ignore proposal\t\t\t3\n",
      "Ignore offer\t\t\t1\n",
      "Lack of sociality\t\t\t1\n",
      "Uninterpretable\t\t\t0\n",
      "Ignore greeting\t\t\t0\n",
      "No-Err\t\t\t0\n",
      "['Unclear intention', 'Wrong information', 'Ignore question', 'Topic transition error', 'Lack of information', 'Repetition', 'Contradiction', 'Self-contradiction', 'Lack of common sense', 'Semantic error', 'Grammatical error', 'Ignore proposal', 'Ignore offer', 'Lack of sociality', 'Uninterpretable', 'Ignore greeting', 'No-Err']\n",
      "-- Frequency of sets of labels (sorted) --\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(No-Err,)                                      652\n",
       "(Unclear intention,)                           389\n",
       "(Wrong information,)                           376\n",
       "(Ignore question,)                             158\n",
       "(Topic transition error,)                      141\n",
       "(Ignore question, Unclear intention)            80\n",
       "(Lack of information,)                          46\n",
       "(Ignore question, Topic transition error)       46\n",
       "(Repetition,)                                   36\n",
       "(Contradiction,)                                18\n",
       "(Ignore question, Repetition)                   11\n",
       "(Self-contradiction,)                           10\n",
       "(Lack of information, Ignore question)           8\n",
       "(Semantic error,)                                6\n",
       "(Lack of common sense,)                          6\n",
       "(Topic transition error, Unclear intention)      5\n",
       "(Grammatical error,)                             4\n",
       "(Ignore proposal,)                               3\n",
       "(Ignore question, Self-contradiction)            2\n",
       "(Lack of sociality,)                             1\n",
       "(Lack of common sense, Repetition)               1\n",
       "(Ignore offer,)                                  1\n",
       "Name: ec, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[1 if (i in ec) else 0 for i in error_types] for ec in df.ec])\n",
    "\n",
    "# Display data statistics\n",
    "print('Number of breakdowns: ', y.shape[0])\n",
    "print('-- Frequency of labels --')\n",
    "error_times_dict = {}\n",
    "for e,c in zip(error_types, sum(y)):\n",
    "  error_times_dict[e] = c\n",
    "error_freq = sorted(error_times_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "for tup in error_freq:\n",
    "  print(\"{0}\\t\\t\\t{1}\".format(tup[0], tup[1]))\n",
    "error_types_2 = [ ef[0] for ef in error_freq]\n",
    "print(error_types_2)\n",
    "\n",
    "print('-- Frequency of sets of labels (sorted) --')\n",
    "df_all['ec'].apply(tuple).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df:pd.DataFrame) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "\n",
    "  # Make feature vector\n",
    "    return np.array([np.concatenate([nlp(u).vector, nlp(s).vector]) for u,s in zip(df.usr, df.sys)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_context2(df:pd.DataFrame) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    feature = []\n",
    "    did = 0\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        if did != d:\n",
    "            u_prev_vec = nlp(u).vector\n",
    "            s_prev_vec = nlp(s).vector\n",
    "            did = d\n",
    "                  \n",
    "            if e[0] != \"No-Err\":\n",
    "                each = np.array(\n",
    "                    [np.concatenate(\n",
    "                        [np.zeros(300),\n",
    "                        np.zeros(300), \n",
    "                        u_prev_vec, \n",
    "                        s_prev_vec]\n",
    "                    )]\n",
    "                ) \n",
    "                feature.append(each[0])\n",
    "\n",
    "        else:     \n",
    "            # エラーである\n",
    "            if e[0] != \"No-Err\":\n",
    "                u_vec = nlp(u).vector\n",
    "                s_vec = nlp(s).vector\n",
    "                each = np.array(\n",
    "                    [np.concatenate(\n",
    "                        [u_vec,\n",
    "                        s_vec, \n",
    "                        u_prev_vec, \n",
    "                        s_prev_vec]\n",
    "                    )]\n",
    "                )\n",
    "                feature.append(each[0])\n",
    "                u_prev_vec = u_vec\n",
    "                s_prev_vec = s_vec\n",
    "            # エラーではない\n",
    "            else:    \n",
    "                u_prev_vec = nlp(u).vector\n",
    "                s_prev_vec = nlp(s).vector\n",
    "    return np.array(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_at_least_oneClass(clf, X) -> np.array:\n",
    "    y_pred = clf.predict(X)\n",
    "    p = clf.predict_proba(X)\n",
    "    # print(y_pred)\n",
    "    proba = np.array([[p[c][i][1] if (p[c][i].shape[0]!=1) else 0 \n",
    "                     for c in range(len(error_types))] for i in range(len(X))])\n",
    "    # print(proba)\n",
    "  # replace [] to the highest probability label\n",
    "    y_pred2 = np.empty((0, len(error_types)), int)\n",
    "    for y, pr in zip(y_pred, proba):\n",
    "        if  (sum(y) == 0):\n",
    "            ans = np.zeros_like(y)\n",
    "            ans[np.argmax(pr)] = 1\n",
    "        else:\n",
    "            ans = y\n",
    "        y_pred2 = np.append(y_pred2, np.array([ans]), axis=0)\n",
    "    return y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_y(df:pd.DataFrame) -> np.array:\n",
    "    y = []\n",
    "    for ec in df.ec:\n",
    "        if ec[0] == \"No-Err\":\n",
    "            continue\n",
    "        y_each_err = np.zeros(len(error_types))\n",
    "        for i, err in enumerate( error_types ):\n",
    "            if err in ec:\n",
    "                y_each_err[i] = 1\n",
    "        y.append(y_each_err)\n",
    "    return np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success feature_extraction\n",
      "success extract y\n",
      "size | X: (1348, 1200) y: (1348, 17)\n"
     ]
    }
   ],
   "source": [
    "# df = read_json_with_NoErr(path, datalist)\n",
    "# df_ = read_json(path, datalist)\n",
    "\n",
    "# feature extraction\n",
    "X = feature_extraction_context2(df_all)\n",
    "print(\"success feature_extraction\")\n",
    "# print(df_.shape, X.shape)\n",
    "\n",
    "\n",
    "# Make target (Multilabel)\n",
    "# y = np.array([[1 if (i in ec) else 0 for i in error_types] for ec in df.ec])\n",
    "y = extract_y(df_all)\n",
    "print(\"success extract y\")\n",
    "print(\"size | X:\", X.shape, \"y:\", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)\n",
    "\n",
    "# clf = MultiOutputClassifier(AdaBoostClassifier()).fit(X_train, y_train)\n",
    "# y_pred = predict_at_least_oneClass(clf, X_test)\n",
    "\n",
    "# print('EM:', metrics.accuracy_score(y_test, y_pred))\n",
    "# print('F-measure: ', metrics.f1_score(y_test, y_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_error(df:pd.DataFrame) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    feature = []\n",
    "    did = 0\n",
    "    # show_error_set = set([\n",
    "    #     \"Ignore question\", \"Ignore proposal\",  \n",
    "    #     \"Ignore greeting\", \"Ignore offer\"\n",
    "    #     # ])\n",
    "    show_error_set = set([\n",
    "        \"Ignore proposal\",  \n",
    "        \"Ignore greeting\", \"Ignore offer\"\n",
    "        ])\n",
    "    print(show_error_set)\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        # if did != d:\n",
    "        #     print()\n",
    "        for e_ in e:\n",
    "            if e_ in show_error_set:\n",
    "                print(\"error\",e_,\":\", u, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ignore proposal', 'Ignore offer', 'Ignore greeting'}\n",
      "error Ignore proposal : あなたも一緒にお祭りに行きませんか？ お祭りをみます\n",
      "error Ignore proposal : 蔵王ハートランドのほうが楽しいと思いますよ。行ってみますか？ 私が行った集まりでは、参加した大人の分だけ大根を掘れたので、宮城県蔵王町の蔵王ハートランドでは大根を2本掘りました。\n",
      "error Ignore offer : そうなんですね。では伊勢海老の美味しいところを簡潔に説明してください。 浅田選手が出ないのが残念ですけど、さすがに女子フィギュアはメダル期待できそうですよね。\n",
      "error Ignore proposal : 楽しいです、あなたもやりませんか? そうなのですね。私は、ボードをやりますよ。\n"
     ]
    }
   ],
   "source": [
    "show_error(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1348, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_error_dict(error_types):\n",
    "    error_dict = {}\n",
    "    for e in error_types:\n",
    "        error_dict[e] = len(error_dict)\n",
    "    return error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_did_error(df:pd.DataFrame, error_types) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    \n",
    "    did = df.did[0]\n",
    "    # 全体\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    # 各 did \n",
    "    sequence_did = []\n",
    "    y_did = []\n",
    "    \n",
    "    # エラーの辞書定義\n",
    "    error_dict = make_error_dict(error_types)\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        # did で学習データを分割してみる？\n",
    "        y_one_conv = np.zeros(len(error_types))\n",
    "        \n",
    "        if did != d:\n",
    "            did = d\n",
    "            # 登録用データ修正\n",
    "            sequence_did = np.array(sequence_did)\n",
    "            y_did = np.array(y_did)\n",
    "            X_data.append(sequence_did)\n",
    "            y_data.append(y_did)\n",
    "\n",
    "            sequence_did = []\n",
    "            y_did = []\n",
    "\n",
    "            # break\n",
    "\n",
    "        for e_ in e:\n",
    "            y_one_conv[error_dict[e_]] = 1\n",
    "\n",
    "        sequence_did.append(\n",
    "            np.concatenate(\n",
    "                [nlp(u).vector,\n",
    "                nlp(s).vector]\n",
    "            )\n",
    "        )\n",
    "        # print(sequence_did[0].shape)\n",
    "        y_did.append(y_one_conv)\n",
    "\n",
    "    sequence_did = np.array(sequence_did)\n",
    "    y_did = np.array(y_did)\n",
    "    X_data.append(sequence_did)\n",
    "    y_data.append(y_did)\n",
    "    return X_data, y_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 頑張って学習データを新たに分割\n",
    "def extract_X_y(df:pd.DataFrame, error_types, prev_num) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    n = prev_num\n",
    "    did = df.did[0]\n",
    "    # print(did)\n",
    "    # 全体\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    # 各 did \n",
    "    sequence_did = []\n",
    "    y_did = []\n",
    "    # エラーの辞書定義\n",
    "    error_dict = make_error_dict(error_types)\n",
    "\n",
    "    # 初期の調整 padding\n",
    "    for i in range(n-1):\n",
    "        sequence_did.append(\n",
    "                np.concatenate( [np.zeros(300), np.zeros(300)])\n",
    "            )\n",
    "\n",
    "    # didごとに返却する？\n",
    "    # エラーが発生したら、開始からエラーまでの文脈を入力とする(N=5の固定長でも可能)\n",
    "    # 先にこのベクトル列を作成し，Tensorに変換して， List に保持\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        if did != d:\n",
    "            did = d\n",
    "            sequence_did = []\n",
    "            y_did = []\n",
    "            for i in range(n-1):\n",
    "                sequence_did.append(\n",
    "                        np.concatenate( [np.zeros(300), np.zeros(300)])\n",
    "                    )\n",
    "            # break\n",
    "\n",
    "        # sequence_did.append([u, s])\n",
    "        sequence_did.append(\n",
    "                np.concatenate( [nlp(u).vector, nlp(s).vector])\n",
    "            )\n",
    "        if e[0] == \"No-Err\":\n",
    "            continue\n",
    "        else:\n",
    "            y_each_error_label = np.zeros(len(error_types))\n",
    "            for e_ in e:\n",
    "                y_each_error_label[error_dict[e_]] = 1\n",
    "            X_data.append(sequence_did[-n:])\n",
    "            y_data.append(y_each_error_label)\n",
    "    return np.array(X_data), np.array(y_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = extract_X_y(df_all, error_types, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1348, 5, 600)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1348, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng = 383\n",
    "for i in range(leng):\n",
    "    if i+1 % leng == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # self.transform = transform\n",
    "\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "        self.datanum = len(X_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_X = self.X_data[idx]\n",
    "        out_y = self.y_data[idx]\n",
    "\n",
    "        return out_X, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Mydatasets(X_data[:380], y_data[:380, 0])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 95, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 5, 600])\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for data in trainloader:\n",
    "    print(data[0].shape)\n",
    "    print(data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "95*4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ignore を表示しよう\n",
    "# ignore_list = ['Ignore question', 'Ignore offer', 'Ignore proposal', 'Ignore greeting']\n",
    "ignore_list = ['Ignore question']\n",
    "ignore_set = set(ignore_list)\n",
    "\n",
    "i = 0\n",
    "for d, u, s, ec in zip(df.did, df.usr, df.sys, df.ec):\n",
    "    for e in ec:\n",
    "        if e in ignore_set:\n",
    "            pass\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lack of sociality', 'Unclear intention', 'Grammatical error', 'Self-contradiction', 'Semantic error', 'Wrong information', 'Ignore proposal', 'Contradiction', 'Ignore offer', 'Repetition', 'Lack of common sense', 'Lack of information', 'Topic transition error', 'Ignore question'}\n"
     ]
    }
   ],
   "source": [
    "#エラーの種類を洗い出す\n",
    "error_set = set()\n",
    "for d, u, s, ec in zip(df.did, df.usr, df.sys, df.ec):\n",
    "    for e in ec:\n",
    "        if e not in error_set:\n",
    "            error_set.add(e)\n",
    "\n",
    "print(error_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Uninterpretable', 'No-Err', 'Ignore greeting'}\n"
     ]
    }
   ],
   "source": [
    "error_types_set = set(error_types)\n",
    "print(error_types_set - error_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}