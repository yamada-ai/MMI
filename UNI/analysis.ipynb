{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './error_category_classification/dbdc5_ja_dev_labeled/'\n",
    "# Names of the dialogue systems\n",
    "# datalist = ['DCM', 'DIT', 'IRS']\n",
    "datalist = ['DCM']\n",
    "# List of error types\n",
    "error_types = ['Ignore question', 'Unclear intention', 'Wrong information', 'Topic transition error', 'Lack of information', \n",
    "'Repetition', 'Semantic error', 'Self-contradiction', 'Contradiction', 'Grammatical error', 'Ignore offer', \n",
    "'Ignore proposal', 'Lack of sociality', 'Lack of common sense', 'Uninterpretable', 'Ignore greeting', \"No-Err\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path:str, datalist:list) -> pd.DataFrame:\n",
    "    cols = ['did', 'tid', 'usr', 'sys', 'ec']\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "    for p in datalist:\n",
    "        datapath = Path(path + p + '/')\n",
    "        for file in datapath.glob(\"*.json\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                did = json_data[\"dialogue-id\"]\n",
    "                for t in json_data[\"turns\"]:\n",
    "                    if t[\"turn-index\"] == 0:\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"U\":\n",
    "                        usr = t[\"utterance\"]\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"S\" and t[\"error_category\"] != None:\n",
    "                        tid = t[\"turn-index\"]\n",
    "                        sys = t[\"utterance\"]\n",
    "                        ec = t[\"error_category\"]\n",
    "                        df = df.append(pd.DataFrame([did, tid, usr, sys, ec], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_with_NoErr(path:str, datalist:list) -> pd.DataFrame:\n",
    "    cols = ['did', 'tid', 'usr', 'sys', 'ec']\n",
    "    df = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "    for p in datalist:\n",
    "        datapath = Path(path + p + '/')\n",
    "        for file in datapath.glob(\"*.json\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                json_data = json.load(f)\n",
    "                did = json_data[\"dialogue-id\"]\n",
    "                for t in json_data[\"turns\"]:\n",
    "                    if t[\"turn-index\"] == 0:\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"U\":\n",
    "                        usr = t[\"utterance\"]\n",
    "                        continue\n",
    "                    if t[\"speaker\"] == \"S\" :\n",
    "                        tid = t[\"turn-index\"]\n",
    "                        sys = t[\"utterance\"]\n",
    "                        if t[\"error_category\"]:\n",
    "                            ec = t[\"error_category\"]\n",
    "                        else:\n",
    "                            ec = [\"No-Err\"]\n",
    "                        df = df.append(pd.DataFrame([did, tid, usr, sys, ec], index = cols).T)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            did tid                   usr                          sys  \\\n",
       "0    1470646494   2    そうですね。最近とても暑いですから。                  海に行かないんですね？   \n",
       "1    1470646494   4         休日に行きたいと思います。                     海は大丈夫ですね   \n",
       "2    1470646494   6       はい。あなたは海に行きますか？                       海は危険です   \n",
       "3    1470646494   8                何故ですか？                     海はいけないです   \n",
       "4    1470646494  10  そうですか。山に行くのはどうでしょうか？                    わあ！いいですね！   \n",
       "..          ...  ..                   ...                          ...   \n",
       "665  1470623483  12                かっこいいね                        ありがとう   \n",
       "666  1470623483  14              どういたしまして                           はい   \n",
       "667  1470623483  16       真夏日が続いて夏バテしそうだよ  真夏日は続くんですね？真夏日まで気温が上がりますよねー   \n",
       "668  1470623483  18                夜は寝苦しい                    真夏日はいいですね   \n",
       "669  1470623483  20               私は苦手だなあ               真夏日はスイカがうまいですね   \n",
       "\n",
       "                                        ec  \n",
       "0                          [Contradiction]  \n",
       "1                    [Lack of information]  \n",
       "2    [Ignore question, Self-contradiction]  \n",
       "3                        [Ignore question]  \n",
       "4                                 [No-Err]  \n",
       "..                                     ...  \n",
       "665                    [Unclear intention]  \n",
       "666                               [No-Err]  \n",
       "667                    [Unclear intention]  \n",
       "668                               [No-Err]  \n",
       "669                    [Unclear intention]  \n",
       "\n",
       "[670 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>tid</th>\n      <th>usr</th>\n      <th>sys</th>\n      <th>ec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1470646494</td>\n      <td>2</td>\n      <td>そうですね。最近とても暑いですから。</td>\n      <td>海に行かないんですね？</td>\n      <td>[Contradiction]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1470646494</td>\n      <td>4</td>\n      <td>休日に行きたいと思います。</td>\n      <td>海は大丈夫ですね</td>\n      <td>[Lack of information]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1470646494</td>\n      <td>6</td>\n      <td>はい。あなたは海に行きますか？</td>\n      <td>海は危険です</td>\n      <td>[Ignore question, Self-contradiction]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1470646494</td>\n      <td>8</td>\n      <td>何故ですか？</td>\n      <td>海はいけないです</td>\n      <td>[Ignore question]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1470646494</td>\n      <td>10</td>\n      <td>そうですか。山に行くのはどうでしょうか？</td>\n      <td>わあ！いいですね！</td>\n      <td>[No-Err]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>1470623483</td>\n      <td>12</td>\n      <td>かっこいいね</td>\n      <td>ありがとう</td>\n      <td>[Unclear intention]</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>1470623483</td>\n      <td>14</td>\n      <td>どういたしまして</td>\n      <td>はい</td>\n      <td>[No-Err]</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>1470623483</td>\n      <td>16</td>\n      <td>真夏日が続いて夏バテしそうだよ</td>\n      <td>真夏日は続くんですね？真夏日まで気温が上がりますよねー</td>\n      <td>[Unclear intention]</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>1470623483</td>\n      <td>18</td>\n      <td>夜は寝苦しい</td>\n      <td>真夏日はいいですね</td>\n      <td>[No-Err]</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>1470623483</td>\n      <td>20</td>\n      <td>私は苦手だなあ</td>\n      <td>真夏日はスイカがうまいですね</td>\n      <td>[Unclear intention]</td>\n    </tr>\n  </tbody>\n</table>\n<p>670 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_all = read_json_with_NoErr(path, datalist)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            did tid                 usr                          sys  \\\n",
       "0    1470646494   2  そうですね。最近とても暑いですから。                  海に行かないんですね？   \n",
       "1    1470646494   4       休日に行きたいと思います。                     海は大丈夫ですね   \n",
       "2    1470646494   6     はい。あなたは海に行きますか？                       海は危険です   \n",
       "3    1470646494   8              何故ですか？                     海はいけないです   \n",
       "4    1470646494  12         山はお好きなのですか？                    わあ！いいですね！   \n",
       "..          ...  ..                 ...                          ...   \n",
       "378  1470623483   8         固いといえばくるみかな                     風早が好きですね   \n",
       "379  1470623483  10            花火見に行ったよ                  風早がかっこよいですね   \n",
       "380  1470623483  12              かっこいいね                        ありがとう   \n",
       "381  1470623483  16     真夏日が続いて夏バテしそうだよ  真夏日は続くんですね？真夏日まで気温が上がりますよねー   \n",
       "382  1470623483  20             私は苦手だなあ               真夏日はスイカがうまいですね   \n",
       "\n",
       "                                        ec  \n",
       "0                          [Contradiction]  \n",
       "1                    [Lack of information]  \n",
       "2    [Ignore question, Self-contradiction]  \n",
       "3                        [Ignore question]  \n",
       "4            [Ignore question, Repetition]  \n",
       "..                                     ...  \n",
       "378               [Topic transition error]  \n",
       "379               [Topic transition error]  \n",
       "380                    [Unclear intention]  \n",
       "381                    [Unclear intention]  \n",
       "382                    [Unclear intention]  \n",
       "\n",
       "[383 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>tid</th>\n      <th>usr</th>\n      <th>sys</th>\n      <th>ec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1470646494</td>\n      <td>2</td>\n      <td>そうですね。最近とても暑いですから。</td>\n      <td>海に行かないんですね？</td>\n      <td>[Contradiction]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1470646494</td>\n      <td>4</td>\n      <td>休日に行きたいと思います。</td>\n      <td>海は大丈夫ですね</td>\n      <td>[Lack of information]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1470646494</td>\n      <td>6</td>\n      <td>はい。あなたは海に行きますか？</td>\n      <td>海は危険です</td>\n      <td>[Ignore question, Self-contradiction]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1470646494</td>\n      <td>8</td>\n      <td>何故ですか？</td>\n      <td>海はいけないです</td>\n      <td>[Ignore question]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1470646494</td>\n      <td>12</td>\n      <td>山はお好きなのですか？</td>\n      <td>わあ！いいですね！</td>\n      <td>[Ignore question, Repetition]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>1470623483</td>\n      <td>8</td>\n      <td>固いといえばくるみかな</td>\n      <td>風早が好きですね</td>\n      <td>[Topic transition error]</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>1470623483</td>\n      <td>10</td>\n      <td>花火見に行ったよ</td>\n      <td>風早がかっこよいですね</td>\n      <td>[Topic transition error]</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>1470623483</td>\n      <td>12</td>\n      <td>かっこいいね</td>\n      <td>ありがとう</td>\n      <td>[Unclear intention]</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>1470623483</td>\n      <td>16</td>\n      <td>真夏日が続いて夏バテしそうだよ</td>\n      <td>真夏日は続くんですね？真夏日まで気温が上がりますよねー</td>\n      <td>[Unclear intention]</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>1470623483</td>\n      <td>20</td>\n      <td>私は苦手だなあ</td>\n      <td>真夏日はスイカがうまいですね</td>\n      <td>[Unclear intention]</td>\n    </tr>\n  </tbody>\n</table>\n<p>383 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df = read_json(path, datalist)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of breakdowns:  670\n-- Frequency of labels --\nIgnore question 129\nUnclear intention 181\nWrong information 2\nTopic transition error 51\nLack of information 22\nRepetition 34\nSemantic error 6\nSelf-contradiction 6\nContradiction 8\nGrammatical error 4\nIgnore offer 0\nIgnore proposal 1\nLack of sociality 1\nLack of common sense 7\nUninterpretable 0\nIgnore greeting 0\nNo-Err 287\n-- Frequency of sets of labels (sorted) --\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(No-Err,)                                      287\n",
       "(Unclear intention,)                           142\n",
       "(Ignore question,)                              62\n",
       "(Ignore question, Unclear intention)            38\n",
       "(Topic transition error,)                       33\n",
       "(Repetition,)                                   26\n",
       "(Lack of information,)                          18\n",
       "(Ignore question, Topic transition error)       17\n",
       "(Contradiction,)                                 8\n",
       "(Ignore question, Repetition)                    7\n",
       "(Lack of common sense,)                          6\n",
       "(Semantic error,)                                6\n",
       "(Self-contradiction,)                            5\n",
       "(Lack of information, Ignore question)           4\n",
       "(Grammatical error,)                             4\n",
       "(Wrong information,)                             2\n",
       "(Topic transition error, Unclear intention)      1\n",
       "(Lack of common sense, Repetition)               1\n",
       "(Ignore question, Self-contradiction)            1\n",
       "(Lack of sociality,)                             1\n",
       "(Ignore proposal,)                               1\n",
       "Name: ec, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "y = np.array([[1 if (i in ec) else 0 for i in error_types] for ec in df_all.ec])\n",
    "\n",
    "# Display data statistics\n",
    "print('Number of breakdowns: ', y.shape[0])\n",
    "print('-- Frequency of labels --')\n",
    "for e,c in zip(error_types, sum(y)):\n",
    "  print(e,c)\n",
    "print('-- Frequency of sets of labels (sorted) --')\n",
    "df_all['ec'].apply(tuple).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df:pd.DataFrame) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "\n",
    "  # Make feature vector\n",
    "    return np.array([np.concatenate([nlp(u).vector, nlp(s).vector]) for u,s in zip(df.usr, df.sys)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_context2(df:pd.DataFrame) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    feature = []\n",
    "    did = 0\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        if did != d:\n",
    "            u_prev_vec = nlp(u).vector\n",
    "            s_prev_vec = nlp(s).vector\n",
    "            did = d\n",
    "                  \n",
    "            if e[0] != \"No-Err\":\n",
    "                each = np.array(\n",
    "                    [np.concatenate(\n",
    "                        [np.zeros(300),\n",
    "                        np.zeros(300), \n",
    "                        u_prev_vec, \n",
    "                        s_prev_vec]\n",
    "                    )]\n",
    "                ) \n",
    "                feature.append(each[0])\n",
    "\n",
    "        else:     \n",
    "            # エラーである\n",
    "            if e[0] != \"No-Err\":\n",
    "                u_vec = nlp(u).vector\n",
    "                s_vec = nlp(s).vector\n",
    "                each = np.array(\n",
    "                    [np.concatenate(\n",
    "                        [u_vec,\n",
    "                        s_vec, \n",
    "                        u_prev_vec, \n",
    "                        s_prev_vec]\n",
    "                    )]\n",
    "                )\n",
    "                feature.append(each[0])\n",
    "                u_prev_vec = u_vec\n",
    "                s_prev_vec = s_vec\n",
    "            # エラーではない\n",
    "            else:    \n",
    "                u_prev_vec = nlp(u).vector\n",
    "                s_prev_vec = nlp(s).vector\n",
    "    return np.array(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_at_least_oneClass(clf, X) -> np.array:\n",
    "    y_pred = clf.predict(X)\n",
    "    p = clf.predict_proba(X)\n",
    "    # print(y_pred)\n",
    "    proba = np.array([[p[c][i][1] if (p[c][i].shape[0]!=1) else 0 \n",
    "                     for c in range(len(error_types))] for i in range(len(X))])\n",
    "    # print(proba)\n",
    "  # replace [] to the highest probability label\n",
    "    y_pred2 = np.empty((0, len(error_types)), int)\n",
    "    for y, pr in zip(y_pred, proba):\n",
    "        if  (sum(y) == 0):\n",
    "            ans = np.zeros_like(y)\n",
    "            ans[np.argmax(pr)] = 1\n",
    "        else:\n",
    "            ans = y\n",
    "        y_pred2 = np.append(y_pred2, np.array([ans]), axis=0)\n",
    "    return y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_y(df:pd.DataFrame) -> np.array:\n",
    "    y = []\n",
    "    for ec in df.ec:\n",
    "        if ec[0] == \"No-Err\":\n",
    "            continue\n",
    "        y_each_err = np.zeros(len(error_types))\n",
    "        for i, err in enumerate( error_types ):\n",
    "            if err in ec:\n",
    "                y_each_err[i] = 1\n",
    "        y.append(y_each_err)\n",
    "    return np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success feature_extraction\nsuccess extract y\nsize | X: (383, 1200) y: (383, 17)\n"
     ]
    }
   ],
   "source": [
    "# df = read_json_with_NoErr(path, datalist)\n",
    "# df_ = read_json(path, datalist)\n",
    "\n",
    "# feature extraction\n",
    "X = feature_extraction_context2(df_all)\n",
    "print(\"success feature_extraction\")\n",
    "# print(df_.shape, X.shape)\n",
    "\n",
    "\n",
    "# Make target (Multilabel)\n",
    "# y = np.array([[1 if (i in ec) else 0 for i in error_types] for ec in df.ec])\n",
    "y = extract_y(df_all)\n",
    "print(\"success extract y\")\n",
    "print(\"size | X:\", X.shape, \"y:\", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=5)\n",
    "\n",
    "# clf = MultiOutputClassifier(AdaBoostClassifier()).fit(X_train, y_train)\n",
    "# y_pred = predict_at_least_oneClass(clf, X_test)\n",
    "\n",
    "# print('EM:', metrics.accuracy_score(y_test, y_pred))\n",
    "# print('F-measure: ', metrics.f1_score(y_test, y_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_error(df:pd.DataFrame) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    feature = []\n",
    "    did = 0\n",
    "    # show_error_set = set([\n",
    "    #     \"Ignore question\", \"Ignore proposal\",  \n",
    "    #     \"Ignore greeting\", \"Ignore offer\"\n",
    "    #     # ])\n",
    "    show_error_set = set([\n",
    "        \"Ignore proposal\",  \n",
    "        \"Ignore greeting\", \"Ignore offer\"\n",
    "        ])\n",
    "    print(show_error_set)\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        # if did != d:\n",
    "        #     print()\n",
    "        for e_ in e:\n",
    "            if e_ in show_error_set:\n",
    "                print(\"error\",e_,\":\", u, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Ignore proposal', 'Ignore offer', 'Ignore greeting'}\nerror Ignore proposal : あなたも一緒にお祭りに行きませんか？ お祭りをみます\n"
     ]
    }
   ],
   "source": [
    "show_error(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(383, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_error_dict(error_types):\n",
    "    error_dict = {}\n",
    "    for e in error_types:\n",
    "        error_dict[e] = len(error_dict)\n",
    "    return error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_did_error(df:pd.DataFrame, error_types) -> np.array:\n",
    "    nlp = spacy.load('ja_ginza')\n",
    "    \n",
    "    did = df.did[0]\n",
    "    # 全体\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    # 各 did \n",
    "    sequence_did = []\n",
    "    y_did = []\n",
    "    \n",
    "    # エラーの辞書定義\n",
    "    error_dict = make_error_dict(error_types)\n",
    "    for d, u, s, e in zip(df.did, df.usr, df.sys, df.ec):\n",
    "        # did で学習データを分割してみる？\n",
    "        y_one_conv = np.zeros(len(error_types))\n",
    "        \n",
    "        if did != d:\n",
    "            did = d\n",
    "            # 登録用データ修正\n",
    "            sequence_did = np.array(sequence_did)\n",
    "            y_did = np.array(y_did)\n",
    "            X_data.append(sequence_did)\n",
    "            y_data.append(y_did)\n",
    "\n",
    "            sequence_did = []\n",
    "            y_did = []\n",
    "\n",
    "            # break\n",
    "\n",
    "        for e_ in e:\n",
    "            y_one_conv[error_dict[e_]] = 1\n",
    "\n",
    "        sequence_did.append(\n",
    "            np.concatenate(\n",
    "                [nlp(u).vector,\n",
    "                nlp(s).vector]\n",
    "            )\n",
    "        )\n",
    "        # print(sequence_did[0].shape)\n",
    "        y_did.append(y_one_conv)\n",
    "\n",
    "    sequence_did = np.array(sequence_did)\n",
    "    y_did = np.array(y_did)\n",
    "    X_data.append(sequence_did)\n",
    "    y_data.append(y_did)\n",
    "    return X_data, y_data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_data, y_data = div_did_error(df_all, error_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 600)\n67\n"
     ]
    }
   ],
   "source": [
    "print(X_data[4].shape)\n",
    "print(len(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 17)\n67\n"
     ]
    }
   ],
   "source": [
    "print(y_data[5].shape)\n",
    "print(len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(670, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}